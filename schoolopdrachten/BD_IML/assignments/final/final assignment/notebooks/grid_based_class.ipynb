{
 "cells": [
  {
   "attachments": {
    "grid_voorbeeld.JPG": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQEAYABgAAD/4RD0RXhpZgAATU0AKgAAAAgABAE7AAIAAAAOAAAISodpAAQAAAABAAAIWJydAAEAAAAcAAAQ0OocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAElicmFoaW0gU2FoaW4AAAWQAwACAAAAFAAAEKaQBAACAAAAFAAAELqSkQACAAAAAzY4AACSkgACAAAAAzY4AADqHAAHAAAIDAAACJoAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIxOjEwOjMxIDIwOjI3OjQ2ADIwMjE6MTA6MzEgMjA6Mjc6NDYAAABJAGIAcgBhAGgAaQBtACAAUwBhAGgAaQBuAAAA/+ELIGh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjEtMTAtMzFUMjA6Mjc6NDYuNjgzPC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPklicmFoaW0gU2FoaW48L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgAvwOkAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+kaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArO1rw9o3iO1W317S7TUYUO5EuoVkCn1GRwfpWjRQBU0zSdP0WxSy0ext7G1TlYbaIRoD64HerdFFABRRRQBT1TSNO1yxNlrNhb39qzBjDcxCRCRyDg8VaiijhhSKFFjjRQqIgwFA6ADsKdRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAFebT7O4vbe8uLSCW6td3kTvGC8O4Ybax5XI4OOtWKKKACiiigAooooAKKKKAGTQxXMDw3EaSxSKVeN1DKwPUEHqKydH8HeG/D11Jc6FoOnafPIMNLbWyRsR6ZAzj2rZooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoqpdahHayhHBJIzxUP9swf3WoJ5kaNFZ39swf3Wo/tmD+61AcyNGis7+2YP7rU5NWhfdhT8oyaA5kX6Kzv7Zg/utR/bMH91qA5kaNFZ39swf3Wo/tmD+61AcyNGis7+2YP7rU59WhjbaVOcA/mKA5kX6Kzv7Zg/utR/bMH91qA5kaNFZ39swf3Wo/tmD+61AcyNGiqA1aExs+04UgH8c/4U3+2YP7rUBzI0aKzv7Zg/utR/bMH91qA5kaNFZ39swf3WpV1eFmChTknFAcyNCiiigoKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDD1r/j9T/rmP5muA1bxTf6V4ontjb/aLfZDFbwx7iWkcSMWbbGzABYj0B+nOR3+tf8fqf9cx/M1iXWl6ffK4vbG2uBJt3+bErbtuducjnGTj0yaRhK13c5S6+ILCEG001g0kDMhmLDy5fIaYK4C4HC4wWDd9uOasP45Nvpcc01hvuCzxtHHKMFkVScEjoS1bNxpGg2avfXOnWMQhj5lNuvyqF2+n935fpxUOl6X4dv7K31Kw0iyEdzCrRv8AZFVimBgYxkcAcew9KpdSdNCrpfiyTUNcOnS6ZNDteSIzLvZBIgG4bigXGcgEHJxyBmuqg6S/9cz/ADFUE0ywi1B7+Oyt0vJBh7hYlEjDjq2M9h+Qq/B0l/65n+YpdA6mF4ovb6w0My6X5YuHnhhVpDgKHkVCeh5+b0/wrEt/H/nwlk0ucb8fZmkEiibLFf8AnnknjOED8fQ46+WGKdNk8aSLuDbXUEZByDz3BAP4VRbw9ozebu0myPnOHk/0dPnYEkE8cnJJ/E0BpYwNK8cS6hqMayWSR2txHG0R8w70Yxyu24EDj91gf5FMX4gSSwRSwaPI6zukcQEjOWYwCZshEYgBWAzg5PoOaviDwxcaoulvotvuGY42ksAI2KDcUViMcbifTlsd61pND0mW0+yy6ZZvb7g3lNApXIUKDjGMhQB9BijzHoT2F2uoabbXiRyRLcRLIEkGGXIzgj1q7c/6/wD4Cv8A6CKgRFjjVI1CIoAVVGAB6AVPc/6//gK/+gim7X0JWxwLeNr7T9Qvoryxe72zzGNLZXby4Yiqn7sZyxLZ+Ygf7QqW68dTtdPbWFhGX85BHJLI+x0+0JC/OzGfn42lgO+CMV00+i6XdMpudOtJikhkUyQK2HPVuR1OBz7VQ1Kw0DS4nuJ9FglNwxDiGyEjPzvOcDpld3PceuKnZK/QrRt2KX/CamVrCO004yzXsUMqK0wUKJBKeTg9BEe3OateGvFI8Rs+LCe1TyknieRHAdGJxyyqM8dtw5GCauadpeiCOO+0zTrOMThZ0lit1UtkHDZxnOGP/fR9atWemWGnvK1hZW9s0xzIYYlQufU4HPU/nVbPUl2exfX/AI85f99f5NXL+MdbutCs7O5tgvlGdjckff8ALSJ5CFGCCTsx/h1HUL/x5y/76/yaqs1tBchRcQxyhCSvmIG2kggkZ9iR9Cal36D06nH3HxCa2sJJptImWWHe8kTeYuY1RWLKDHuPDAZKhQerDIJntvGkqjUPt1mn+jSSGPypPvIJRGM5HDc5raPhnQjAsB0bTzEpJEf2ZNoyADxjvgfkPSqlvaeGdW1O8ii02xnuLGYec5tVOJGAP3scn5Rk+q+1UrXDoZn/AAn0gkiDaNOyyAynymeQiLzPLDfKhAOQxwSBgdcnFdrD/r4/94fzrOk0XS5jAZdNtHNucw7oFPlnOfl4455471ow/wCvj/3h/Ol0DS+h1NFFFB0hRRRQAUUVzHj3V77RdBhudMn8iVrlUZtitldrHGCD3AoA6eivFT8QPEwH/IS/8gR//E04eP8AxLtGdR/8gR//ABNAHtFFeLv4+8ShSV1L/wAgR/8AxNVbr4n67ZKPtOq7CegMEfP/AI7TUXJ2QHuVFfNF18YfGT3Dm11fyov4VNtCf/ZKt6J8WPFlxcvHfa2G3ACMfZYRz+CV1SwlSMOZk8yPoyivFP8AhYHiYnjUv/IEX/xNO/4T7xM3TUsf9sI//ia5Cj2mivFT4/8AEvIGqcj/AKd4/wD4mkHxB8THj+0vx8iL/wCJoA9rorxZvH/iXGRqn/kvH/8AE0Dx/wCJTx/afPr5Ef8A8TQB7TRXg2s/E3xNY2LbNX2TH7n+jxHP/jtc9b/GDxqtwpn1fegPzJ9lhGfx2V008NOpHmiS5JH01RXikXxB8TSRqRqfLKD/AKiL/wCJpw8feJuc6n/5Lx//ABNcxR7TRXiv/CwPEwHOpf8AkCP/AOJo/wCFgeJuP+Jln/thH/8AE0Ae1UV4jd/EfxFaW7TS6qFUdvIi/wDiawm+NXiLaQLpt3Y+VF/8RW1OjUqaxQrpH0XRXzXZ/GbxbEzm81AzqfugQQrt/JKuf8Lq8Q/8/Df9+4v/AIitZYOsna1xcyPoiivCdP8Aib4l1C0E6ajsyxG0wRH/ANlq6fH3ifjGp/8AkvF/8TXNKLi7Mo9porxZfH3ibP8AyE9w/wCveP8A+JoPxA8Sgn/iZZ56eRH/APE1IHtNFeLN8QPEqjH9pc+vkRf/ABNZN/8AF7X7C48r+0DMw+8BDEMf+O1cKcpu0UF7Hv8ARXzWfjL4tF95n9pH7OekX2eHj8dlT3Hxn8TPAy2920UhHyuYYjj8NldDwdZNaE8yPo2ivnqy+MPiW5uYbc3TbnIBfyouv/fFbn/CwPEgOP7Syf8ArhH/APE1hUpzpu0kNO57TRXn3gLxPq+ta9Nb6nd+fEts0gXykXDblGcgDsTXoNZjCiiigAooooAKKKKACiuX8favfaLoMNxplx9nla5WMtsVsqVY4wQe4Fefjx94m2nOpfj5Ef8A8TQB7RRXiw8f+JScDUun/TCPn/x2o5viL4iijeR9UCqgyf3EX/xNG4HttFfOk/xo8R7JI4bxt/IWTyYuPfGyobL4z+KY4yt3fmd+zCCFf5JXUsJWcb2J5kfSNFfODfGbxQbpXW9YQhSGj8mLk+udla+lfFLxJqccji9MQQ45hiOf/HaieHqQjzSWg7pnvFFeLD4geJW6al+PkR//ABNen+ENQudU8K2d5fS+bPJv3vtC5w7AcDA6AVgM2qKKKACiiigAooooAKKK+QPGvxy+IukePvEGm6f4h8m0s9TuYII/sVu2xElZVGTGScADknNAH1/RXxL/AMNB/E7/AKGb/wAkLb/43Utt8ePirdzJFbeIWkd2CKF062OSTgf8s6APtWivHvDvh/4zajptpfar4/hsZJMNLZvo9uzKM9NwUdq7XxfovjLVILNfCXiuLQ5Ix/pDvYRz+ccejA4/CgDrKK4HS/DXxHttJ1OHVPHsF5eTxBbK4GlRILZ88sVAw3HY15f8Udc+LHwx0qyvbnx/DqAu5jEEj0m3j24Gc8oaAPo6iviX/hoP4nf9DN/5IW3/AMbr6I/Z/wDGOu+N/AN7qXie++3XcWpyQJJ5KR4QRRMBhFA6s3OM80AepUUUUAFFFFABRRRQAUUVzfxB8Xf8IJ4E1DxH9i+3/YvK/wBH83yt++VY/vbWxjfnoelAHSUV82/8Nc/9ST/5Vv8A7TVyy/aq+2RXL/8ACG7PIj34/tTO72/1NTKSirs1pUp1p8kFd/5an0NRXzvp37VF1quoQ2Vh4DaaeZgiKuq9Sf8AtjXdn4meLbGaA698Pm061llWI3B1UPtLHA48oUSkoq7CjSnWqKnTV29j02iuD1vxl410/Wbi10r4etqVpG2Irv8AtQR+aPXb5Rx+ZpNY8e+I9F8OWeqXfgwhpM/aof7QH+jenPl/Nn6CnKSirsVKnOrNU4K7bsjvaK8B8QftM6h4Z1U6fq3gPybgIsgU6t1VuQf9T6Vl/wDDXP8A1JP/AJVv/tNMhpp2Z9JUVm+HNX/4SDwrpWs+R9n/ALRsobvyd+/y/MQPt3YGcZxnArSoEFFFFABRRRQAUUUUAYetf8fqf9cx/M1n1tajbJNcKzswOwDge5qp9hh/56P/AN8igwlF3M88iqej6f8A2VotpYeb5v2aJY/M27d2BjOMnFbn2GH/AJ6P/wB8ij7DD/z0f/vkUC5WUKlg6S/9cz/MVa+ww/8APR/++RT4rKJRJh35THQUAoszaKv/AGGH/no//fIo+ww/89H/AO+RQHKzlbbRb6PxPNql5fwXMbApBEbVla3Q4+VW8wjkjJO3J+gAG3V/7DD/AM9H/wC+RR9hh/56P/3yKOlg5WUKluf9f/wFf/QRVr7DD/z0f/vkU+ayiaTJdxwOw9KA5XYzaztb06bVNPNrDLbqjkiWO6tvPjlUgjaVyD1weD2roPsMP/PR/wDvkUfYYf8Ano//AHyKTV9ASa1MbTbM6fpdrZmZ5zbwrGZZPvPgYyfc1aq/9hh/56P/AN8ij7DD/wA9H/75FU3d3Fysqr/x5y/76/yaoq0lsohbuu98FlPQe9M+ww/89H/75FIfKzPYblIyRkYyO1Yfh/wxH4eu7uSC9uJ4rhUVY5iDs255yOpOev8AOus+ww/89H/75FH2GH/no/8A3yKA5WUKfD/r4/8AeH86ufYYf+ej/wDfIp0dlEJFIkfgjsKA5WbdFFFB0BRRRQAVxXxT/wCRWt/+vxf/AEB67WuK+KYz4Xtv+vxf/QHoA8nUY60h/ibooGSfSh5PKRnb5lVSeK4e81CWe7mkhkkWN24UtXTQw7rN9BN2Nq/8SCPdFaDLg8SHkGsO81G41DH2khivTAxVRvXv2pcfn7V7FPD06ey1Mm2xPu/eNPiV5ZkSAEuTxt61HyWOantHkhu42gXdIpyorWWi0A7u3AW2jD53BRmphyc9KiiLNChYYZlGakAKtx6d6+ae5sGMsR7044Awoz6008MPejO33NIBVYbSKavAJ7VHPeQ265ndUOMgHqa42+v5Li+eSGSRY2PA3dK6aOHlVfYTdibxBfG7vSiurxR/dwKyV3BaVmyaUp717kIqEVFGW52Phti2kBnJJ3EcnpWmAOufpWX4ejki0lRICvzk4NaqqG5FeBX/AIsrdzVbBjcOabKfKjZ+oVSaevUg8c1leJZGj0ljG207wOKmnHnmo9wehzepalJqM2SSqD7q+g96m0zQpr+MyBhGo+6WH3qqabam9vY4lwD159q7xEWOPagwB6V6mIrewioUyEr6s5a58LzwwM6zLKw6IoOTWaunXjTNELZy6jJX0ru+uGzVe8ubeyieebhiO3Vqwp4yo/dtdjcUcjpTPHq0CMzL+8xtzxXbn7uQetcVpYa412KSNCwEm4+wrtSFA5557Usd8a9Bx2DIC4B5zQVwaMZAI4FJJKIo3ZhkKCa88o5XXdWlkne1hygRsN6k1mRWt1egtDE0pH3iO1Jezpc38syAgOcgGuo8OwwJp4kibMjcyDPQ17cpLDUU4rUz3ZyUsEkMmy4Qow6g0mMjrwK9CaGB8vJEjHuSK5rxE1q8cX2Ux7tx3BO1Kji/ayUbA42MOGZ7e4SSLhlOQTXoNsS9vGz8kqCa4G1g+03CQpwznAJ7V39uuy3RG6qoBNY4+3u9xwO3+FoA8VXOP+fJv/Q0r1ivJ/hauPFVx6fYm/8AQ0r1ivLLCiiigAooooAKKoW2tWV1rF5pccuLyz2mSJuCVZQwYeo+bH1/Cr9BMZRkrxZxXxTx/wAIvbZ/5/V/9AevKPvN14r1f4p/8ivbZ/5/V/8AQHryfGCaCiveXAs7OScqWCDOBXF3eoXF3cGR2O08YHTFdP4hvEh01o3UkygqMdq5SzSKS7iSY7Y2bDHPQV62CglBzaIlvYedNvfL837M+zGc47VWAwfQ16HGkaW6xr80e3AzzkVFPHZQIDLHEgzjcVFKOPeziHKcCR3zzWz4ZuJRfmAHEbgswI9Kz9R8s6hMYuU3cbelafhq2LXZuV+7H8pHrmuqu06LcuxK3OrAB/Gvafh//wAiLp//AG0/9GtXi5Gcdq9n+H/HgXT8/wDTT/0a1eAanSUUUUAFFFFABRVbUr+HS9Nnvrnd5Nuhd9oycDrT7S7gvrSO6s5VmglXcjochhQTzR5uW+pNXwB8R/8Akqfiv/sNXn/o96+/6+APiP8A8lT8V/8AYavP/R70FGJptk2o6pa2SMEa4mWIMegLHGf1r7e+G/wq0jwF4eS1aGG8vpMNc3DoGDOO6gj5RXyV8KvCl34v+IFhZWMscTwOLljJ0KoQSPrX3TfySw6bcy2y7pkhdo1xnLAHA/OgDA1D4j+D9J1Z9L1HX7O2vY2CNA7HcCeg6V0yOskauhyrDII7ivz+8canq+qeNtQvtfg+y6lJLmWMLt2kdOKTTtc8WaneR2WmalqVxO/CRRzsSfoM0AfoHXm/x18Nadr3wx1C71BHaXS4muLYq2MPwOfXirHwTg1e2+GNnH4iW4W+Esm8XJJfGeM5qh8ffFdr4d+Gt1ZXUUkj6ujW0RTorYByfagD4rr62/ZU/wCSWal/2Gpf/REFfJNfW37Kn/JLNS/7DUv/AKIgoA9tooooAKKKKACiiqGka1Za3avNYS7/AC3MciHho2BwQRQS5RTUW9WX682/aD/5IT4h/wC3b/0pir0mvPPjy0CfBLXmu0aSEfZ9yqcE/wCkxY5+tJuyuaQipSUW7X6s+H66z4e6I3iTXm0dJhC14oiEhGQuT1rJ+06H/wA+Nz/39FegfDHSLp9d07U9EsZrKOe48mC9uDvjLjqMe1clao3D4X07d/U+iy3BQjik1Wg9Jfzfyv8Aun0h4I+EHhnwQ8V5Z2ofUFhCSzu25WPcgHpU3xRkRvDlmFdSf7Rt+h/2xXE/FbxB4z8E+D2udV1W0u7e7b7Oy20BjcZHUHPFeAaH4lzqaywy37vAPNUXFyZFyvPQmitUbpv3X+H+YZZg4RxtOSrQevTm/wDkT7sHQVyfxM/5EG+/4D/Ovnu1/aU8UXN3DbqIVMrqgJhXjJxXq/jKz8ZnwVPcaprNhNaMqM0UdsVY5xjmnVqN05Lle3l/mRl+ChHGUmq0H7y/m7/4TyP9ovwjJp99pfic3SumowxwCELymyPOc14jXvHxv1KRNN0fTfEuq2upywgSJaWiGOSAFOCxPUEcV479p0P/AJ8bn/v6K0VV2+F/h/mclTA0+d/v4f8Ak3/yJ90/Dj/klnhT/sC2f/ohK6Sue+HxRvhl4XMKlYzo9oUUnJA8lcV0NbnlNWdgooooEFFFUNS1qy0ia0TUJfJF3L5Ubt90NjIBPbNBMpRgrydkX6KKKCije/64f7tcLrHizUNI8WT2ptvtNtsgitoYg7M0jiVyzbY2YALER8oP05yO6vf9cP8AdrMu9J06/WQX1hbXIk27/NhVt23O3ORzjJx6ZNIjTW5yF38R2EINnpbB5LdmQzs48uX7O0wRwEwOFxgsG77cc1Zk8em20mOefTvMuC0kbRxzDBdFUnBI6Ev6Vrajpvh3SbWTVLrSbMfZ0A3paKz4xsCqAM9Dtx6cUabomgXMCXtvoFpbtIm0CSyRHCjgDGOmAPwAqlbUT6FPSfGEmpa8dMl0qaDa8kJnUOyCWMAuNxQLjOQCGyccgZrqo+j/AO7VKPStPi1J9QisbZL2QYe5WJRIw46tjJ6D8hV2Po/+7S6IOph+K76/0/QWl0nyxcvPBCrSHAUSSqhPQ8/N6f4VhW3xF+0QMyaTcDft+ytKJFE4Llf+eeS3GcRh+PocdnNBFcR7LiJJUDBtrqGGQcg89wQCPcVQbw3ob+du0ewPnuJJf9GT52BJBPHJySfxPrQGljndH8eS6lqcSyWKRWlzFG0J8w70YxSuwYEDj91gdPf0Ea/EWSWCKW30WSRZ3SOECR3LMYFnbKpGxACsBnByfQc1pR2vha+1N9LTQ7aUwfu9509TECnOwNtxxvPHTlgOciteTQdIms/skulWT224N5LW6FNwUKDjGMhQB9Bijz+4ehPp14uo6ZbXqRyRLcRLKI5Vwy7hnBHY81bk/wBZ+A/lUaIkUaxxKqIoCqqjAAHQAVJJ/rPwH8qbtfQlbHn7eO7/AE7Ur+G9sJLzbcTmOO1V38qCIqpPyxnLEtn5iF/2hxUt34/uGu3tdP0+Iv50axSyyPskT7SkL87MZ+fjaWA74IxXVXGh6TdsputMs5ikhlUyQK2HPVuR1OBz7VmaxZeHdEs57660GCWN9xuHhskc7c7yz8dMqG57jNTslfpuU9W7FP8A4TkzNp8Vnpplmv4YJUVpwoQSCU8nB6CE9uc1b8LeLR4maTGnXFonkpPC8qOBJG5OOWVRu45C7hyMMau6XpOirFFf6fpFravOFnDfZVjkBIOCeMhsO303H1NW7LStP015W0+xtrVpjulMESoXPPJwOep/M1Wz1J32Lo/1Lf7w/rXL+Nteu/D9lZXNqF8k3DG5I+/5SRPIwUEEEkJj/DOR1A/1Lf7w/rVee1t7oKLmCOYISVEiBtpIKkjPsSPoTUu/QenU4y5+I7WunyzzaNMk0Id5IW81SY1RXLKDFuPDgZKqoPVgCCZ7bxxMo1L7fZR/6LJIY/JlPzRiYRjORw3OfStw+FvD5t1gOh6cYULFY/sqbRuAB4x3AH5D0rN0xfCniO6la30i1klixcB5rFVLhyQJFJHIJj69flHtVK1xP4Sh/wALDkEkIbRJ2WRTKfKZ5SIvM8sN8qEAkhjgkDA65OK7hPvr9az5dD0mc25m0yzkNscwboFPlHOfl445GeO9aCffX60ug+uhqUUUUGgUUUUAFcX8Uv8AkV7fP/P4v/oD12lcV8Uz/wAUtb473i/+gPQB41rMM0+mlbU7G6nHcelcM6uHKsNpB5Br0YgnCtWXqHh+C9mDhjEf4io+8fWvQwuJjSXLLYiUbnM2Wlz6ijGEr8hwcmtC60JLLTHnlZjKvUDpXRWGnw6fbqiD5sfM2OW+tYvimd0WKNJOGzvUHrWscTOrWUYvQLJI5sck4/WtXQrZ59SSRMERHc2aysjPp6113hyGJdNWVFCuzEM3ciurFVOSm33JitTYVvagkg0LndjOR70pO4cgYrwDUTnHqM4qtf3iWFu00gJA+UYHerK+/TtXO+KJpBJGgLCJlyw7E5rahT9pUUWJ6Iyb/U5NRZGlUKUGBiqkSmaURoCST2q3ZaVc3+XhT5QcEk44rpNN0WDT5GcHzHPRmH3a9epXpUFyrfsZpNmLq2jx2EETw733D5iR0rJAzgk11fiS6eGy8pE3CThm9K5PaAM9TTws5Tp3kEtz0G3wYIvTYP5VITjpxUdoP9Giz12D+VS7fmweleFLdmoAcbjWdrdnJeacyxAEg7ua0Tnbjtmhx8vyn2xThJwkpLoB58jSW8pKM0bj04Ird03xEsUPl3uW29GAyT9aua5pkclk8kUUazZBLk4zXIc54r2o+zxULtGesTrz4lsTyFf8Vrm77UJr64LyfdB+VR2qqOVq/oiWst+i3jEAH5Vxw31qo0KdBOaQrtmr4Ys5YHkuHXasi4AbrXREEcgcd6bhOi9AOKcM7eteNVqOrNyZolZAQNv40yWPfCyn7rAgmnj5WwBk470jdgemayGcFfW32S+kiwdinCse4q3o2rDTpGV1zG/JPeui1jT4Lu1JkwjKMh+49q4raMkZ6V7lGccTTtIyejOouPEtv9nYW6sZCOAw4rlmYs7MepOTilwDjFWNPMKX8b3Q3Q5+Ydc1rTpQoxfIgbua3h7TPNZbtzgKflx61044JBqK0igjth9mVVjPIC1YAGOa8WvVdWd2aJWR2fwsJPie4/682/8AQ0rdv/izo2n6lc2U1nftJbStExVEwSpIOPm6cVg/Cw58U3PP/Lm3H/A0rgfE/wDyN2r/APX9N/6MNTTipPU8XN8ZVwkIypdWeqf8Ll0L/nx1H/vhP/i6P+Fy6F/z46j/AN8J/wDF14vRWvsonz39uYzuvuPaP+Fy6F/z46j/AN8J/wDF0f8AC5dC/wCfHUf++E/+Lrxeij2UQ/tzGd19x0ev+KnvPHM3iDRWmtWJQxl8BhtRVOQCRg4PHpXsHgvxpa+K7DB2w6hEv76DPX/aX1H8vyJ+fKs6fqF1pd/FeWEzQ3ETZR1/l7j2pygmrGeDzSrh6znLVSd2v1R7b8UufC9t/wBfi/8AoD15PgFuCa9G8ZXt5qfw50y71O0NncyXKM8J7fI/Ptnrg8ivOQcqMDA7VyH30JKcVJdTK1+z+0WJPJeLLKB3rjug54OeleigBmOa5XxFYQW8gnhwhc4KD+dengq1v3bFJdSzY+I4ktUjuVIZeBtHaqet6yt/GIYF/dg5JI5zWPgDmkx1rtjhqcZ86WpPM7CxKZJFT+8cDNdtpWm/YLUrnLty3oDWL4eWzkUxXKK0+7chPYfWurwM4rhxtZt+zKiuo0Hgeter6Fr9v4b+F9lqN7HLJEjOpWIAtzKw7kV5U2AOK7XVv+SE23f99/7WavPiruxji6kqVCdSO6TZqf8AC5dC/wCfHUf++E/+Lo/4XLoX/PjqP/fCf/F14vRXR7KJ8Z/bmM7r7j2j/hcuhf8APjqP/fCf/F0f8Ll0L/nx1H/vhP8A4uvF6KPZRD+3MZ3X3Hq/iD4qaPq3h2+sLezvkluYWjVnRNoJHfDVy/gbxzP4Xuxb3RabTJW/eR9TGf7y/wBR3rkKKpQilY5amZYmdaNZv3kfUlpdwX1pHdWcqzQSruR0OQwr4G+I/wDyVPxX/wBhq8/9HvX0n8LNe1a21xdKtYXu7GY7pY88QesgPb3Hf6182fEf/kqfiv8A7DV5/wCj3rllHldj7jAYxYyj7RKz6lz4XeL7jwX48stQtUiYysLdzKeFRyAT+Vfd1tcwXlslxaSpNDIMpIhyrD2NfnDX0P8As2ePtdl1dfCtzHJd6bsLRzPnFsFHCDAxg571J3G38W/gDqXirxW+t+Gp4zLdktcrcPtCnttp/wAIvgJqPhLxQut+JJ4xNanNstu+4Me+6vfqKAAnCkntXx18d/ionjjVl0fT4dun6dMxV3XDmT7rD6cV7f8AHkeMrfwzb6h4Lu5rZLNme88hvmZMYGBg55r42nklluZJLgsZnctIW6liec/jQBHX1j+y9cLa/CHWLiQErDq0zsF6kCCE18nV9U/s2/8AJD/EP/YRuf8A0mhoJm2oto7j/hcuhf8APjqP/fCf/F0f8Ll0L/nx1H/vhP8A4uvF6K6vZRPhf7cxndfce0f8Ll0L/nx1H/vhP/i6P+Fy6F/z46j/AN8J/wDF14vRR7KIf25jO6+49o/4XLoX/PjqP/fCf/F15ppHiq80HxJNqemsdksrNJC54kQnOD7+/asKiqUIo5a+ZYmvKMpPWO1j6W8P+ILHxJpSXunvkHiSM/ejb+6R/nNcV+0H/wAkJ8Q/9u3/AKUxV5z4T1vVND16GTR1aaSVgjWwyROM/dx6+h7V6T8c4nvfgZraSbbd5FtiwkYYQ/aIiQSPyrmqRUNeh9nlOMlj48tvf0Xk7nxFXuHwd8WWtxZ+HvCywSC5tNTe5aUn5SrdB9a8l/sE/wDP9bf9910Pg17jwvrB1WzubaWe3AeME5UEevtXBWrU3Cyfb8z7bLctxcMUpShpaXVfyvzPtPxZoEfiXwxe6a8cLyTRMsTSruCMRwa+NpPhv4l8La7dw3+mzmBA0CXKphJWIwMfWvpnw78XrfWdGhni0u9vJVULM9tHuTf3ArM8e+NBqmi20I0fULfZewybposA4bOPrRWrU3TaTHlmW4uGNpylDRPuv8yh8BvhbJ4e8Nz3niixtpJ75lljimhBeDA6HPeu9+J7CH4d6g2PlRVOB6A1APiMuB/xT2rf9+a8r+JHxF8TXlxcaVNYR2WjXg2xfaIysrY606tam6ckn0Iy/LMXDGUpShopLqu/qeJ/EzxTbeMPGTanZQyQxrbxwbZDzlBgmuRrZm0ItPI3222GWJwX96Z/YJ/5/rb/AL7rRV6dtzkqZVjHN+5+K/zPsTQfHGn+E/hp4Mhv7e5lafQ7RlMKqQAIUHOSKn/4XLoX/PjqP/fCf/F1wPiePyvA/gSPcG2aDbruHQ4jTmuVrvhCMopn53mOaYrDYqdGLVl5HtH/AAuXQv8Anx1H/vhP/i6P+Fy6F/z46j/3wn/xdeL0VXsonD/bmM7r7j2j/hcuhf8APjqP/fCf/F1ynj/x3p3ivS7W2sLe6ieGbzGMyqARtI7E+tcFRTVOKd0Y1s2xVem6c2rPyPVPh38RMeVouvzccJbXTnp6Ix/kfwr1avlWvavhVr2rappctrqELy21qAsN4x6/7B9cDv279qzqQtqj2cnzKU2sNV17P/P/ADOyvf8AXD/dqvT9SulhuVVoyxKA5DY7n2qn9vT/AJ4t/wB/P/rVgfSNq5HrOnf2rpM1nmAeZtI+0QCaM4YHDIeo49QfQg1D4f0f+w9L+yeZG5MskpEUXlxoXYttRMnaoz0yatfb0/54t/38/wDrUfb0/wCeLf8Afz/61AuZFmnx9H/3ap/b0/54t/38/wDrVJFfIwk/csMIT9//AOtQO6JaKrfb0/54t/38/wDrUfb0/wCeLf8Afz/61ArowrHwdHYeKpNXimhCtNLPtW32zM0gAZWk3fMgPIXA5xzxXTVW+3p/zxb/AL+f/Wo+3p/zxb/v5/8AWo6WDmV7lmnyf6z8B/Kqf29P+eLf9/P/AK1STXyLLgwseB/H7fSgd0S1Q1nTP7XsVtHl8uIzRySjbu8xUcMU69DjB9jU329P+eLf9/P/AK1H29P+eLf9/P8A61AuZFmiq329P+eLf9/P/rUfb0/54t/38/8ArUBdFwf6lv8AeH9aZUS3yG3dvJbhlGN/19vao/t6f88W/wC/n/1qB3RZIyCOlc34W8Jf8I3PPJ9phl82JIz5Nv5RlKlj5sh3HfId3LcZx0rb+3p/zxb/AL+f/Wo+3p/zxb/v5/8AWoFzK1izTk++v1qp9vT/AJ4t/wB/P/rU6O+QyqPJYZI/j/8ArUDujdooooNQooooAK4v4pEDwvbZ/wCf1f8A0B67SuJ+Khx4Wtv+v1f/AEB6APKMbuSeM0pPzAUi5z6jvSqByCeR0oAQ5ZiCcCuY8UQLHPG8Y+Z87j6107E8A/jXJ+IjcNqBEqnyv+WZrswaftSZbGLtBJrtdEt3g0tUlXaeTj2ri+FYZOBn867+zliuLJGgYOu0DI9a68e3yJExLOBs9qadp60n3uvQCgrleua8g0FOOOe1RXFrDdReVcoGXPANSKMc5p2c9eDTTad0BFDHHBEIYhtVeABT9vBz1oP3+FpSPu54pXvqwMLxRK8cMSRthX+8PWuXzgZ61ueJ7wPdLbhceV39c1g87ducV72FhairmUtz0K2YtaRHsUAH5VKwwtQ2wxaQj/YHH4VJtwc5zXhS3ZqPx93nFBwM56UpJA6fjTd3y4JpAcn4g1WSa4e1X5Y4zg/7XvWbZadc34JgTKqeTT9ZGNWuR1G/rXVaEP8AiUwHbgY5Ne1Kp9XoJwW5nuyqPDsBs/K6S4/1mK5u4tWsbkxS8OprvzyeK4vxDltXk+gxWODrTnNxkxySsdZYzxXNnG8DZ+UL+IqzgYx0NY3ho40lcjnea1wc8gc159WKjUaRS2FYcgg5NB5XGOc5oB69zQOMkisxmD4muxHbpbMv+s+bOemK5y1t5Lq6WOEZJrT8SpIt4hkfcrA7Bj7oqPw8MavGO2DzXt0f3eHvEzerLv8AwiwYZW4OcdMVg3VtLaXDRyAqy9PevQxtGNowa5zxUqbYMYzk5PrXPhcTOVTllrccoqxD4cvykxt5ZSQ3+rX0NdQ2Sa89imkhnV4jtZDkGu/tnZ7WN5DyyjJqMdT5ZKa6hFncfC0f8VVcHH/Lk3/oaVR1r4YeIr/X9Qu4FtfKuLmSVN02DtZiR296vfC0EeKbk5yPsTf+hpXrFcMZOOxy4vBUsZFRqX07Hhn/AAqXxN/dtP8Av/8A/Wo/4VL4m/u2n/f/AP8ArV7nRV+1kef/AGDhPP7/APgHhn/CpfE3920/7/8A/wBaj/hUvib+7af9/wD/AOtXudFHtZB/YOE8/v8A+AfMes6RdaFq02nX4QXEO3dsbI5UMOfoRXpvw7+Hf2fyta1+H97w1tbOPuejsPX0Hb69OkXwRbXHju88RaltmyY/ssOMhSsajc3qcg4H4/Tq6cql1ZGOByeNOtKrU2TfKvno2cX8Uf8AkWLbt/pi/wDoD15OBjOORXq/xT/5Fa3/AOvxf/QHryjORjHFYn0YHlsjpXD6xdrd6g77dpX5cfSu0uVdrdkibbJj5Wx0rgJl/wBJcMckMcn15r0sBFczkRIvaXpEl+jM7bI+ze9Wb3w29tamWGQy46jGMVqeGsHSzuH8ZrYIUqQfu+lKriqkKrS2QKKsecRs8TgqxUg5z6V3GjXv2yxRt++RRiQn1rktSCrqdxt6bzxV/wAN3Eq3/kq2I3BJGK6sVBVKXN21Ji7M6wfe6V6PDod5r/wctNP08IZ2kZhvbaMCZiea8568Zwe1e0/D8EeBdPB6/vP/AEa1eKnZ3HVpxq03Tls9Dy//AIVL4m/u2n/f/wD+tR/wqXxN/dtP+/8A/wDWr3OitPayPG/sHCef3/8AAPDP+FS+Jv7tp/3/AP8A61H/AAqXxN/dtP8Av/8A/Wr3Oij2sg/sHCef3/8AAPA9R+GniDS9NnvrpbbybdDI+2bJwPbFYWhaFe+IdUjsdOj3SNyzH7sa92Y9hX0R4h0+XVfDt9YW5VZbmFo1LHgE9zVbwx4YsvC2li1s13SNgzTsPmlb19h6DtVe1djjnkUHXioXULa/5IPDHhiy8LaWLWzXdI2DNOw+aVvX2HoO1fDXxH/5Kn4r/wCw1ef+j3r7/r4A+I//ACVPxX/2Grz/ANHvWLdz6anTjTgoQVkjm6+xv2dfB6eHvh7HqguPObWQtztK48rAIxmvj61eGO8he5jMsKuDIgOCy55Ffe3w0uLC7+G2iT6RaNZ2UlsDDA7bjGuTxnvSLMz4ofFCw+G+kpLMguL6fmC2PG8Z55rzfw7+1HbalrtvaaxpKWFpI2HuBIW2fhWX+1gpa/0DAJ/dSdB71858qe4NAH6OwT29/ZpNAyzQyqGBHIIIr4//AGgvAH/CK+MDqWm2C2ukXoAjZT96XBL8fjXu/wCz1JJL8HrBpnd286QZcknrVn45+HdO1v4X6ldahEZJdNhae2IbG1+Bn34oA+Iq+rf2ZYHufgxrkEWN8uqXCLk9zbwgV8pV9bfsqf8AJLNS/wCw1L/6IgoE1dWZD/wqXxN/dtP+/wD/APWo/wCFS+Jv7tp/3/8A/rV7nRWvtZHh/wBg4Tz+/wD4B4Z/wqXxN/dtP+//AP8AWo/4VL4m/u2n/f8A/wDrV7nRR7WQf2DhPP7/APgHhn/CpfE3920/7/8A/wBauQFjcPqP2GKJpbjzPKCRjJZs4wK+oq5Twn4IttAurjUbrbPqNxI7b8cQqSTtX39T+H1pVXbU48RkUHOEaN7dWyv4D8Bw+GbYXl8Fl1SRfmbqIQf4V9/U/wBOuT+0H/yQnxD/ANu3/pTFXpNeefHm2e7+CWvQRFQzfZ8F2wOLmI9awlL7TPpcLhY04xoUV5Lzf+Z8P103gjR7nxBqc2k2O37RdoI495wMk9zWf/wjl5/z0tv+/wAK7L4W27+H/HFnfXpWSKORSRAfMb8AK461am4WUu35n0+W5ZjYYpSlSaVpdP7rPrrwP4XtfCXhS0022s4LWVY1NwIFwHkxy3vXB/F34gaHaPa6F5xmvI50unEXzBFjbLA+h9q6n/haeh/8+mq/+AD18r+I7d774k65qcJVYLqSQorttcZHdeoorVqbptKQZZlmNhjacpUmkn2PqfwL8VfDnj9po9GmeOWEgeVONrNx1A71X+L+j6ffeBrq9urOKa7tEzbysuWjJ/untXyH4bttZ8P+ILXUNNvo7aaOQAvFMN23IyPxFfUHjD4gaZqvgeayig1ATuiZeW0ZVyMZ5NOrWpunJKXQjL8rxsMZSlKk0lJdPM+P9Ss7iyv5YryCSCTO7bIpU4PQ1Vr2X4zaXp2vX9lreky3aXc0SQzRXkPkxgInBVj1NeYf8I5ef89Lb/v8K0Velb4jlqZVjnN/un9x9U/8Ibqvif4deB5dLEJWDQbVX8yTbyYkNUP+FS+Jv7tp/wB//wD61eo/D6Mw/DLwvE2CyaPaKSDkZEK10VdcajS0Pk8Tk+HrVpTqXu99Twz/AIVL4m/u2n/f/wD+tR/wqXxN/dtP+/8A/wDWr3Oin7WRh/YOE8/v/wCAeGf8Kl8Tf3bT/v8A/wD1qyPEPgvVvDFrFcaoIRHK+xfLk3HOM/0r6KrnPGHhb/hK49PtpJfKt4bjzZiPvFdpGB7nPXtTVV31OfEZHRVJujdy6ankXgnwTc+Kr3zJd0OnRN+9mxyx/ur7+/avebGxttNsorSxhWGCFdqIo4AosbG202yitLGFYYIV2oijgCp6ic3Jnp5fl8MHCy1k93/XQw9a/wCP1P8ArmP5mvNvEHiDU9G8T3TxypJb7LeGNJMLHBvErF23SIpJMYXkjqMHsfSda/4/U/65j+ZrOIyMHkVmdcnqzzq6+IGoybYbeO2gmmtz8vDtFJ9maYMPn+YZA6KV5+9nipv+FgTpp8aQvY3V784IDHBAVCrkAkgNvz/Kuy1bUY9I06S9kiaXayIqrgFmZgqjJ4Ayw5PSk0jU49WtHnSPynjleCVCQ210YqRkcEZql1JeyMDR/FOo3fiuTSLy3twImkjcxsqsCgH7zaZC21ieAVGAR8xrs4Okv/XM/wAxUOOc96mg6S/9cz/MUugdTn/Fsl3HoB+wXP2aWS5giMgUkhXlVTjBBBweuf8AGuXg+IN+0M3m29tAQyom90YxMXK7HHm/ewpOXMfII+vodRylI4nd1LKo3EKpYnHoByTSC+ljgNM8fXMl9DNqVxZw2l1DE3lvhfJJjmJO7dyC0YH44z6q3jzVv7Oivfs9lHDNLHEGbgRk26zEsXkReS20DI9eelbbeNIP7Piul065IKTzTRsVVoYoZNjsRnk552j3rpRhlB6g8in3f9f10HdLoV9NunvtKtbqaLyZJ4UkaPcG2EgEjI6/Wr9z/r/+Ar/6CKiqW5/1/wDwFf8A0EU3uStjzS48W6vo2pXit5d35t3OY/NZY1CxsqrCm6QAMd2cjJ/2TS3Xju/nvJ7e2mtLeOOZCJigOxFukicMC+eQxySqYwcZ616IQD1FZsurxQ+II9L+zT75bd7jzhH8nylQVB/ib5h0zSWlvIpu99Dmrbxxd6lcWNrpwsjPcJB52SXELssxdCARyPKAwTnnmr3g7xTeeI5LgXdtFCqRpIBG6FoyxYGNgHY5GOpCnr8oxW1ouqx6zp7XcVvLbjzpIjHMu1wUcqSR2zjOOtX8Y6UbEvy/qxMv/HnL/vr/ACauS8cahfabZWM+nu3y3DPJCgO6cJDJIEBBGMlAO/8AQ9av/HnL/vr/ACaoqTHex5xc/Ee+t9Je4MVk0qeY6srIyzKiIxAxMVBy+Pvs3QhTyBYi8c3FlJqEV9cWcsiTSfZ1b5G4lVRHjPJCsD64INdnql7Hpelz3rwSzrAhfy4U3M30H9TwO9ZzeI9tzp4fTphBemNUnLLw7qWAC5ycAckdPzxS3/rqD+H+uhzsnjnV4ZLPzLS0YXWZEAYJvXzfL8sF5Bl+M5Abqo2969Ch/wBfH/vD+dR4z17VJD/r4/8AeH86XSwbs6miiig6QooooAK4v4o/8ivb8Z/0xf8A0B67Suf8Z6DdeItGitLKSGORLgSEzEgYCsOwPPIoA8S69OOelGAzHrmu2Hws1nvdWH/fx/8A4ig/C3Wv4bqwB/66P/8AEUAcSSBkDrXO+KulvnjrXq//AAq3W/8An50/P/XR/wD4iq178HtWvoDHNc6f7HzHyP8AxytqE1TqKTE9UeGAZbk59K7Pw6CNFX/eNb5+Afibd8t9pOM/89pf/jdbWj/BvXdOhIlvrB3bqBLIVH/jld+LrU6lO0WTFNM5nGU46Uu0hMdDmu1Hws1oN/x9WGP+uj//ABFH/Crdc/5+tP8Ab94//wARXlFnFjgY3Cm7iBjIrth8LNbJ+a60/wDCR/8A4ig/CvWs8XVh+Mj/APxFAHFK3I+lKp3ZyeTXaH4Wa2V5utPz/wBdH/8AiKb/AMKr1z/n60//AL+P/wDEUAeVeK0UGA4AbJyfWucUBuT1Fe7S/CXV5v8AXT6c+Om53OP/ABysqb4GatcX8ksl1pyRFQFVJXBB/wC+K9PD4qEIcsuhDjdnPwf8esQ/2B/KpDtPYjHvXaRfCrWYowgurD5RgfvH/wDiKX/hVmt8/wClaf8A9/H/APiK817lnGA8fLnn1pMAfe69q7T/AIVZrQXAurD/AL+P/wDEUp+FutnH+laf+Mj/APxFIDyDxHY+VcieJGw/MjE8A1nWWqXVgjJbuMN2cZxXtsnwo1iZSstxp7AnoZH/APiKw9S+BWuXNx5lnd6YmfvBpZB+WEr06GJg4+zqENPdHm1zr17PbtE7qFbqVGDWYzM7/Mxb6nJr0/8A4UJ4o/5/9I/7/S//ABur+n/AnV7dklurvT3kU5IWWQqf/HK6Pb0Kcfd/AVmzk9Ajli0lFlQo24kAjqK1CuBx0712g+FmtAYF1YYxx+8fj/xygfCzWgf+Puwx/wBdH/8AiK8ecueTl3NDiweCOMYo3cDPpXaD4W62CcXWn495H/8AiKP+FW63jm60/P8A10f/AOIqAPNPEFh9rtRIiM8qHC7fSuUZZIJChzG68EZwRXu//CrdbAwLqw/7+P8A/EVgat8DNfvLozWt7piluX3yyD+SV6OFxCj7k9iJLqeXWmsXlkp8qTJP9/5qjvL2e9k82cgsewGAPwr0hfgJ4oAw1/pB/wC20v8A8bq7pnwK1u3uPMvbzTJAv3Qksh/PKV1uvh4tzVrk2Z5loumrqV1skbCLy4zyRXZxRiJBGPuqMDNdpH8JdWhYmKXTUJ/uu4/9kqVvhZrRHF1Yf9/H/wDiK8zEV3WlfoaJWD4W5/4Si454+xt/6Gler1xHgvwZqPh3Wpbu+mtZI3tzEBC7E5LKe6jjg129cwwooooAKKKKACiiigDivin/AMivbf8AX4v/AKA9eU5zt6Zr2rxpoF14j0WK0spIY5EuBKTMxAwFYdgfWuI/4VbrmB/pWn/9/H/+IoA4vdnp1rkNa0xre8eWCJ/KxuZu2e9eyf8ACrNayP8ASrDH/XR//iKjuPhPrNzbvC91YbXGD+8f/wCIrehWdKVxNXPCvOljUbJGAz0ViKvrr9+IfIDIU24zt5/Ou+k+AXibzCY7/SdmeAZpen/fug/ATxOR/wAf+kf9/pf/AI3XrSq4eW7RnZnl7sWb5iTzyfWuo0DSUjhW9LEuw+TB6CvQrD4K6naWoWSfTZJDyxLuRn2+StCP4VazGoVbjT1UdAJH/wDiK48Ri1NckCoxOLHOCete1eAP+RH0/P8A00/9GNXFH4Wa3uyLqw/7+P8A/EV6F4X0qfRPDdrp920bzQ79zRElTl2YYyB2NecWa1FFFABRRRQAUUUUAFfAHxH/AOSp+K/+w1ef+j3r7/r5g8Wfs1eMde8aa3q9nqWhpb6hqE91Ess8wdVeRmAYCIjODzgmgD57r6h/Z9+KVmnhNtG8UatZ2n2KRLewjYbWZCP1OTXF/wDDKnjf/oK+H/8AwIn/APjNS2v7Lnjq0vIbmPVPDxeGRZFzcT9Qc/8APGgD6oudPsdQ2NeWdvc4HymaJXwPbIrgdd+BHgfxDrsmrX1ncR3EhBK283lx8eigYrtfD0erw6DbR+ImtX1FUxM1oWMZPtkA/pWlQBXsbC202yitLGFIYYlCqqKAOB7d68C/aL+KlzpfneCtMh2PPCDdyyKGDxsMgL3ByOtdX8UvA/xH8Y6pGnhrWtL03TYPmj3XE0crEjndtjIx+NeWX/7M3xE1W6NzqWvaJdTkBTJLdzs2B0GfJoA8Jr62/ZU/5JZqX/Yal/8AREFebf8ADKnjf/oK+H//AAIn/wDjNe5fBT4f6r8OPBd3pGuXFnPcTag90rWbsyBTHGoBLKpzlD29KAPRKKKKACiiigAooooAK82/aD/5IT4h/wC3b/0pir0muJ+MXh7VPFXwn1nRtBtvtWoXPkeVD5ipu2zxufmYgD5VJ5PagD4Sya6v4fa4/hzXW1hIVnazUSiNjgNg9K3v+GfPid/0LP8A5P23/wAcrR0v4DfEi2t71ZvDm0yw7U/062OTn/rpWNZNwsvL8z0ctnGGKUpuytL/ANJZ9Y+G9etfEGh2V4kluJriBZWhjkDFMjp61518VPh34bTS31Ky02K21K+u44pbtB8x3nBNcF8Ifh/8TPAXjFL7UPDDS2syeTIW1G3IiUnlsCQk49BXuXj7R77WtEtrfTIPPljvYZWXeq4VWyTyRRWTdNpBlk4wxtOU3ZJ9Tzfwv+zNomh69BqGoalJqkUXP2aaMBSex49K9A+Jix2/w7vsKFSNV6DoAa62VnS3dok8yRVJVM43HHAzXz94n0341+KNauoZNEa10Oc4+yi+tmAH/fzNOqm6ckuxGXzUMZSlJ2SkvzPOfjV8T7Pxqmm6RpMINppoVhcEEM77NrAj2rybJr0yb9n74mvPIy+GcgsSP9PtvX/rpTP+GfPid/0LP/k/bf8AxytFsclR3mz62+HH/JLPCn/YFs//AEQldJWJ4K0+60jwD4f03UIvJu7PTLaCePcG2OkSqwyCQcEHkHFbdMgKKKKACiiigAooooAw9a/4/U/65j+ZrPrdvo4nnBkjVzt6kn+hqr5EH/PBfzb/ABoMZRuzC1GxTUtPms5XdElXaWQKSPwYEH6EEGotH0i20TTxZ2e4pvZyzBQWZjknCgAfQAACui8iD/ngv5t/jR5EH/PBfzb/ABoJ5WZlSwdJf+uZ/mKveRB/zwX82/xp8cMAD4hUfLzyf8aBqJk0Vp+RB/zwX82/xo8iD/ngv5t/jQLlZxlx4Qsp4BELm7iXE6SbGTMsc0m90bKnjPcYIHet8AAADoK1PIg/54L+bf40eRB/zwX82/xoHytmZUtz/r/+Ar/6CKveRB/zwX82/wAafLDCZOYVJwO59PrQHKZNVZbCKXVLe/ZnEtvHJGgBG0hypOf++B+tbvkQf88F/Nv8aPIg/wCeC/m3+NAuVmFYWEWnQyRwM7LJNJMd5B+Z2LHp2yatVp+RB/zwX82/xo8iD/ngv5t/jQHKyiv/AB5yf76/yaoq1hDB5LjyVxuHGT7+9M8iD/ngv5t/jQPlMe5gW6tZbeQkJKhRivUAjHFZEXhiODWLbUI9Svc20CW8cDCJowijBxlNwLdyCM4HYCuv8iD/AJ4L+bf40eRB/wA8F/Nv8aNg5WZlPh/18f8AvD+daHkQf88F/Nv8ackEAkXEKg5Hdv8AGgOVmvRRRQbhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAUb3/XD/drznxINdsfFV3qGli6aORLaAyCIssMZErOUxFIc7ljB+Vvvc44I9Gvf9cP92q9IjueZ3WteMbpktvJvInktTHN5FqyqrG1Zw6ExZB8zaMlxg5XZ3qf+3/E406O0s4dQa6XeDLNpr52bE8tiSgBbJbI65ByBiuw1nVrjTLnTY4bPzo7u6WCWUyBRED046kn8uDk9AYNL1u8ufEd5pWoWscDwxCeMozcqWIAywAbgAkrkAtg89aWt/P8ATUT6eX/DGTot/wCJj4wlstR3vZRtIhaSFlDIoGyQMIgm5j1Ac9SAoxXax9H/AN2mU+Po/wDu0uiDqc/4xs7jUPDptrVrhWkubdX+zqCxjMyb8gg8bck8dBzxmuSh17xgsE4ure4jy6piK1cm3O8jCkwY27R1Al7HoePSqbIzJE7IjSMqkhFIBY+gzgfnS2DyPONL1vxLb38F7qsWqGO4hiE8IsHdEIjmGVAjyCXEef8AeHABFK+reNP7Liu3+0xmSWOORPsZDRL9mVywAikY5lJU/KQMY4PNa03jxrbRbGe4tIkvrq8ML23n8QxrceSzlu+OPqT6AkdlT7sLlXS5LqbSLSTUUVLt4EadUBADlRuAB5HPrV2T/WfgP5Uynyf6z8B/Km9XcS2PMLqTxTpGqXraYly4ury4k82aBm3srIIkOyFj5e3d/d9nGKW61bxTe31zFjVILVZkfMVowaMJdxqVH7rkGMscbpMgZ4GRXpdYep69dWGuLZJpzSwmxnullVstI8e35FQZJ+9/LGanZLy/RFfE3br/AJnPWuteJ9TubC2jS8tMpAt5M2nlQsm2YygF1xjKRjIyBuGOtaHgnUvEV/Lc/wDCQxGMCNG2tE6eXKS25FJjQFQAOhf/AHjkVp+GNan1mxla+SOG6hcLLAsckbR5UMARIAe/XGK2qrZ6k3vsPH+pb/eH9a5Lx7b6nNY6e+jxzTTQXLTeQihkkKwyMgfg/LvCDtyR3xXWj/Ut/vD+tMqWO9jzG68ReMotHdoYruWcGV4XWycmQrGhCNm3B5YtgBFyARvGMm1HrPiLTZdRiMep3DSzym28yxeQKxmXADBMbPLORk4688YHb6xez6do11eWtr9rmhjLrDvCBsepPQdz1PoCeK56DxrJca7a2Qto0iZYBNI6yYDypvADBSo7ABiMk9uM1H4vw+//AIYH8P8AXT/hzJl1TxrDLZEea4nzIQ9owAbzdvlMEiYhQgByShO4ndgYr0ZPvr9abTk++v1pdLBu7mpRRRQaBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAUb3/XD/dqvWo0aOcsoJ96TyIv7i/lQS0Yt1ZQXvk/aY9/kyrNH8xG116HiqthoOnaZeSXVnC6yupXLzO4RS24qoYkICecLgdPQV0nkRf3F/KjyIv7i/lQHKzMp8fR/wDdrQ8iL+4v5UCGMdEH5UBymZRWn5EX9xfyo8iL+4v5UC5Tl5/C+i3Vottc6bBNEspmUSDcQxk8wkMefv8AOM47dOK1elafkRf3F/KjyIv7i/lQHKZlPk/1n4D+VaHkRf3F/Kgwxnqg/KgfKZlVLvS7O/lEl3CJGWGSAEsR8kmN4wD32j8q3vIi/uL+VHkRf3F/KgLM5/TdIs9JjlWyWTMzB5HmmeV3IAAyzkk4AA61drT8iL+4v5UeRF/cX8qBcpnj/Ut/vD+tMrT8mPGNgx9KPIi/uL+VA+UyZoUuLeSGZd0cilHXOMgjBrN/4RnShewXQt2EkAQIBM4Q7BhCyZ2sVB4JBP5Cuo8iL+4v5UeRF/cX8qA5WZlOT76/WtHyIv7i/lR5MY6Iv5UByj6KKKCgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP/2Q=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid based classification\n",
    "\n",
    "In deze notebook zullen we gebruik maken van grid based classification. Het idee van grid based classification is om de binaire versie van een afbeelding te verdelen in stukken (rooster over de afbeelding). Per stuk zullen we het aantal witte pixels optellen. Deze data wordt dan gebruikt om de afbeelding te classificeren. Dit zou in een grid van 4x4 betekenen dat we 16 features hebben per afbeelding. hieronder een voorbeeld:\n",
    "\n",
    "![grid_voorbeeld.JPG](attachment:grid_voorbeeld.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uitvoering\n",
    "\n",
    "Om dit probleem op te pakken zullen we de workflow hanteren die voornamelijk worden gebruikt binnen een Machine learning probleem (Data Science lifecycle). De workflow is te verdelen in de volgende stappen:\n",
    "\n",
    "1. Data verzamelen\n",
    "2. Data analyseren\n",
    "3. Preprocessen\n",
    "4. Feature engineering\n",
    "5. Trainen / Testen / Evalueren\n",
    "\n",
    "Allereerst beginnen we met het importeren van de libraries die we nodig zullen hebben in onze code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io, transform, color, filters, data, morphology, measure\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    images_name = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = io.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            images_name.append(filename[0:4])\n",
    "    \n",
    "    images_df = pd.DataFrame({\"name\": images_name,\n",
    "                             \"image\": images})\n",
    "    return images_df\n",
    "\n",
    "def display(np_image):\n",
    "    \"\"\"\n",
    "    This is a display function that we have added to show numpy images at full size\n",
    "    If you pass in an image with 3 channels, it will be displayed in RGB\n",
    "    If you passn in an image with 1 channel, it will be displayed in grayscale\n",
    "    \"\"\"\n",
    "    dpi = matplotlib.rcParams['figure.dpi']\n",
    "    if len(np_image.shape) == 3:\n",
    "        height, width, depth = np_image.shape\n",
    "    else:\n",
    "        height, width = np_image.shape\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Display the image in either RGB or grayscale (depending on the amount of dimensions)\n",
    "    if (len(np_image.shape) >= 3):\n",
    "        ax.imshow(np_image)\n",
    "    else:\n",
    "        ax.imshow(np_image, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hierboven gedefineerde functies zijn geleverd door Saxion zelf. Die zullen gebruikt worden voor het inladen van de data en het tonen van de afbeeldingen.\n",
    "\n",
    "Hieronden wordt de data ingeladen. Voor de zekerheid zullen we de data ook printen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>[[[241, 241, 241], [242, 242, 242], [244, 244,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1027</td>\n",
       "      <td>[[[206, 206, 206], [211, 211, 211], [218, 218,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1029</td>\n",
       "      <td>[[[82, 82, 82], [83, 83, 83], [84, 84, 84], [8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1036</td>\n",
       "      <td>[[[241, 241, 241], [246, 246, 246], [243, 243,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1053</td>\n",
       "      <td>[[[241, 241, 241], [243, 243, 243], [243, 243,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>5264</td>\n",
       "      <td>[[[228, 228, 228], [227, 227, 227], [224, 224,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>5339</td>\n",
       "      <td>[[[70, 70, 70], [71, 71, 71], [67, 67, 67], [7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>5377</td>\n",
       "      <td>[[[243, 243, 243], [236, 236, 236], [243, 243,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>5382</td>\n",
       "      <td>[[[214, 214, 214], [222, 222, 222], [206, 206,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>5384</td>\n",
       "      <td>[[[88, 88, 88], [94, 94, 94], [91, 91, 91], [8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                                              image\n",
       "0    1000  [[[241, 241, 241], [242, 242, 242], [244, 244,...\n",
       "1    1027  [[[206, 206, 206], [211, 211, 211], [218, 218,...\n",
       "2    1029  [[[82, 82, 82], [83, 83, 83], [84, 84, 84], [8...\n",
       "3    1036  [[[241, 241, 241], [246, 246, 246], [243, 243,...\n",
       "4    1053  [[[241, 241, 241], [243, 243, 243], [243, 243,...\n",
       "..    ...                                                ...\n",
       "235  5264  [[[228, 228, 228], [227, 227, 227], [224, 224,...\n",
       "236  5339  [[[70, 70, 70], [71, 71, 71], [67, 67, 67], [7...\n",
       "237  5377  [[[243, 243, 243], [236, 236, 236], [243, 243,...\n",
       "238  5382  [[[214, 214, 214], [222, 222, 222], [206, 206,...\n",
       "239  5384  [[[88, 88, 88], [94, 94, 94], [91, 91, 91], [8...\n",
       "\n",
       "[240 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_df = load_images_from_folder('../dataset-images/dataset1')\n",
    "all_images_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals hierboven is te zien is de data succesvol geladen. Laten we voor de zekerheid kijken of er toch geen gebreken zijn. Hiervoor zullen we de \"describe()\" functie gebruiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1266</td>\n",
       "      <td>[[[222, 222, 222], [240, 240, 240], [238, 238,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                              image\n",
       "count    240                                                240\n",
       "unique   240                                                240\n",
       "top     1266  [[[222, 222, 222], [240, 240, 240], [238, 238,...\n",
       "freq       1                                                  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor nu lijkt de data in orde dus kunnen we verder gaan.\n",
    "\n",
    "De data is nu verzameld.\n",
    "\n",
    "Om de data te kunnen gebruiken voor de machine learning algoritme zullen we het eerst moeten preprocessen en de features eruit halen.\n",
    "\n",
    "Hieronder zullen we een begin maken met het schrijven van de eerste versie van de preproces pipeline. Hiervoor zullen we de volgende stappen uitvoeren:\n",
    "\n",
    "1. De kleuren van de afbeelding omdraaien, zodat de cijfers wit zijn en de achtergrond zwart.\n",
    "2. De afbeelding omzetten naar een binair formaat (zwart/wit).\n",
    "3. Afbeelding knippen naar 1 cijfer per afbeelding.\n",
    "4. Afbeelding plaatsen in een grid en features eruit halen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De kleuren van de afbeelding omdraaien, zodat de cijfers wit zijn en de achtergrond zwart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image = all_images_df.iloc[0,1]\n",
    "image_name = all_images_df.iloc[0,0]\n",
    "\n",
    "image = image*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De afbeelding omzetten naar een binair formaat (zwart/wit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAAAuCAYAAAD+4SHmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAACSklEQVR4nO2bwW7EIAxEl2r//5fpqdKKAgtm7AEy71SlTWzM4NiEppzzS4hZftgOiDORcIQJCUeYkHCECQlHmJBwhIl375cpJXiv/tn+p5TQj9+Gv3FGjvHb1sqsLznn5g1d4aApB5ZzhgW2FzTm5EUtlJH9OGS8w15VzI3GCNs5Z9oYGXavqHFGVxvTvocPFrGifAgRjveKGE2/Hn6cmGUQPl+dcVJK/0QVOdE1QUcLzauuchUO873fA+XTiGCZnaOnD8dnnN7k1X6OtNu6tirc2v1ldi1ton1wE86IY5GrkfnKqtn3tBNR8x2dcWZWfe86ips3NEuOFk6NmcnzaI97fPrGqP+QzQJcOMyCeEQ0T8oKnkCFw+ygniyI1bFb5g0mnGjReLfUs4wWpbcIHCIcS/BvCeAqjCyNiP3S1/EdN/dEDOaMI9Fw2CXuR7bjq8FjFJNI+ztgEs7IfgVzV/g2ezsCzziMoJ7a0Z2MSTitD3lPWYk7fPFmY+6q2MFjH2RigfD9sQe5Tp74VTwWrOWZrsLpObQy+Tuka+Qxjdl7a7ajM/CRGacG68D4bj5EcY1wXq/vE9I6OReJpw8j40fZdxfODhPTux5lH+1DK66fNlo/jzznG6H/yYmk11mNTtCqqFs+zAjE+zy014IJeVXtUMyW7OATQris+6k1DuKbD3vj0Wof5bP1Oav2w4TTCjDyIJXH33qAtj87dvp5nN0oD4OX1yJso4vQXe2nG/YURDxX7eOIOCQcYULCESYkHGFCwhEmJBxh4hchRkJtFws/hQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 128x32 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gray = color.rgb2gray(image)\n",
    "thresh = filters.threshold_otsu(gray)\n",
    "binary = gray > thresh\n",
    "display(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afbeelding knippen naar 1 cijfer per afbeelding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC4AAAAuCAYAAABXuSs3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA20lEQVR4nO2Yyw7DIAwE2ar//8vkVCmqEoj8WGsVzzUcRhtjA5hzDkU+1QJWWpxNi7ORFf+uPgII75Xn9gtgt/Z2ATXx/5nhmSE08ehBJ1vjFPGMY4Vs4suu4iXzACebeJr4k7R3fXxFJ84mfHOyblShiTOvgWHi7LtriLhF2tNRxnDWeOULgTnx6mcN2XZoEt+lDcBdwzvCE88W/mESv5JjpHzG3FWYkle8a3M+ZfVXvO20E2eTLp61iTvxFRmplyYu8XZ4N1mt8rI1jupztRXZxFucTYuzkRU/AHA9PVknbkApAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 32x32 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC4AAAAuCAYAAABXuSs3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA/UlEQVR4nO2YwQ7EIAhEnc3+/y/T6yarlsIImjKnpiT1FQERiEg7UZ9sAKsKPFoFHq1jwb8zI4DUWikiGNmm4A8XGdqA4fpmhYTKikOOAq4BY8NTwLWhwIRf6nEAfz/Fgk8phwx4N/jM271nlsI8zg4ZF7jG25r3FtE9/gTO43UquAaa5XUa+IoEnMkMzqrH1u8c29YWeLRM4N74ZiRyaHfIVFg/zta7YtwbGmlt7Q6D0hSPM0SLce0ubHl1u4Pq2a27R68qI3h2XpgnWQDckJ5cSavj3gR3zQ5/F48ukSk3IEY5pU1rW+vvwKqajx1OQYve1WTtoAKPVoFH6wIak15ZbYYDZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 32x32 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC4AAAAuCAYAAABXuSs3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAABA0lEQVR4nO2Yyw6DMAwE2ar//8vuCYSqPGC92ETJ3EoJTCxjW4GZbSPyyRZgWeLRLPFohhX/tv4EQNfKvcwCYB+xmVl1cVOcfFn1t2cT/8jEoxuZJMevSis35xbPGhkerSqlnFZt1CVekwBwSCs/yDO0eEu6d00R9bAGpI68VPyptCghFe+lwHljZuZKmWFnlSV+LoG9+xSkR5zN83RxlrnEvZ1PkeeUeGSjqZEScQVzRfwNzCeunLGZtaHT4d37WoSnSkma+djl4q1oKsuo60AIQFHmjiBbWlOriqcfuMWvzuGldR5SIq7ovLJDz13mznmL631vGJgY5mv52SzxaJZ4ND8ZM1tia7pJBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 32x32 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC4AAAAuCAYAAABXuSs3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAABAUlEQVR4nO2YwQ7EIAhEy2b//5fZU5OuUSoMogbn1KapPkcElZj52lGf2QBWHfBoHfBobQv+lT4SkSpXvqVWItI0dzFz8wc3x3vqgWfNcAGfUcQgcGZWQ3sN0gyOAHjAD88q2gXZq6HgN/QIeBN4baqJ6A+whC3f0XBxd7wcgCQEftvKGQpemw2r67kdR7OGxfXcjmvlkdfzOL7KdUYex1dRHvBR21StpizOKQeJEY5b2jTFeG2jFH2Uy7M4Jb0515qZsFCROnuCtZ572nmTeAVnVQ8wKihU0AyD/A/HuLVzdNDhJyDNLYAktxi/YbwXYbO/VfbXWp0CFK0DHq0DHq0f8m1hXm3x4wYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 32x32 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "binary_splitted = [binary[:, :32], binary[:, 32:64], binary[:, 64:96], binary[:, 96:128]]\n",
    "\n",
    "for x in range(0, len(binary_splitted)):\n",
    "    display(binary_splitted[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afbeelding plaatsen in een grid en features eruit halen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  number    1     2     3    4     5     6     7     8     9    10    11  \\\n",
       "0      1  0.0   0.0  45.0  7.0   0.0  29.0  62.0   0.0   7.0  30.0  56.0   \n",
       "1      0  0.0  39.0  27.0  0.0   3.0  33.0  20.0   9.0  13.0  23.0  12.0   \n",
       "2      0  1.0  40.0  32.0  0.0   8.0  33.0  21.0   8.0   9.0  25.0   9.0   \n",
       "3      0  5.0  52.0  41.0  0.0  16.0  20.0  18.0  18.0  20.0  18.0  11.0   \n",
       "\n",
       "     12   13    14    15   16  \n",
       "0   0.0  0.0   0.0  42.0  5.0  \n",
       "1  16.0  3.0  41.0  41.0  4.0  \n",
       "2  17.0  0.0  43.0  41.0  8.0  \n",
       "3  23.0  2.0  44.0  43.0  7.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for x in range(0, len(binary_splitted)):\n",
    "    \n",
    "    \n",
    "    test = binary_splitted[x]\n",
    "    height = 8\n",
    "    width = 8\n",
    "\n",
    "    s_width = 0\n",
    "    s_heigth = 0\n",
    "    #df_tmp = pd.DataFrame({\"number\": [image_name[x]]})\n",
    "    df.loc[x, 'number'] = image_name[x]\n",
    "    for i in range(1, 17):\n",
    "        h = s_heigth+height\n",
    "        w = s_width+width\n",
    "        feat = test[s_heigth:h, s_width:w]\n",
    "        white_pixels = feat[feat==1]\n",
    "        total_white_pixels = len(white_pixels)\n",
    "        df.loc[x, i] = total_white_pixels\n",
    "        if (i%4 == 0):\n",
    "            s_width = 0\n",
    "            s_heigth = s_heigth + height\n",
    "        else:\n",
    "            s_width = s_width + width\n",
    "        #plt.subplot(4,4,i)\n",
    "        #plt.imshow(feat)\n",
    "        #display(feat)\n",
    "    #pd.concat([df, df_tmp])\n",
    "    #print(binary1)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze stappen leveren uiteindelijk de features op die hierboven te zien zijn. Voor deze functie is er gebruik gemaakt van een 4x4 grid. Hierdoor hebben we 16 features tot onze beschikking. Dit kan natuurlijk ook in een andere formaat. Dit zal geanalyseerd moeten worden.\n",
    "\n",
    "Nu het gelukt is om een functie te schrijven die de features uit een afbeelding kan halen door middel van een grid, zullen we dit gebruiken in een grotere formaat. Het idee is om nu een preprocess functie te schrijven die per afbeelding de bovengenoemde stoppen repeteert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "error_counts = 0\n",
    "\n",
    "def initialize_image(image, image_name):\n",
    "    zipcode = image\n",
    "    zipcode = zipcode *-1\n",
    "    gray = color.rgb2gray(zipcode)\n",
    "    thresh = filters.threshold_otsu(gray)\n",
    "    binary = gray > thresh\n",
    "    binary_splitted = [binary[:, :32], binary[:, 32:64], binary[:, 64:96], binary[:, 96:128]]\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for x in range(0, len(binary_splitted)):\n",
    "        \n",
    "        test = binary_splitted[x]\n",
    "        height = 8\n",
    "        width = 8\n",
    "\n",
    "        s_width = 0\n",
    "        s_heigth = 0\n",
    "        #print('lol: ', image_name[x])\n",
    "        df.loc[x, 'number'] = image_name[x]\n",
    "\n",
    "        for i in range(1, 17):\n",
    "            h = s_heigth+height\n",
    "            w = s_width+width\n",
    "            feat = test[s_heigth:h, s_width:w]\n",
    "            white_pixels = feat[feat==1]\n",
    "            total_white_pixels = len(white_pixels)\n",
    "            df.loc[x, i] = total_white_pixels\n",
    "            if (i%4 == 0):\n",
    "                s_width = 0\n",
    "                s_heigth = s_heigth + height\n",
    "            else:\n",
    "                s_width = s_width + width\n",
    "            #plt.subplot(4,4,i)\n",
    "            #plt.imshow(feat)\n",
    "            #display(feat)\n",
    "\n",
    "        #pd.concat([df, df_tmp])\n",
    "        \n",
    "    return df\n",
    "    #display(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit betekent dat we nog niet klaar zijn. We moeten er namelijk voor zorgen dat de data goed leesbaar is voor het algoritme. De data is al in een nummer formaat, dus het is al geschikt voor het algoritme. Alleen zijn er nog wel wat verschillen in groottes tussen de data. We willen dus eigenlijk de data gaan normaliseren zodat de algoritme hiermee beter om kan gaan. Hiervoor zullen we twee bekende functies gebruiken:\n",
    "\n",
    "- MinMaxScaler\n",
    "- StandarScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     1     2     3     4     5     6     7     8     9    10    11  \\\n",
       "0        1   0.0   0.0  45.0   7.0   0.0  29.0  62.0   0.0   7.0  30.0  56.0   \n",
       "1        0   0.0  39.0  27.0   0.0   3.0  33.0  20.0   9.0  13.0  23.0  12.0   \n",
       "2        0   1.0  40.0  32.0   0.0   8.0  33.0  21.0   8.0   9.0  25.0   9.0   \n",
       "3        0   5.0  52.0  41.0   0.0  16.0  20.0  18.0  18.0  20.0  18.0  11.0   \n",
       "4        1   0.0  48.0   0.0   0.0  19.0  58.0   3.0   0.0   0.0  28.0  13.0   \n",
       "..     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "955      2  11.0  57.0  30.0   3.0   7.0  12.0  42.0   2.0   1.0  29.0  21.0   \n",
       "956      5  10.0  59.0  50.0   9.0   9.0  44.0  13.0  12.0   9.0  14.0  37.0   \n",
       "957      3  17.0  47.0  41.0  13.0  10.0  28.0  40.0   9.0   9.0  15.0  47.0   \n",
       "958      8  13.0  42.0  31.0  11.0  18.0  46.0  49.0  17.0  17.0  54.0  45.0   \n",
       "959      4   8.0  19.0  40.0  17.0   7.0  45.0  32.0  34.0  26.0  50.0  60.0   \n",
       "\n",
       "       12    13    14    15    16  \n",
       "0     0.0   0.0   0.0  42.0   5.0  \n",
       "1    16.0   3.0  41.0  41.0   4.0  \n",
       "2    17.0   0.0  43.0  41.0   8.0  \n",
       "3    23.0   2.0  44.0  43.0   7.0  \n",
       "4     0.0   0.0  52.0  59.0  27.0  \n",
       "..    ...   ...   ...   ...   ...  \n",
       "955   3.0   8.0  63.0  50.0  20.0  \n",
       "956   6.0   9.0  49.0  40.0   8.0  \n",
       "957  24.0  12.0  39.0  44.0  12.0  \n",
       "958  21.0   7.0  49.0  46.0  16.0  \n",
       "959  22.0  11.0  12.0  52.0  10.0  \n",
       "\n",
       "[960 rows x 17 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalerA = StandardScaler()\n",
    "scalerB = MinMaxScaler()\n",
    "result = pd.DataFrame()\n",
    "for i in range(0, len(all_images_df.index)):\n",
    "    image_name = all_images_df.iloc[i,0]\n",
    "    image = all_images_df.iloc[i,1]\n",
    "    tmp_result = initialize_image(image, image_name)\n",
    "    result = pd.concat([result, tmp_result])\n",
    "    \n",
    "result.reset_index(inplace=True)\n",
    "result.drop(columns=['index'], inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Hierboven is te zien dat het eruit halen van de features is gelukt. Dit heeft ons uiteindelijk 960 datapunten opgeleverd. Laten we verder met een \"describe\" functie gaan bekijken of er gebreken zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>960</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.00000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.973958</td>\n",
       "      <td>40.127083</td>\n",
       "      <td>36.930208</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.388542</td>\n",
       "      <td>36.345833</td>\n",
       "      <td>34.962500</td>\n",
       "      <td>6.810417</td>\n",
       "      <td>6.153125</td>\n",
       "      <td>31.022917</td>\n",
       "      <td>37.850000</td>\n",
       "      <td>8.566667</td>\n",
       "      <td>3.96250</td>\n",
       "      <td>36.465625</td>\n",
       "      <td>40.151042</td>\n",
       "      <td>9.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.829561</td>\n",
       "      <td>13.274848</td>\n",
       "      <td>13.717176</td>\n",
       "      <td>7.709561</td>\n",
       "      <td>6.242416</td>\n",
       "      <td>15.306639</td>\n",
       "      <td>15.980392</td>\n",
       "      <td>7.340483</td>\n",
       "      <td>6.426977</td>\n",
       "      <td>17.706549</td>\n",
       "      <td>13.952564</td>\n",
       "      <td>7.077681</td>\n",
       "      <td>4.21906</td>\n",
       "      <td>13.516717</td>\n",
       "      <td>13.723210</td>\n",
       "      <td>9.561216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number           1           2           3           4           5  \\\n",
       "count     960  960.000000  960.000000  960.000000  960.000000  960.000000   \n",
       "unique     10         NaN         NaN         NaN         NaN         NaN   \n",
       "top         1         NaN         NaN         NaN         NaN         NaN   \n",
       "freq      138         NaN         NaN         NaN         NaN         NaN   \n",
       "mean      NaN    4.973958   40.127083   36.930208    5.900000    7.388542   \n",
       "std       NaN    4.829561   13.274848   13.717176    7.709561    6.242416   \n",
       "min       NaN    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%       NaN    1.000000   35.000000   29.000000    0.000000    2.000000   \n",
       "50%       NaN    4.000000   43.000000   39.000000    3.000000    6.000000   \n",
       "75%       NaN    8.000000   50.000000   47.000000    8.000000   12.000000   \n",
       "max       NaN   23.000000   62.000000   64.000000   54.000000   31.000000   \n",
       "\n",
       "                 6           7           8           9          10  \\\n",
       "count   960.000000  960.000000  960.000000  960.000000  960.000000   \n",
       "unique         NaN         NaN         NaN         NaN         NaN   \n",
       "top            NaN         NaN         NaN         NaN         NaN   \n",
       "freq           NaN         NaN         NaN         NaN         NaN   \n",
       "mean     36.345833   34.962500    6.810417    6.153125   31.022917   \n",
       "std      15.306639   15.980392    7.340483    6.426977   17.706549   \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      25.000000   24.000000    1.000000    1.000000   15.750000   \n",
       "50%      39.000000   38.000000    5.000000    4.000000   32.000000   \n",
       "75%      48.000000   47.000000   10.000000    9.000000   46.000000   \n",
       "max      64.000000   64.000000   37.000000   39.000000   64.000000   \n",
       "\n",
       "                11          12         13          14          15          16  \n",
       "count   960.000000  960.000000  960.00000  960.000000  960.000000  960.000000  \n",
       "unique         NaN         NaN        NaN         NaN         NaN         NaN  \n",
       "top            NaN         NaN        NaN         NaN         NaN         NaN  \n",
       "freq           NaN         NaN        NaN         NaN         NaN         NaN  \n",
       "mean     37.850000    8.566667    3.96250   36.465625   40.151042    9.015625  \n",
       "std      13.952564    7.077681    4.21906   13.516717   13.723210    9.561216  \n",
       "min       0.000000    0.000000    0.00000    0.000000    0.000000    0.000000  \n",
       "25%      29.000000    3.000000    0.00000   30.750000   35.000000    2.000000  \n",
       "50%      39.000000    7.000000    3.00000   38.000000   43.000000    6.000000  \n",
       "75%      48.000000   13.000000    6.00000   45.250000   49.000000   13.000000  \n",
       "max      64.000000   35.000000   28.00000   64.000000   64.000000   50.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het lijkt erop dat er geen missende velden zijn. Alleen wordt de \"number\" kolom, ook wel de output kolom gezien als een NaN. We zullen de waardes in deze kolom moeten omzetten naar werkelijke nummers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.00000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.942708</td>\n",
       "      <td>4.973958</td>\n",
       "      <td>40.127083</td>\n",
       "      <td>36.930208</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.388542</td>\n",
       "      <td>36.345833</td>\n",
       "      <td>34.962500</td>\n",
       "      <td>6.810417</td>\n",
       "      <td>6.153125</td>\n",
       "      <td>31.022917</td>\n",
       "      <td>37.850000</td>\n",
       "      <td>8.566667</td>\n",
       "      <td>3.96250</td>\n",
       "      <td>36.465625</td>\n",
       "      <td>40.151042</td>\n",
       "      <td>9.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.741914</td>\n",
       "      <td>4.829561</td>\n",
       "      <td>13.274848</td>\n",
       "      <td>13.717176</td>\n",
       "      <td>7.709561</td>\n",
       "      <td>6.242416</td>\n",
       "      <td>15.306639</td>\n",
       "      <td>15.980392</td>\n",
       "      <td>7.340483</td>\n",
       "      <td>6.426977</td>\n",
       "      <td>17.706549</td>\n",
       "      <td>13.952564</td>\n",
       "      <td>7.077681</td>\n",
       "      <td>4.21906</td>\n",
       "      <td>13.516717</td>\n",
       "      <td>13.723210</td>\n",
       "      <td>9.561216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           number           1           2           3           4           5  \\\n",
       "count  960.000000  960.000000  960.000000  960.000000  960.000000  960.000000   \n",
       "mean     3.942708    4.973958   40.127083   36.930208    5.900000    7.388542   \n",
       "std      2.741914    4.829561   13.274848   13.717176    7.709561    6.242416   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      2.000000    1.000000   35.000000   29.000000    0.000000    2.000000   \n",
       "50%      4.000000    4.000000   43.000000   39.000000    3.000000    6.000000   \n",
       "75%      6.000000    8.000000   50.000000   47.000000    8.000000   12.000000   \n",
       "max      9.000000   23.000000   62.000000   64.000000   54.000000   31.000000   \n",
       "\n",
       "                6           7           8           9          10          11  \\\n",
       "count  960.000000  960.000000  960.000000  960.000000  960.000000  960.000000   \n",
       "mean    36.345833   34.962500    6.810417    6.153125   31.022917   37.850000   \n",
       "std     15.306639   15.980392    7.340483    6.426977   17.706549   13.952564   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     25.000000   24.000000    1.000000    1.000000   15.750000   29.000000   \n",
       "50%     39.000000   38.000000    5.000000    4.000000   32.000000   39.000000   \n",
       "75%     48.000000   47.000000   10.000000    9.000000   46.000000   48.000000   \n",
       "max     64.000000   64.000000   37.000000   39.000000   64.000000   64.000000   \n",
       "\n",
       "               12         13          14          15          16  \n",
       "count  960.000000  960.00000  960.000000  960.000000  960.000000  \n",
       "mean     8.566667    3.96250   36.465625   40.151042    9.015625  \n",
       "std      7.077681    4.21906   13.516717   13.723210    9.561216  \n",
       "min      0.000000    0.00000    0.000000    0.000000    0.000000  \n",
       "25%      3.000000    0.00000   30.750000   35.000000    2.000000  \n",
       "50%      7.000000    3.00000   38.000000   43.000000    6.000000  \n",
       "75%     13.000000    6.00000   45.250000   49.000000   13.000000  \n",
       "max     35.000000   28.00000   64.000000   64.000000   50.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"number\"] = pd.to_numeric(result[\"number\"])\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben de kolom omgezet naar nummerieke waardes. Nu kunnen we de data dus ook goed analyseren. Er lijkt binnen de \"number\" kolom ook geen problemen te zijn. De kleinste waarde is een 0 en de grootste waarde is een 9. Dit klopt inderdaad ook aangezien een postcode de nummer 10 niet kan bevatten. Daarnaast kunnen we met de eerste describe functie herleiden, dat de dataset alle nummers tussen de 0-9 bevat, omdat er 10 unieke waardes zijn geconstateerd.\n",
    "\n",
    "Dit betekent dat we door kunnen gaan met de volgende stappen.\n",
    "\n",
    "Allereerst zullen we nu meerdere functies defineren om code duplicatie te voorkomen, dit voorkomt namelijk problemen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "\n",
    "def preprocess(X_train, X_test):\n",
    "    print('-----Start preprocc----------')\n",
    "    global features\n",
    "    X_train[features] = scalerB.fit_transform(X_train[features].to_numpy())\n",
    "    X_test[features] = scalerB.transform(X_test[features].to_numpy())\n",
    "    print('---------Preprocess Done--------')\n",
    "    return X_train, X_test\n",
    "\n",
    "def splitTrainTest(result):\n",
    "    # Split data into 50% train and 50% test subsets\n",
    "    global features\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        result[features], result['number'], test_size=0.3, random_state=0)\n",
    "    \n",
    "    X_train, X_test = preprocess(X_train, X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainen / Testen / Evalueren\n",
    "\n",
    "Inmiddels hebben we de data verzameld. We hebben de data geanalyseerd en de benodigde features eruit gehaald. De preprocessors staan ook klaar. Dit betekent dat we door kunnen gaan met het uitkiezen van de bijpassende algoritme.\n",
    "\n",
    "Omdat er meerdere algoritmes bestaan willen we graag de algoritme kiezen met de hoogste accuracy. Hiervoor zijn de volgende regels belangrijk:\n",
    "\n",
    "- Verschillende parameters gebruiken per algoritme om de hoogst mogelijke accuraatheid te halen.\n",
    "- Algoritme controleren op overfitting en underfitting\n",
    "\n",
    "Voor het testen van de algoritmes met verschillende parameters zullen we gebruik maken van Grid search. Hiermee kunnen we een lijst meegeven van parameters. De functie zal dan deze lijst aflopen en de parameters die de hoogste accuraatheid halen tonen.\n",
    "\n",
    "Om de algoritme te controleren op overfitting en underfitting zullen we gebruik maken van Kfolding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoek optimale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def searchHyperParams_Knn(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'n_neighbors' : [3,5,11,14,19],\n",
    "        'weights' : ['uniform', 'distance'],\n",
    "        'metric' : ['euclidean', 'manhattan', 'chebyshev']\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        KNeighborsClassifier(),\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.8958333333333334\n",
      "best estimator:\n",
      "KNeighborsClassifier(metric='euclidean', weights='distance')\n",
      "best params:\n",
      "{'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_Knn(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volgens de resultaten is de best behaalde accuraatheid score: 0.896 afgerond. Hiervoor worden de volgende parameters gebruikt:\n",
    "- Metric -> euclidean\n",
    "- n_neighbors -> 5\n",
    "- weights -> distance\n",
    "\n",
    "We zullen deze parameters gebruiken om de algoritme te trainen en testen op een gesplitste dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hercontroleren door middel van een pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "def usingPipelines_Knn(result):\n",
    "    knnClassifier = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean')\n",
    "    knnPipe = Pipeline([('scaler', MinMaxScaler()), ('clf', knnClassifier)])\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('-------train model----------')\n",
    "    knnPipe.fit(X_train, y_train)\n",
    "    print('----------score---------')\n",
    "    score = knnPipe.score(X_test, y_test)\n",
    "\n",
    "    print('----------done---------')\n",
    "    print('the score is: {0}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-------train model----------\n",
      "----------score---------\n",
      "----------done---------\n",
      "the score is: 0.90625\n"
     ]
    }
   ],
   "source": [
    "usingPipelines_Knn(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessant. Volgens de pipeline halen we nog steeds een hoge score. Zelfs een hoger score die we door middel van de grid search hebben gekregen. Het is voor alsnog hadden om de algoritme te testen op overfitting en underfitting. Hiervoor zullen we dus kfolding gebruiken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controleren overfitting en underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def fit_score_knn(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean')\n",
    "    neigh.fit(X_train, y_train.to_numpy().reshape(train_samples))\n",
    "\n",
    "    score = neigh.score(X_test, y_test.to_numpy().reshape(test_samples))\n",
    "    return score\n",
    "\n",
    "    # Explanation KneighborsClassifier\n",
    "\n",
    "#we want to test the  model for overfitting and underfitting. for this i will use Kfold.\n",
    "def kfolding_knn(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = fit_score_knn(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 1], score: 0.89062\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 2], score: 0.91667\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 3], score: 0.93750\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 4], score: 0.89583\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 5], score: 0.89062\n"
     ]
    }
   ],
   "source": [
    "kfolding_knn(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De algoritme lijkt alsnog zeer hoge scores te halen die rond de 90% zitten. Dit lijkt erop dat de algoritme geen last heeft van overfitting of underfitting. Doormiddel van kfolding en gridsearch hebben we de optimale algoritme kunnen maken voor het classificeren van de dataset door middel van een KNN classifier.\n",
    "\n",
    "Dezelfde stappen die we hebben uitgevoerd voor de knn classifier zullen we ook gebruiken voor de rest van de classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "0.8472222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "score = gnb.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoek optimale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def searchHyperParams_svc(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'C': [0.1,1, 10, 100],\n",
    "        'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': [1,0.1,0.01,0.001]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        SVC(),\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.9136904761904763\n",
      "best estimator:\n",
      "SVC(C=10, gamma=1)\n",
      "best params:\n",
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_svc(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimale parameters:\n",
    "\n",
    "- C -> 10\n",
    "- gamma -> 1\n",
    "- kernel -> rbf\n",
    "- accuraatheid -> 91.37%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hercontroleren door middel van een pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usingPipelines_svc(result):\n",
    "    classifier = SVC(C=10, gamma=1, kernel='rbf')\n",
    "    svcPipe = Pipeline([('scaler', MinMaxScaler()), ('clf', classifier)])\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('-------train model----------')\n",
    "    svcPipe.fit(X_train, y_train)\n",
    "    print('----------score---------')\n",
    "    score = svcPipe.score(X_test, y_test)\n",
    "\n",
    "    print('----------done---------')\n",
    "    print('the score is: {0}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usingPipelines_svc(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controleren overfitting en underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score_svc(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    classifier = SVC(C=10, gamma=1, kernel='rbf')\n",
    "    classifier.fit(X_train, y_train.to_numpy().reshape(train_samples))\n",
    "\n",
    "    score = classifier.score(X_test, y_test.to_numpy().reshape(test_samples))\n",
    "    return score\n",
    "\n",
    "def kfolding_svc(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = fit_score_svc(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 1], score: 0.92188\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 2], score: 0.90104\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 3], score: 0.95312\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 4], score: 0.90104\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 5], score: 0.95312\n"
     ]
    }
   ],
   "source": [
    "kfolding_svc(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree\n",
    "## Zoek optimale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def searchHyperParams_DT(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter' : ['best', 'random'],\n",
    "        'max_depth': [1,5,10,20,50,100,150,None],\n",
    "        'min_samples_split': np.arange(2,5),\n",
    "        'min_samples_leaf': np.arange(1,5),\n",
    "        'min_weight_fraction_leaf': np.arange(0,0.5)\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        DecisionTreeClassifier(),\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 384 candidates, totalling 1152 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.7217261904761904\n",
      "best estimator:\n",
      "DecisionTreeClassifier()\n",
      "best params:\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_DT(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimale parameters:\n",
    "\n",
    "- Criterion -> gini\n",
    "- max-depth -> None\n",
    "- min_samples_leaf -> 1\n",
    "- min_samples_split -> 2\n",
    "- min_weight_fraction_leaf -> 0.0\n",
    "- splitter -> best\n",
    "- accuraatheid -> 72.17%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hercontroleren door middel van een pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usingPipelines_dt(result):\n",
    "    classifier = DecisionTreeClassifier('criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, \n",
    "                                        'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'splitter': 'best')\n",
    "    dtPipe = Pipeline([('scaler', MinMaxScaler()), ('clf', classifier)])\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('-------train model----------')\n",
    "    dtPipe.fit(X_train, y_train)\n",
    "    print('----------score---------')\n",
    "    score = dtPipe.score(X_test, y_test)\n",
    "\n",
    "    print('----------done---------')\n",
    "    print('the score is: {0}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usingPipelines_dt(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controleren overfitting en underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score_dt(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    classifier = DecisionTreeClassifier('criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, \n",
    "                                        'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'splitter': 'best')\n",
    "    classifier.fit(X_train, y_train.to_numpy().reshape(train_samples))\n",
    "\n",
    "    score = classifier.score(X_test, y_test.to_numpy().reshape(test_samples))\n",
    "    return score\n",
    "\n",
    "def kfolding_dt(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = fit_score_dt(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolding_dt(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "## Zoek optimale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def searchHyperParams_RC(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'bootstrap': [True, False],\n",
    "         'max_depth': [10, 20, 30, 40, None],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_leaf': [1, 2, 4],\n",
    "         'min_samples_split': [2, 5, 10],\n",
    "         'n_estimators': [200, 400, 600, 800]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        RandomForestClassifier(),\n",
    "        grid_params,\n",
    "        verbose = 3,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.9017857142857143\n",
      "best estimator:\n",
      "RandomForestClassifier(bootstrap=False, max_depth=30, max_features='sqrt',\n",
      "                       n_estimators=200)\n",
      "best params:\n",
      "{'bootstrap': False, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_RC(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimale parameters:\n",
    "\n",
    "- bootstrap -> False\n",
    "- max-depth -> 30\n",
    "- max_features -> sqrt\n",
    "- min_samples_leaf -> 1\n",
    "- min_samples_split -> 2\n",
    "- n_estimators -> 20\n",
    "- accuraatheid -> 90.18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hercontroleren door middel van een pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usingPipelines_rf(result):\n",
    "    classifier = RandomForestClassifier('bootstrap': False, 'max_depth': 30, 'max_features': 'sqrt', \n",
    "                                        'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200)\n",
    "    rfPipe = Pipeline([('scaler', MinMaxScaler()), ('clf', classifier)])\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('-------train model----------')\n",
    "    rfPipe.fit(X_train, y_train)\n",
    "    print('----------score---------')\n",
    "    score = rfPipe.score(X_test, y_test)\n",
    "\n",
    "    print('----------done---------')\n",
    "    print('the score is: {0}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usingPipelines_rf(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controleren overfitting en underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score_rf(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    classifier = RandomForestClassifier('bootstrap': False, 'max_depth': 30, 'max_features': 'sqrt', \n",
    "                                        'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200)\n",
    "    classifier.fit(X_train, y_train.to_numpy().reshape(train_samples))\n",
    "\n",
    "    score = classifier.score(X_test, y_test.to_numpy().reshape(test_samples))\n",
    "    return score\n",
    "\n",
    "def kfolding_rf(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = fit_score_rf(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usingPipelines_rf(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultaten\n",
    "\n",
    "Volgens de resultaten is .. de beste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
