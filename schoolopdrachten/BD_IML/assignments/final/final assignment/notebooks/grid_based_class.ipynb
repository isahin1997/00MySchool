{
 "cells": [
  {
   "attachments": {
    "grid_voorbeeld.JPG": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQEAYABgAAD/4RD0RXhpZgAATU0AKgAAAAgABAE7AAIAAAAOAAAISodpAAQAAAABAAAIWJydAAEAAAAcAAAQ0OocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAElicmFoaW0gU2FoaW4AAAWQAwACAAAAFAAAEKaQBAACAAAAFAAAELqSkQACAAAAAzY4AACSkgACAAAAAzY4AADqHAAHAAAIDAAACJoAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIxOjEwOjMxIDIwOjI3OjQ2ADIwMjE6MTA6MzEgMjA6Mjc6NDYAAABJAGIAcgBhAGgAaQBtACAAUwBhAGgAaQBuAAAA/+ELIGh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjEtMTAtMzFUMjA6Mjc6NDYuNjgzPC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPklicmFoaW0gU2FoaW48L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgAvwOkAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+kaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArO1rw9o3iO1W317S7TUYUO5EuoVkCn1GRwfpWjRQBU0zSdP0WxSy0ext7G1TlYbaIRoD64HerdFFABRRRQBT1TSNO1yxNlrNhb39qzBjDcxCRCRyDg8VaiijhhSKFFjjRQqIgwFA6ADsKdRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAFebT7O4vbe8uLSCW6td3kTvGC8O4Ybax5XI4OOtWKKKACiiigAooooAKKKKAGTQxXMDw3EaSxSKVeN1DKwPUEHqKydH8HeG/D11Jc6FoOnafPIMNLbWyRsR6ZAzj2rZooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoqpdahHayhHBJIzxUP9swf3WoJ5kaNFZ39swf3Wo/tmD+61AcyNGis7+2YP7rU5NWhfdhT8oyaA5kX6Kzv7Zg/utR/bMH91qA5kaNFZ39swf3Wo/tmD+61AcyNGis7+2YP7rU59WhjbaVOcA/mKA5kX6Kzv7Zg/utR/bMH91qA5kaNFZ39swf3Wo/tmD+61AcyNGiqA1aExs+04UgH8c/4U3+2YP7rUBzI0aKzv7Zg/utR/bMH91qA5kaNFZ39swf3WpV1eFmChTknFAcyNCiiigoKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDD1r/j9T/rmP5muA1bxTf6V4ontjb/aLfZDFbwx7iWkcSMWbbGzABYj0B+nOR3+tf8fqf9cx/M1iXWl6ffK4vbG2uBJt3+bErbtuducjnGTj0yaRhK13c5S6+ILCEG001g0kDMhmLDy5fIaYK4C4HC4wWDd9uOasP45Nvpcc01hvuCzxtHHKMFkVScEjoS1bNxpGg2avfXOnWMQhj5lNuvyqF2+n935fpxUOl6X4dv7K31Kw0iyEdzCrRv8AZFVimBgYxkcAcew9KpdSdNCrpfiyTUNcOnS6ZNDteSIzLvZBIgG4bigXGcgEHJxyBmuqg6S/9cz/ADFUE0ywi1B7+Oyt0vJBh7hYlEjDjq2M9h+Qq/B0l/65n+YpdA6mF4ovb6w0My6X5YuHnhhVpDgKHkVCeh5+b0/wrEt/H/nwlk0ucb8fZmkEiibLFf8AnnknjOED8fQ46+WGKdNk8aSLuDbXUEZByDz3BAP4VRbw9ozebu0myPnOHk/0dPnYEkE8cnJJ/E0BpYwNK8cS6hqMayWSR2txHG0R8w70Yxyu24EDj91gf5FMX4gSSwRSwaPI6zukcQEjOWYwCZshEYgBWAzg5PoOaviDwxcaoulvotvuGY42ksAI2KDcUViMcbifTlsd61pND0mW0+yy6ZZvb7g3lNApXIUKDjGMhQB9BijzHoT2F2uoabbXiRyRLcRLIEkGGXIzgj1q7c/6/wD4Cv8A6CKgRFjjVI1CIoAVVGAB6AVPc/6//gK/+gim7X0JWxwLeNr7T9Qvoryxe72zzGNLZXby4Yiqn7sZyxLZ+Ygf7QqW68dTtdPbWFhGX85BHJLI+x0+0JC/OzGfn42lgO+CMV00+i6XdMpudOtJikhkUyQK2HPVuR1OBz7VQ1Kw0DS4nuJ9FglNwxDiGyEjPzvOcDpld3PceuKnZK/QrRt2KX/CamVrCO004yzXsUMqK0wUKJBKeTg9BEe3OateGvFI8Rs+LCe1TyknieRHAdGJxyyqM8dtw5GCauadpeiCOO+0zTrOMThZ0lit1UtkHDZxnOGP/fR9atWemWGnvK1hZW9s0xzIYYlQufU4HPU/nVbPUl2exfX/AI85f99f5NXL+MdbutCs7O5tgvlGdjckff8ALSJ5CFGCCTsx/h1HUL/x5y/76/yaqs1tBchRcQxyhCSvmIG2kggkZ9iR9Cal36D06nH3HxCa2sJJptImWWHe8kTeYuY1RWLKDHuPDAZKhQerDIJntvGkqjUPt1mn+jSSGPypPvIJRGM5HDc5raPhnQjAsB0bTzEpJEf2ZNoyADxjvgfkPSqlvaeGdW1O8ii02xnuLGYec5tVOJGAP3scn5Rk+q+1UrXDoZn/AAn0gkiDaNOyyAynymeQiLzPLDfKhAOQxwSBgdcnFdrD/r4/94fzrOk0XS5jAZdNtHNucw7oFPlnOfl4455471ow/wCvj/3h/Ol0DS+h1NFFFB0hRRRQAUUVzHj3V77RdBhudMn8iVrlUZtitldrHGCD3AoA6eivFT8QPEwH/IS/8gR//E04eP8AxLtGdR/8gR//ABNAHtFFeLv4+8ShSV1L/wAgR/8AxNVbr4n67ZKPtOq7CegMEfP/AI7TUXJ2QHuVFfNF18YfGT3Dm11fyov4VNtCf/ZKt6J8WPFlxcvHfa2G3ACMfZYRz+CV1SwlSMOZk8yPoyivFP8AhYHiYnjUv/IEX/xNO/4T7xM3TUsf9sI//ia5Cj2mivFT4/8AEvIGqcj/AKd4/wD4mkHxB8THj+0vx8iL/wCJoA9rorxZvH/iXGRqn/kvH/8AE0Dx/wCJTx/afPr5Ef8A8TQB7TRXg2s/E3xNY2LbNX2TH7n+jxHP/jtc9b/GDxqtwpn1fegPzJ9lhGfx2V008NOpHmiS5JH01RXikXxB8TSRqRqfLKD/AKiL/wCJpw8feJuc6n/5Lx//ABNcxR7TRXiv/CwPEwHOpf8AkCP/AOJo/wCFgeJuP+Jln/thH/8AE0Ae1UV4jd/EfxFaW7TS6qFUdvIi/wDiawm+NXiLaQLpt3Y+VF/8RW1OjUqaxQrpH0XRXzXZ/GbxbEzm81AzqfugQQrt/JKuf8Lq8Q/8/Df9+4v/AIitZYOsna1xcyPoiivCdP8Aib4l1C0E6ajsyxG0wRH/ANlq6fH3ifjGp/8AkvF/8TXNKLi7Mo9porxZfH3ibP8AyE9w/wCveP8A+JoPxA8Sgn/iZZ56eRH/APE1IHtNFeLN8QPEqjH9pc+vkRf/ABNZN/8AF7X7C48r+0DMw+8BDEMf+O1cKcpu0UF7Hv8ARXzWfjL4tF95n9pH7OekX2eHj8dlT3Hxn8TPAy2920UhHyuYYjj8NldDwdZNaE8yPo2ivnqy+MPiW5uYbc3TbnIBfyouv/fFbn/CwPEgOP7Syf8ArhH/APE1hUpzpu0kNO57TRXn3gLxPq+ta9Nb6nd+fEts0gXykXDblGcgDsTXoNZjCiiigAooooAKKKKACiuX8favfaLoMNxplx9nla5WMtsVsqVY4wQe4Fefjx94m2nOpfj5Ef8A8TQB7RRXiw8f+JScDUun/TCPn/x2o5viL4iijeR9UCqgyf3EX/xNG4HttFfOk/xo8R7JI4bxt/IWTyYuPfGyobL4z+KY4yt3fmd+zCCFf5JXUsJWcb2J5kfSNFfODfGbxQbpXW9YQhSGj8mLk+udla+lfFLxJqccji9MQQ45hiOf/HaieHqQjzSWg7pnvFFeLD4geJW6al+PkR//ABNen+ENQudU8K2d5fS+bPJv3vtC5w7AcDA6AVgM2qKKKACiiigAooooAKKK+QPGvxy+IukePvEGm6f4h8m0s9TuYII/sVu2xElZVGTGScADknNAH1/RXxL/AMNB/E7/AKGb/wAkLb/43Utt8ePirdzJFbeIWkd2CKF062OSTgf8s6APtWivHvDvh/4zajptpfar4/hsZJMNLZvo9uzKM9NwUdq7XxfovjLVILNfCXiuLQ5Ix/pDvYRz+ccejA4/CgDrKK4HS/DXxHttJ1OHVPHsF5eTxBbK4GlRILZ88sVAw3HY15f8Udc+LHwx0qyvbnx/DqAu5jEEj0m3j24Gc8oaAPo6iviX/hoP4nf9DN/5IW3/AMbr6I/Z/wDGOu+N/AN7qXie++3XcWpyQJJ5KR4QRRMBhFA6s3OM80AepUUUUAFFFFABRRRQAUUVzfxB8Xf8IJ4E1DxH9i+3/YvK/wBH83yt++VY/vbWxjfnoelAHSUV82/8Nc/9ST/5Vv8A7TVyy/aq+2RXL/8ACG7PIj34/tTO72/1NTKSirs1pUp1p8kFd/5an0NRXzvp37VF1quoQ2Vh4DaaeZgiKuq9Sf8AtjXdn4meLbGaA698Pm061llWI3B1UPtLHA48oUSkoq7CjSnWqKnTV29j02iuD1vxl410/Wbi10r4etqVpG2Irv8AtQR+aPXb5Rx+ZpNY8e+I9F8OWeqXfgwhpM/aof7QH+jenPl/Nn6CnKSirsVKnOrNU4K7bsjvaK8B8QftM6h4Z1U6fq3gPybgIsgU6t1VuQf9T6Vl/wDDXP8A1JP/AJVv/tNMhpp2Z9JUVm+HNX/4SDwrpWs+R9n/ALRsobvyd+/y/MQPt3YGcZxnArSoEFFFFABRRRQAUUUUAYetf8fqf9cx/M1n1tajbJNcKzswOwDge5qp9hh/56P/AN8igwlF3M88iqej6f8A2VotpYeb5v2aJY/M27d2BjOMnFbn2GH/AJ6P/wB8ij7DD/z0f/vkUC5WUKlg6S/9cz/MVa+ww/8APR/++RT4rKJRJh35THQUAoszaKv/AGGH/no//fIo+ww/89H/AO+RQHKzlbbRb6PxPNql5fwXMbApBEbVla3Q4+VW8wjkjJO3J+gAG3V/7DD/AM9H/wC+RR9hh/56P/3yKOlg5WUKluf9f/wFf/QRVr7DD/z0f/vkU+ayiaTJdxwOw9KA5XYzaztb06bVNPNrDLbqjkiWO6tvPjlUgjaVyD1weD2roPsMP/PR/wDvkUfYYf8Ano//AHyKTV9ASa1MbTbM6fpdrZmZ5zbwrGZZPvPgYyfc1aq/9hh/56P/AN8ij7DD/wA9H/75FU3d3Fysqr/x5y/76/yaoq0lsohbuu98FlPQe9M+ww/89H/75FIfKzPYblIyRkYyO1Yfh/wxH4eu7uSC9uJ4rhUVY5iDs255yOpOev8AOus+ww/89H/75FH2GH/no/8A3yKA5WUKfD/r4/8AeH86ufYYf+ej/wDfIp0dlEJFIkfgjsKA5WbdFFFB0BRRRQAVxXxT/wCRWt/+vxf/AEB67WuK+KYz4Xtv+vxf/QHoA8nUY60h/ibooGSfSh5PKRnb5lVSeK4e81CWe7mkhkkWN24UtXTQw7rN9BN2Nq/8SCPdFaDLg8SHkGsO81G41DH2khivTAxVRvXv2pcfn7V7FPD06ey1Mm2xPu/eNPiV5ZkSAEuTxt61HyWOantHkhu42gXdIpyorWWi0A7u3AW2jD53BRmphyc9KiiLNChYYZlGakAKtx6d6+ae5sGMsR7044Awoz6008MPejO33NIBVYbSKavAJ7VHPeQ265ndUOMgHqa42+v5Li+eSGSRY2PA3dK6aOHlVfYTdibxBfG7vSiurxR/dwKyV3BaVmyaUp717kIqEVFGW52Phti2kBnJJ3EcnpWmAOufpWX4ejki0lRICvzk4NaqqG5FeBX/AIsrdzVbBjcOabKfKjZ+oVSaevUg8c1leJZGj0ljG207wOKmnHnmo9wehzepalJqM2SSqD7q+g96m0zQpr+MyBhGo+6WH3qqabam9vY4lwD159q7xEWOPagwB6V6mIrewioUyEr6s5a58LzwwM6zLKw6IoOTWaunXjTNELZy6jJX0ru+uGzVe8ubeyieebhiO3Vqwp4yo/dtdjcUcjpTPHq0CMzL+8xtzxXbn7uQetcVpYa412KSNCwEm4+wrtSFA5557Usd8a9Bx2DIC4B5zQVwaMZAI4FJJKIo3ZhkKCa88o5XXdWlkne1hygRsN6k1mRWt1egtDE0pH3iO1Jezpc38syAgOcgGuo8OwwJp4kibMjcyDPQ17cpLDUU4rUz3ZyUsEkMmy4Qow6g0mMjrwK9CaGB8vJEjHuSK5rxE1q8cX2Ux7tx3BO1Kji/ayUbA42MOGZ7e4SSLhlOQTXoNsS9vGz8kqCa4G1g+03CQpwznAJ7V39uuy3RG6qoBNY4+3u9xwO3+FoA8VXOP+fJv/Q0r1ivJ/hauPFVx6fYm/8AQ0r1ivLLCiiigAooooAKKoW2tWV1rF5pccuLyz2mSJuCVZQwYeo+bH1/Cr9BMZRkrxZxXxTx/wAIvbZ/5/V/9AevKPvN14r1f4p/8ivbZ/5/V/8AQHryfGCaCiveXAs7OScqWCDOBXF3eoXF3cGR2O08YHTFdP4hvEh01o3UkygqMdq5SzSKS7iSY7Y2bDHPQV62CglBzaIlvYedNvfL837M+zGc47VWAwfQ16HGkaW6xr80e3AzzkVFPHZQIDLHEgzjcVFKOPeziHKcCR3zzWz4ZuJRfmAHEbgswI9Kz9R8s6hMYuU3cbelafhq2LXZuV+7H8pHrmuqu06LcuxK3OrAB/Gvafh//wAiLp//AG0/9GtXi5Gcdq9n+H/HgXT8/wDTT/0a1eAanSUUUUAFFFFABRVbUr+HS9Nnvrnd5Nuhd9oycDrT7S7gvrSO6s5VmglXcjochhQTzR5uW+pNXwB8R/8Akqfiv/sNXn/o96+/6+APiP8A8lT8V/8AYavP/R70FGJptk2o6pa2SMEa4mWIMegLHGf1r7e+G/wq0jwF4eS1aGG8vpMNc3DoGDOO6gj5RXyV8KvCl34v+IFhZWMscTwOLljJ0KoQSPrX3TfySw6bcy2y7pkhdo1xnLAHA/OgDA1D4j+D9J1Z9L1HX7O2vY2CNA7HcCeg6V0yOskauhyrDII7ivz+8canq+qeNtQvtfg+y6lJLmWMLt2kdOKTTtc8WaneR2WmalqVxO/CRRzsSfoM0AfoHXm/x18Nadr3wx1C71BHaXS4muLYq2MPwOfXirHwTg1e2+GNnH4iW4W+Esm8XJJfGeM5qh8ffFdr4d+Gt1ZXUUkj6ujW0RTorYByfagD4rr62/ZU/wCSWal/2Gpf/REFfJNfW37Kn/JLNS/7DUv/AKIgoA9tooooAKKKKACiiqGka1Za3avNYS7/AC3MciHho2BwQRQS5RTUW9WX682/aD/5IT4h/wC3b/0pir0mvPPjy0CfBLXmu0aSEfZ9yqcE/wCkxY5+tJuyuaQipSUW7X6s+H66z4e6I3iTXm0dJhC14oiEhGQuT1rJ+06H/wA+Nz/39FegfDHSLp9d07U9EsZrKOe48mC9uDvjLjqMe1clao3D4X07d/U+iy3BQjik1Wg9Jfzfyv8Aun0h4I+EHhnwQ8V5Z2ofUFhCSzu25WPcgHpU3xRkRvDlmFdSf7Rt+h/2xXE/FbxB4z8E+D2udV1W0u7e7b7Oy20BjcZHUHPFeAaH4lzqaywy37vAPNUXFyZFyvPQmitUbpv3X+H+YZZg4RxtOSrQevTm/wDkT7sHQVyfxM/5EG+/4D/Ovnu1/aU8UXN3DbqIVMrqgJhXjJxXq/jKz8ZnwVPcaprNhNaMqM0UdsVY5xjmnVqN05Lle3l/mRl+ChHGUmq0H7y/m7/4TyP9ovwjJp99pfic3SumowxwCELymyPOc14jXvHxv1KRNN0fTfEuq2upywgSJaWiGOSAFOCxPUEcV479p0P/AJ8bn/v6K0VV2+F/h/mclTA0+d/v4f8Ak3/yJ90/Dj/klnhT/sC2f/ohK6Sue+HxRvhl4XMKlYzo9oUUnJA8lcV0NbnlNWdgooooEFFFUNS1qy0ia0TUJfJF3L5Ubt90NjIBPbNBMpRgrydkX6KKKCije/64f7tcLrHizUNI8WT2ptvtNtsgitoYg7M0jiVyzbY2YALER8oP05yO6vf9cP8AdrMu9J06/WQX1hbXIk27/NhVt23O3ORzjJx6ZNIjTW5yF38R2EINnpbB5LdmQzs48uX7O0wRwEwOFxgsG77cc1Zk8em20mOefTvMuC0kbRxzDBdFUnBI6Ev6Vrajpvh3SbWTVLrSbMfZ0A3paKz4xsCqAM9Dtx6cUabomgXMCXtvoFpbtIm0CSyRHCjgDGOmAPwAqlbUT6FPSfGEmpa8dMl0qaDa8kJnUOyCWMAuNxQLjOQCGyccgZrqo+j/AO7VKPStPi1J9QisbZL2QYe5WJRIw46tjJ6D8hV2Po/+7S6IOph+K76/0/QWl0nyxcvPBCrSHAUSSqhPQ8/N6f4VhW3xF+0QMyaTcDft+ytKJFE4Llf+eeS3GcRh+PocdnNBFcR7LiJJUDBtrqGGQcg89wQCPcVQbw3ob+du0ewPnuJJf9GT52BJBPHJySfxPrQGljndH8eS6lqcSyWKRWlzFG0J8w70YxSuwYEDj91gdPf0Ea/EWSWCKW30WSRZ3SOECR3LMYFnbKpGxACsBnByfQc1pR2vha+1N9LTQ7aUwfu9509TECnOwNtxxvPHTlgOciteTQdIms/skulWT224N5LW6FNwUKDjGMhQB9Bijz+4ehPp14uo6ZbXqRyRLcRLKI5Vwy7hnBHY81bk/wBZ+A/lUaIkUaxxKqIoCqqjAAHQAVJJ/rPwH8qbtfQlbHn7eO7/AE7Ur+G9sJLzbcTmOO1V38qCIqpPyxnLEtn5iF/2hxUt34/uGu3tdP0+Iv50axSyyPskT7SkL87MZ+fjaWA74IxXVXGh6TdsputMs5ikhlUyQK2HPVuR1OBz7VmaxZeHdEs57660GCWN9xuHhskc7c7yz8dMqG57jNTslfpuU9W7FP8A4TkzNp8Vnpplmv4YJUVpwoQSCU8nB6CE9uc1b8LeLR4maTGnXFonkpPC8qOBJG5OOWVRu45C7hyMMau6XpOirFFf6fpFravOFnDfZVjkBIOCeMhsO303H1NW7LStP015W0+xtrVpjulMESoXPPJwOep/M1Wz1J32Lo/1Lf7w/rXL+Nteu/D9lZXNqF8k3DG5I+/5SRPIwUEEEkJj/DOR1A/1Lf7w/rVee1t7oKLmCOYISVEiBtpIKkjPsSPoTUu/QenU4y5+I7WunyzzaNMk0Id5IW81SY1RXLKDFuPDgZKqoPVgCCZ7bxxMo1L7fZR/6LJIY/JlPzRiYRjORw3OfStw+FvD5t1gOh6cYULFY/sqbRuAB4x3AH5D0rN0xfCniO6la30i1klixcB5rFVLhyQJFJHIJj69flHtVK1xP4Sh/wALDkEkIbRJ2WRTKfKZ5SIvM8sN8qEAkhjgkDA65OK7hPvr9az5dD0mc25m0yzkNscwboFPlHOfl445GeO9aCffX60ug+uhqUUUUGgUUUUAFcX8Uv8AkV7fP/P4v/oD12lcV8Uz/wAUtb473i/+gPQB41rMM0+mlbU7G6nHcelcM6uHKsNpB5Br0YgnCtWXqHh+C9mDhjEf4io+8fWvQwuJjSXLLYiUbnM2Wlz6ijGEr8hwcmtC60JLLTHnlZjKvUDpXRWGnw6fbqiD5sfM2OW+tYvimd0WKNJOGzvUHrWscTOrWUYvQLJI5sck4/WtXQrZ59SSRMERHc2aysjPp6113hyGJdNWVFCuzEM3ciurFVOSm33JitTYVvagkg0LndjOR70pO4cgYrwDUTnHqM4qtf3iWFu00gJA+UYHerK+/TtXO+KJpBJGgLCJlyw7E5rahT9pUUWJ6Iyb/U5NRZGlUKUGBiqkSmaURoCST2q3ZaVc3+XhT5QcEk44rpNN0WDT5GcHzHPRmH3a9epXpUFyrfsZpNmLq2jx2EETw733D5iR0rJAzgk11fiS6eGy8pE3CThm9K5PaAM9TTws5Tp3kEtz0G3wYIvTYP5VITjpxUdoP9Giz12D+VS7fmweleFLdmoAcbjWdrdnJeacyxAEg7ua0Tnbjtmhx8vyn2xThJwkpLoB58jSW8pKM0bj04Ird03xEsUPl3uW29GAyT9aua5pkclk8kUUazZBLk4zXIc54r2o+zxULtGesTrz4lsTyFf8Vrm77UJr64LyfdB+VR2qqOVq/oiWst+i3jEAH5Vxw31qo0KdBOaQrtmr4Ys5YHkuHXasi4AbrXREEcgcd6bhOi9AOKcM7eteNVqOrNyZolZAQNv40yWPfCyn7rAgmnj5WwBk470jdgemayGcFfW32S+kiwdinCse4q3o2rDTpGV1zG/JPeui1jT4Lu1JkwjKMh+49q4raMkZ6V7lGccTTtIyejOouPEtv9nYW6sZCOAw4rlmYs7MepOTilwDjFWNPMKX8b3Q3Q5+Ydc1rTpQoxfIgbua3h7TPNZbtzgKflx61044JBqK0igjth9mVVjPIC1YAGOa8WvVdWd2aJWR2fwsJPie4/682/8AQ0rdv/izo2n6lc2U1nftJbStExVEwSpIOPm6cVg/Cw58U3PP/Lm3H/A0rgfE/wDyN2r/APX9N/6MNTTipPU8XN8ZVwkIypdWeqf8Ll0L/nx1H/vhP/i6P+Fy6F/z46j/AN8J/wDF14vRWvsonz39uYzuvuPaP+Fy6F/z46j/AN8J/wDF0f8AC5dC/wCfHUf++E/+Lrxeij2UQ/tzGd19x0ev+KnvPHM3iDRWmtWJQxl8BhtRVOQCRg4PHpXsHgvxpa+K7DB2w6hEv76DPX/aX1H8vyJ+fKs6fqF1pd/FeWEzQ3ETZR1/l7j2pygmrGeDzSrh6znLVSd2v1R7b8UufC9t/wBfi/8AoD15PgFuCa9G8ZXt5qfw50y71O0NncyXKM8J7fI/Ptnrg8ivOQcqMDA7VyH30JKcVJdTK1+z+0WJPJeLLKB3rjug54OeleigBmOa5XxFYQW8gnhwhc4KD+dengq1v3bFJdSzY+I4ktUjuVIZeBtHaqet6yt/GIYF/dg5JI5zWPgDmkx1rtjhqcZ86WpPM7CxKZJFT+8cDNdtpWm/YLUrnLty3oDWL4eWzkUxXKK0+7chPYfWurwM4rhxtZt+zKiuo0Hgeter6Fr9v4b+F9lqN7HLJEjOpWIAtzKw7kV5U2AOK7XVv+SE23f99/7WavPiruxji6kqVCdSO6TZqf8AC5dC/wCfHUf++E/+Lo/4XLoX/PjqP/fCf/F14vRXR7KJ8Z/bmM7r7j2j/hcuhf8APjqP/fCf/F0f8Ll0L/nx1H/vhP8A4uvF6KPZRD+3MZ3X3Hq/iD4qaPq3h2+sLezvkluYWjVnRNoJHfDVy/gbxzP4Xuxb3RabTJW/eR9TGf7y/wBR3rkKKpQilY5amZYmdaNZv3kfUlpdwX1pHdWcqzQSruR0OQwr4G+I/wDyVPxX/wBhq8/9HvX0n8LNe1a21xdKtYXu7GY7pY88QesgPb3Hf6182fEf/kqfiv8A7DV5/wCj3rllHldj7jAYxYyj7RKz6lz4XeL7jwX48stQtUiYysLdzKeFRyAT+Vfd1tcwXlslxaSpNDIMpIhyrD2NfnDX0P8As2ePtdl1dfCtzHJd6bsLRzPnFsFHCDAxg571J3G38W/gDqXirxW+t+Gp4zLdktcrcPtCnttp/wAIvgJqPhLxQut+JJ4xNanNstu+4Me+6vfqKAAnCkntXx18d/ionjjVl0fT4dun6dMxV3XDmT7rD6cV7f8AHkeMrfwzb6h4Lu5rZLNme88hvmZMYGBg55r42nklluZJLgsZnctIW6liec/jQBHX1j+y9cLa/CHWLiQErDq0zsF6kCCE18nV9U/s2/8AJD/EP/YRuf8A0mhoJm2oto7j/hcuhf8APjqP/fCf/F0f8Ll0L/nx1H/vhP8A4uvF6K6vZRPhf7cxndfce0f8Ll0L/nx1H/vhP/i6P+Fy6F/z46j/AN8J/wDF14vRR7KIf25jO6+49o/4XLoX/PjqP/fCf/F15ppHiq80HxJNqemsdksrNJC54kQnOD7+/asKiqUIo5a+ZYmvKMpPWO1j6W8P+ILHxJpSXunvkHiSM/ejb+6R/nNcV+0H/wAkJ8Q/9u3/AKUxV5z4T1vVND16GTR1aaSVgjWwyROM/dx6+h7V6T8c4nvfgZraSbbd5FtiwkYYQ/aIiQSPyrmqRUNeh9nlOMlj48tvf0Xk7nxFXuHwd8WWtxZ+HvCywSC5tNTe5aUn5SrdB9a8l/sE/wDP9bf9910Pg17jwvrB1WzubaWe3AeME5UEevtXBWrU3Cyfb8z7bLctxcMUpShpaXVfyvzPtPxZoEfiXwxe6a8cLyTRMsTSruCMRwa+NpPhv4l8La7dw3+mzmBA0CXKphJWIwMfWvpnw78XrfWdGhni0u9vJVULM9tHuTf3ArM8e+NBqmi20I0fULfZewybposA4bOPrRWrU3TaTHlmW4uGNpylDRPuv8yh8BvhbJ4e8Nz3niixtpJ75lljimhBeDA6HPeu9+J7CH4d6g2PlRVOB6A1APiMuB/xT2rf9+a8r+JHxF8TXlxcaVNYR2WjXg2xfaIysrY606tam6ckn0Iy/LMXDGUpShopLqu/qeJ/EzxTbeMPGTanZQyQxrbxwbZDzlBgmuRrZm0ItPI3222GWJwX96Z/YJ/5/rb/AL7rRV6dtzkqZVjHN+5+K/zPsTQfHGn+E/hp4Mhv7e5lafQ7RlMKqQAIUHOSKn/4XLoX/PjqP/fCf/F1wPiePyvA/gSPcG2aDbruHQ4jTmuVrvhCMopn53mOaYrDYqdGLVl5HtH/AAuXQv8Anx1H/vhP/i6P+Fy6F/z46j/3wn/xdeL0VXsonD/bmM7r7j2j/hcuhf8APjqP/fCf/F1ynj/x3p3ivS7W2sLe6ieGbzGMyqARtI7E+tcFRTVOKd0Y1s2xVem6c2rPyPVPh38RMeVouvzccJbXTnp6Ix/kfwr1avlWvavhVr2rappctrqELy21qAsN4x6/7B9cDv279qzqQtqj2cnzKU2sNV17P/P/ADOyvf8AXD/dqvT9SulhuVVoyxKA5DY7n2qn9vT/AJ4t/wB/P/rVgfSNq5HrOnf2rpM1nmAeZtI+0QCaM4YHDIeo49QfQg1D4f0f+w9L+yeZG5MskpEUXlxoXYttRMnaoz0yatfb0/54t/38/wDrUfb0/wCeLf8Afz/61AuZFmnx9H/3ap/b0/54t/38/wDrVJFfIwk/csMIT9//AOtQO6JaKrfb0/54t/38/wDrUfb0/wCeLf8Afz/61ArowrHwdHYeKpNXimhCtNLPtW32zM0gAZWk3fMgPIXA5xzxXTVW+3p/zxb/AL+f/Wo+3p/zxb/v5/8AWo6WDmV7lmnyf6z8B/Kqf29P+eLf9/P/AK1STXyLLgwseB/H7fSgd0S1Q1nTP7XsVtHl8uIzRySjbu8xUcMU69DjB9jU329P+eLf9/P/AK1H29P+eLf9/P8A61AuZFmiq329P+eLf9/P/rUfb0/54t/38/8ArUBdFwf6lv8AeH9aZUS3yG3dvJbhlGN/19vao/t6f88W/wC/n/1qB3RZIyCOlc34W8Jf8I3PPJ9phl82JIz5Nv5RlKlj5sh3HfId3LcZx0rb+3p/zxb/AL+f/Wo+3p/zxb/v5/8AWoFzK1izTk++v1qp9vT/AJ4t/wB/P/rU6O+QyqPJYZI/j/8ArUDujdooooNQooooAK4v4pEDwvbZ/wCf1f8A0B67SuJ+Khx4Wtv+v1f/AEB6APKMbuSeM0pPzAUi5z6jvSqByCeR0oAQ5ZiCcCuY8UQLHPG8Y+Z87j6107E8A/jXJ+IjcNqBEqnyv+WZrswaftSZbGLtBJrtdEt3g0tUlXaeTj2ri+FYZOBn867+zliuLJGgYOu0DI9a68e3yJExLOBs9qadp60n3uvQCgrleua8g0FOOOe1RXFrDdReVcoGXPANSKMc5p2c9eDTTad0BFDHHBEIYhtVeABT9vBz1oP3+FpSPu54pXvqwMLxRK8cMSRthX+8PWuXzgZ61ueJ7wPdLbhceV39c1g87ducV72FhairmUtz0K2YtaRHsUAH5VKwwtQ2wxaQj/YHH4VJtwc5zXhS3ZqPx93nFBwM56UpJA6fjTd3y4JpAcn4g1WSa4e1X5Y4zg/7XvWbZadc34JgTKqeTT9ZGNWuR1G/rXVaEP8AiUwHbgY5Ne1Kp9XoJwW5nuyqPDsBs/K6S4/1mK5u4tWsbkxS8OprvzyeK4vxDltXk+gxWODrTnNxkxySsdZYzxXNnG8DZ+UL+IqzgYx0NY3ho40lcjnea1wc8gc159WKjUaRS2FYcgg5NB5XGOc5oB69zQOMkisxmD4muxHbpbMv+s+bOemK5y1t5Lq6WOEZJrT8SpIt4hkfcrA7Bj7oqPw8MavGO2DzXt0f3eHvEzerLv8AwiwYZW4OcdMVg3VtLaXDRyAqy9PevQxtGNowa5zxUqbYMYzk5PrXPhcTOVTllrccoqxD4cvykxt5ZSQ3+rX0NdQ2Sa89imkhnV4jtZDkGu/tnZ7WN5DyyjJqMdT5ZKa6hFncfC0f8VVcHH/Lk3/oaVR1r4YeIr/X9Qu4FtfKuLmSVN02DtZiR296vfC0EeKbk5yPsTf+hpXrFcMZOOxy4vBUsZFRqX07Hhn/AAqXxN/dtP8Av/8A/Wo/4VL4m/u2n/f/AP8ArV7nRV+1kef/AGDhPP7/APgHhn/CpfE3920/7/8A/wBaj/hUvib+7af9/wD/AOtXudFHtZB/YOE8/v8A+AfMes6RdaFq02nX4QXEO3dsbI5UMOfoRXpvw7+Hf2fyta1+H97w1tbOPuejsPX0Hb69OkXwRbXHju88RaltmyY/ssOMhSsajc3qcg4H4/Tq6cql1ZGOByeNOtKrU2TfKvno2cX8Uf8AkWLbt/pi/wDoD15OBjOORXq/xT/5Fa3/AOvxf/QHryjORjHFYn0YHlsjpXD6xdrd6g77dpX5cfSu0uVdrdkibbJj5Wx0rgJl/wBJcMckMcn15r0sBFczkRIvaXpEl+jM7bI+ze9Wb3w29tamWGQy46jGMVqeGsHSzuH8ZrYIUqQfu+lKriqkKrS2QKKsecRs8TgqxUg5z6V3GjXv2yxRt++RRiQn1rktSCrqdxt6bzxV/wAN3Eq3/kq2I3BJGK6sVBVKXN21Ji7M6wfe6V6PDod5r/wctNP08IZ2kZhvbaMCZiea8568Zwe1e0/D8EeBdPB6/vP/AEa1eKnZ3HVpxq03Tls9Dy//AIVL4m/u2n/f/wD+tR/wqXxN/dtP+/8A/wDWr3OitPayPG/sHCef3/8AAPDP+FS+Jv7tp/3/AP8A61H/AAqXxN/dtP8Av/8A/Wr3Oij2sg/sHCef3/8AAPA9R+GniDS9NnvrpbbybdDI+2bJwPbFYWhaFe+IdUjsdOj3SNyzH7sa92Y9hX0R4h0+XVfDt9YW5VZbmFo1LHgE9zVbwx4YsvC2li1s13SNgzTsPmlb19h6DtVe1djjnkUHXioXULa/5IPDHhiy8LaWLWzXdI2DNOw+aVvX2HoO1fDXxH/5Kn4r/wCw1ef+j3r7/r4A+I//ACVPxX/2Grz/ANHvWLdz6anTjTgoQVkjm6+xv2dfB6eHvh7HqguPObWQtztK48rAIxmvj61eGO8he5jMsKuDIgOCy55Ffe3w0uLC7+G2iT6RaNZ2UlsDDA7bjGuTxnvSLMz4ofFCw+G+kpLMguL6fmC2PG8Z55rzfw7+1HbalrtvaaxpKWFpI2HuBIW2fhWX+1gpa/0DAJ/dSdB71858qe4NAH6OwT29/ZpNAyzQyqGBHIIIr4//AGgvAH/CK+MDqWm2C2ukXoAjZT96XBL8fjXu/wCz1JJL8HrBpnd286QZcknrVn45+HdO1v4X6ldahEZJdNhae2IbG1+Bn34oA+Iq+rf2ZYHufgxrkEWN8uqXCLk9zbwgV8pV9bfsqf8AJLNS/wCw1L/6IgoE1dWZD/wqXxN/dtP+/wD/APWo/wCFS+Jv7tp/3/8A/rV7nRWvtZHh/wBg4Tz+/wD4B4Z/wqXxN/dtP+//AP8AWo/4VL4m/u2n/f8A/wDrV7nRR7WQf2DhPP7/APgHhn/CpfE3920/7/8A/wBauQFjcPqP2GKJpbjzPKCRjJZs4wK+oq5Twn4IttAurjUbrbPqNxI7b8cQqSTtX39T+H1pVXbU48RkUHOEaN7dWyv4D8Bw+GbYXl8Fl1SRfmbqIQf4V9/U/wBOuT+0H/yQnxD/ANu3/pTFXpNeefHm2e7+CWvQRFQzfZ8F2wOLmI9awlL7TPpcLhY04xoUV5Lzf+Z8P103gjR7nxBqc2k2O37RdoI495wMk9zWf/wjl5/z0tv+/wAK7L4W27+H/HFnfXpWSKORSRAfMb8AK461am4WUu35n0+W5ZjYYpSlSaVpdP7rPrrwP4XtfCXhS0022s4LWVY1NwIFwHkxy3vXB/F34gaHaPa6F5xmvI50unEXzBFjbLA+h9q6n/haeh/8+mq/+AD18r+I7d774k65qcJVYLqSQorttcZHdeoorVqbptKQZZlmNhjacpUmkn2PqfwL8VfDnj9po9GmeOWEgeVONrNx1A71X+L+j6ffeBrq9urOKa7tEzbysuWjJ/untXyH4bttZ8P+ILXUNNvo7aaOQAvFMN23IyPxFfUHjD4gaZqvgeayig1ATuiZeW0ZVyMZ5NOrWpunJKXQjL8rxsMZSlKk0lJdPM+P9Ss7iyv5YryCSCTO7bIpU4PQ1Vr2X4zaXp2vX9lreky3aXc0SQzRXkPkxgInBVj1NeYf8I5ef89Lb/v8K0Velb4jlqZVjnN/un9x9U/8Ibqvif4deB5dLEJWDQbVX8yTbyYkNUP+FS+Jv7tp/wB//wD61eo/D6Mw/DLwvE2CyaPaKSDkZEK10VdcajS0Pk8Tk+HrVpTqXu99Twz/AIVL4m/u2n/f/wD+tR/wqXxN/dtP+/8A/wDWr3Oin7WRh/YOE8/v/wCAeGf8Kl8Tf3bT/v8A/wD1qyPEPgvVvDFrFcaoIRHK+xfLk3HOM/0r6KrnPGHhb/hK49PtpJfKt4bjzZiPvFdpGB7nPXtTVV31OfEZHRVJujdy6ankXgnwTc+Kr3zJd0OnRN+9mxyx/ur7+/avebGxttNsorSxhWGCFdqIo4AosbG202yitLGFYYIV2oijgCp6ic3Jnp5fl8MHCy1k93/XQw9a/wCP1P8ArmP5mvNvEHiDU9G8T3TxypJb7LeGNJMLHBvErF23SIpJMYXkjqMHsfSda/4/U/65j+ZrOIyMHkVmdcnqzzq6+IGoybYbeO2gmmtz8vDtFJ9maYMPn+YZA6KV5+9nipv+FgTpp8aQvY3V784IDHBAVCrkAkgNvz/Kuy1bUY9I06S9kiaXayIqrgFmZgqjJ4Ayw5PSk0jU49WtHnSPynjleCVCQ210YqRkcEZql1JeyMDR/FOo3fiuTSLy3twImkjcxsqsCgH7zaZC21ieAVGAR8xrs4Okv/XM/wAxUOOc96mg6S/9cz/MUugdTn/Fsl3HoB+wXP2aWS5giMgUkhXlVTjBBBweuf8AGuXg+IN+0M3m29tAQyom90YxMXK7HHm/ewpOXMfII+vodRylI4nd1LKo3EKpYnHoByTSC+ljgNM8fXMl9DNqVxZw2l1DE3lvhfJJjmJO7dyC0YH44z6q3jzVv7Oivfs9lHDNLHEGbgRk26zEsXkReS20DI9eelbbeNIP7Piul065IKTzTRsVVoYoZNjsRnk552j3rpRhlB6g8in3f9f10HdLoV9NunvtKtbqaLyZJ4UkaPcG2EgEjI6/Wr9z/r/+Ar/6CKiqW5/1/wDwFf8A0EU3uStjzS48W6vo2pXit5d35t3OY/NZY1CxsqrCm6QAMd2cjJ/2TS3Xju/nvJ7e2mtLeOOZCJigOxFukicMC+eQxySqYwcZ616IQD1FZsurxQ+II9L+zT75bd7jzhH8nylQVB/ib5h0zSWlvIpu99Dmrbxxd6lcWNrpwsjPcJB52SXELssxdCARyPKAwTnnmr3g7xTeeI5LgXdtFCqRpIBG6FoyxYGNgHY5GOpCnr8oxW1ouqx6zp7XcVvLbjzpIjHMu1wUcqSR2zjOOtX8Y6UbEvy/qxMv/HnL/vr/ACauS8cahfabZWM+nu3y3DPJCgO6cJDJIEBBGMlAO/8AQ9av/HnL/vr/ACaoqTHex5xc/Ee+t9Je4MVk0qeY6srIyzKiIxAxMVBy+Pvs3QhTyBYi8c3FlJqEV9cWcsiTSfZ1b5G4lVRHjPJCsD64INdnql7Hpelz3rwSzrAhfy4U3M30H9TwO9ZzeI9tzp4fTphBemNUnLLw7qWAC5ycAckdPzxS3/rqD+H+uhzsnjnV4ZLPzLS0YXWZEAYJvXzfL8sF5Bl+M5Abqo2969Ch/wBfH/vD+dR4z17VJD/r4/8AeH86XSwbs6miiig6QooooAK4v4o/8ivb8Z/0xf8A0B67Suf8Z6DdeItGitLKSGORLgSEzEgYCsOwPPIoA8S69OOelGAzHrmu2Hws1nvdWH/fx/8A4ig/C3Wv4bqwB/66P/8AEUAcSSBkDrXO+KulvnjrXq//AAq3W/8An50/P/XR/wD4iq178HtWvoDHNc6f7HzHyP8AxytqE1TqKTE9UeGAZbk59K7Pw6CNFX/eNb5+Afibd8t9pOM/89pf/jdbWj/BvXdOhIlvrB3bqBLIVH/jld+LrU6lO0WTFNM5nGU46Uu0hMdDmu1Hws1oN/x9WGP+uj//ABFH/Crdc/5+tP8Ab94//wARXlFnFjgY3Cm7iBjIrth8LNbJ+a60/wDCR/8A4ig/CvWs8XVh+Mj/APxFAHFK3I+lKp3ZyeTXaH4Wa2V5utPz/wBdH/8AiKb/AMKr1z/n60//AL+P/wDEUAeVeK0UGA4AbJyfWucUBuT1Fe7S/CXV5v8AXT6c+Om53OP/ABysqb4GatcX8ksl1pyRFQFVJXBB/wC+K9PD4qEIcsuhDjdnPwf8esQ/2B/KpDtPYjHvXaRfCrWYowgurD5RgfvH/wDiKX/hVmt8/wClaf8A9/H/APiK817lnGA8fLnn1pMAfe69q7T/AIVZrQXAurD/AL+P/wDEUp+FutnH+laf+Mj/APxFIDyDxHY+VcieJGw/MjE8A1nWWqXVgjJbuMN2cZxXtsnwo1iZSstxp7AnoZH/APiKw9S+BWuXNx5lnd6YmfvBpZB+WEr06GJg4+zqENPdHm1zr17PbtE7qFbqVGDWYzM7/Mxb6nJr0/8A4UJ4o/5/9I/7/S//ABur+n/AnV7dklurvT3kU5IWWQqf/HK6Pb0Kcfd/AVmzk9Ajli0lFlQo24kAjqK1CuBx0712g+FmtAYF1YYxx+8fj/xygfCzWgf+Puwx/wBdH/8AiK8ecueTl3NDiweCOMYo3cDPpXaD4W62CcXWn495H/8AiKP+FW63jm60/P8A10f/AOIqAPNPEFh9rtRIiM8qHC7fSuUZZIJChzG68EZwRXu//CrdbAwLqw/7+P8A/EVgat8DNfvLozWt7piluX3yyD+SV6OFxCj7k9iJLqeXWmsXlkp8qTJP9/5qjvL2e9k82cgsewGAPwr0hfgJ4oAw1/pB/wC20v8A8bq7pnwK1u3uPMvbzTJAv3Qksh/PKV1uvh4tzVrk2Z5loumrqV1skbCLy4zyRXZxRiJBGPuqMDNdpH8JdWhYmKXTUJ/uu4/9kqVvhZrRHF1Yf9/H/wDiK8zEV3WlfoaJWD4W5/4Si454+xt/6Gler1xHgvwZqPh3Wpbu+mtZI3tzEBC7E5LKe6jjg129cwwooooAKKKKACiiigDivin/AMivbf8AX4v/AKA9eU5zt6Zr2rxpoF14j0WK0spIY5EuBKTMxAwFYdgfWuI/4VbrmB/pWn/9/H/+IoA4vdnp1rkNa0xre8eWCJ/KxuZu2e9eyf8ACrNayP8ASrDH/XR//iKjuPhPrNzbvC91YbXGD+8f/wCIrehWdKVxNXPCvOljUbJGAz0ViKvrr9+IfIDIU24zt5/Ou+k+AXibzCY7/SdmeAZpen/fug/ATxOR/wAf+kf9/pf/AI3XrSq4eW7RnZnl7sWb5iTzyfWuo0DSUjhW9LEuw+TB6CvQrD4K6naWoWSfTZJDyxLuRn2+StCP4VazGoVbjT1UdAJH/wDiK48Ri1NckCoxOLHOCete1eAP+RH0/P8A00/9GNXFH4Wa3uyLqw/7+P8A/EV6F4X0qfRPDdrp920bzQ79zRElTl2YYyB2NecWa1FFFABRRRQAUUUUAFfAHxH/AOSp+K/+w1ef+j3r7/r5g8Wfs1eMde8aa3q9nqWhpb6hqE91Ess8wdVeRmAYCIjODzgmgD57r6h/Z9+KVmnhNtG8UatZ2n2KRLewjYbWZCP1OTXF/wDDKnjf/oK+H/8AwIn/APjNS2v7Lnjq0vIbmPVPDxeGRZFzcT9Qc/8APGgD6oudPsdQ2NeWdvc4HymaJXwPbIrgdd+BHgfxDrsmrX1ncR3EhBK283lx8eigYrtfD0erw6DbR+ImtX1FUxM1oWMZPtkA/pWlQBXsbC202yitLGFIYYlCqqKAOB7d68C/aL+KlzpfneCtMh2PPCDdyyKGDxsMgL3ByOtdX8UvA/xH8Y6pGnhrWtL03TYPmj3XE0crEjndtjIx+NeWX/7M3xE1W6NzqWvaJdTkBTJLdzs2B0GfJoA8Jr62/ZU/5JZqX/Yal/8AREFebf8ADKnjf/oK+H//AAIn/wDjNe5fBT4f6r8OPBd3pGuXFnPcTag90rWbsyBTHGoBLKpzlD29KAPRKKKKACiiigAooooAK82/aD/5IT4h/wC3b/0pir0muJ+MXh7VPFXwn1nRtBtvtWoXPkeVD5ipu2zxufmYgD5VJ5PagD4Sya6v4fa4/hzXW1hIVnazUSiNjgNg9K3v+GfPid/0LP8A5P23/wAcrR0v4DfEi2t71ZvDm0yw7U/062OTn/rpWNZNwsvL8z0ctnGGKUpuytL/ANJZ9Y+G9etfEGh2V4kluJriBZWhjkDFMjp61518VPh34bTS31Ky02K21K+u44pbtB8x3nBNcF8Ifh/8TPAXjFL7UPDDS2syeTIW1G3IiUnlsCQk49BXuXj7R77WtEtrfTIPPljvYZWXeq4VWyTyRRWTdNpBlk4wxtOU3ZJ9Tzfwv+zNomh69BqGoalJqkUXP2aaMBSex49K9A+Jix2/w7vsKFSNV6DoAa62VnS3dok8yRVJVM43HHAzXz94n0341+KNauoZNEa10Oc4+yi+tmAH/fzNOqm6ckuxGXzUMZSlJ2SkvzPOfjV8T7Pxqmm6RpMINppoVhcEEM77NrAj2rybJr0yb9n74mvPIy+GcgsSP9PtvX/rpTP+GfPid/0LP/k/bf8AxytFsclR3mz62+HH/JLPCn/YFs//AEQldJWJ4K0+60jwD4f03UIvJu7PTLaCePcG2OkSqwyCQcEHkHFbdMgKKKKACiiigAooooAw9a/4/U/65j+ZrPrdvo4nnBkjVzt6kn+hqr5EH/PBfzb/ABoMZRuzC1GxTUtPms5XdElXaWQKSPwYEH6EEGotH0i20TTxZ2e4pvZyzBQWZjknCgAfQAACui8iD/ngv5t/jR5EH/PBfzb/ABoJ5WZlSwdJf+uZ/mKveRB/zwX82/xp8cMAD4hUfLzyf8aBqJk0Vp+RB/zwX82/xo8iD/ngv5t/jQLlZxlx4Qsp4BELm7iXE6SbGTMsc0m90bKnjPcYIHet8AAADoK1PIg/54L+bf40eRB/zwX82/xoHytmZUtz/r/+Ar/6CKveRB/zwX82/wAafLDCZOYVJwO59PrQHKZNVZbCKXVLe/ZnEtvHJGgBG0hypOf++B+tbvkQf88F/Nv8aPIg/wCeC/m3+NAuVmFYWEWnQyRwM7LJNJMd5B+Z2LHp2yatVp+RB/zwX82/xo8iD/ngv5t/jQHKyiv/AB5yf76/yaoq1hDB5LjyVxuHGT7+9M8iD/ngv5t/jQPlMe5gW6tZbeQkJKhRivUAjHFZEXhiODWLbUI9Svc20CW8cDCJowijBxlNwLdyCM4HYCuv8iD/AJ4L+bf40eRB/wA8F/Nv8aNg5WZlPh/18f8AvD+daHkQf88F/Nv8ackEAkXEKg5Hdv8AGgOVmvRRRQbhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAUb3/XD/drznxINdsfFV3qGli6aORLaAyCIssMZErOUxFIc7ljB+Vvvc44I9Gvf9cP92q9IjueZ3WteMbpktvJvInktTHN5FqyqrG1Zw6ExZB8zaMlxg5XZ3qf+3/E406O0s4dQa6XeDLNpr52bE8tiSgBbJbI65ByBiuw1nVrjTLnTY4bPzo7u6WCWUyBRED046kn8uDk9AYNL1u8ufEd5pWoWscDwxCeMozcqWIAywAbgAkrkAtg89aWt/P8ATUT6eX/DGTot/wCJj4wlstR3vZRtIhaSFlDIoGyQMIgm5j1Ac9SAoxXax9H/AN2mU+Po/wDu0uiDqc/4xs7jUPDptrVrhWkubdX+zqCxjMyb8gg8bck8dBzxmuSh17xgsE4ure4jy6piK1cm3O8jCkwY27R1Al7HoePSqbIzJE7IjSMqkhFIBY+gzgfnS2DyPONL1vxLb38F7qsWqGO4hiE8IsHdEIjmGVAjyCXEef8AeHABFK+reNP7Liu3+0xmSWOORPsZDRL9mVywAikY5lJU/KQMY4PNa03jxrbRbGe4tIkvrq8ML23n8QxrceSzlu+OPqT6AkdlT7sLlXS5LqbSLSTUUVLt4EadUBADlRuAB5HPrV2T/WfgP5Uynyf6z8B/Km9XcS2PMLqTxTpGqXraYly4ury4k82aBm3srIIkOyFj5e3d/d9nGKW61bxTe31zFjVILVZkfMVowaMJdxqVH7rkGMscbpMgZ4GRXpdYep69dWGuLZJpzSwmxnullVstI8e35FQZJ+9/LGanZLy/RFfE3br/AJnPWuteJ9TubC2jS8tMpAt5M2nlQsm2YygF1xjKRjIyBuGOtaHgnUvEV/Lc/wDCQxGMCNG2tE6eXKS25FJjQFQAOhf/AHjkVp+GNan1mxla+SOG6hcLLAsckbR5UMARIAe/XGK2qrZ6k3vsPH+pb/eH9a5Lx7b6nNY6e+jxzTTQXLTeQihkkKwyMgfg/LvCDtyR3xXWj/Ut/vD+tMqWO9jzG68ReMotHdoYruWcGV4XWycmQrGhCNm3B5YtgBFyARvGMm1HrPiLTZdRiMep3DSzym28yxeQKxmXADBMbPLORk4688YHb6xez6do11eWtr9rmhjLrDvCBsepPQdz1PoCeK56DxrJca7a2Qto0iZYBNI6yYDypvADBSo7ABiMk9uM1H4vw+//AIYH8P8AXT/hzJl1TxrDLZEea4nzIQ9owAbzdvlMEiYhQgByShO4ndgYr0ZPvr9abTk++v1pdLBu7mpRRRQaBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAUb3/XD/dqvWo0aOcsoJ96TyIv7i/lQS0Yt1ZQXvk/aY9/kyrNH8xG116HiqthoOnaZeSXVnC6yupXLzO4RS24qoYkICecLgdPQV0nkRf3F/KjyIv7i/lQHKzMp8fR/wDdrQ8iL+4v5UCGMdEH5UBymZRWn5EX9xfyo8iL+4v5UC5Tl5/C+i3Vottc6bBNEspmUSDcQxk8wkMefv8AOM47dOK1elafkRf3F/KjyIv7i/lQHKZlPk/1n4D+VaHkRf3F/Kgwxnqg/KgfKZlVLvS7O/lEl3CJGWGSAEsR8kmN4wD32j8q3vIi/uL+VHkRf3F/KgLM5/TdIs9JjlWyWTMzB5HmmeV3IAAyzkk4AA61drT8iL+4v5UeRF/cX8qBcpnj/Ut/vD+tMrT8mPGNgx9KPIi/uL+VA+UyZoUuLeSGZd0cilHXOMgjBrN/4RnShewXQt2EkAQIBM4Q7BhCyZ2sVB4JBP5Cuo8iL+4v5UeRF/cX8qA5WZlOT76/WtHyIv7i/lR5MY6Iv5UByj6KKKCgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP/2Q=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Number : 408846\n",
    "## Student Name : Ibrahim Sahin\n",
    "\n",
    "# Grid based classification\n",
    "\n",
    "In deze notebook zullen we gebruik maken van grid based classification. Het idee van grid based classification is om de binaire versie van een afbeelding te verdelen in stukken (rooster over de afbeelding). Per stuk zullen we het aantal witte pixels optellen. Deze data wordt dan gebruikt om de afbeelding te classificeren. Dit zou in een grid van 4x4 betekenen dat we 16 features hebben per afbeelding. hieronder een voorbeeld:\n",
    "\n",
    "![grid_voorbeeld.JPG](attachment:grid_voorbeeld.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uitvoering\n",
    "\n",
    "Om dit probleem op te pakken zullen we de workflow hanteren die voornamelijk worden gebruikt binnen een Machine learning probleem (Data Science lifecycle). De workflow is te verdelen in de volgende stappen:\n",
    "\n",
    "1. Data verzamelen\n",
    "2. Data analyseren\n",
    "3. Preprocessen\n",
    "4. Feature engineering\n",
    "5. Trainen / Testen / Evalueren\n",
    "\n",
    "Allereerst beginnen we met het importeren van de libraries die we nodig zullen hebben in onze code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io, transform, color, filters, data, morphology, measure\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    images_name = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = io.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            images_name.append(filename[0:4])\n",
    "    \n",
    "    images_df = pd.DataFrame({\"name\": images_name,\n",
    "                             \"image\": images})\n",
    "    return images_df\n",
    "\n",
    "def display(np_image):\n",
    "    \"\"\"\n",
    "    This is a display function that we have added to show numpy images at full size\n",
    "    If you pass in an image with 3 channels, it will be displayed in RGB\n",
    "    If you passn in an image with 1 channel, it will be displayed in grayscale\n",
    "    \"\"\"\n",
    "    dpi = matplotlib.rcParams['figure.dpi']\n",
    "    if len(np_image.shape) == 3:\n",
    "        height, width, depth = np_image.shape\n",
    "    else:\n",
    "        height, width = np_image.shape\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Display the image in either RGB or grayscale (depending on the amount of dimensions)\n",
    "    if (len(np_image.shape) >= 3):\n",
    "        ax.imshow(np_image)\n",
    "    else:\n",
    "        ax.imshow(np_image, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hierboven gedefineerde functies zijn geleverd door Saxion zelf. Die zullen gebruikt worden voor het inladen van de data en het tonen van de afbeeldingen.\n",
    "\n",
    "Hieronden wordt de data ingeladen. Voor de zekerheid zullen we de data ook printen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>[[[241, 241, 241], [242, 242, 242], [244, 244,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1027</td>\n",
       "      <td>[[[206, 206, 206], [211, 211, 211], [218, 218,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1029</td>\n",
       "      <td>[[[82, 82, 82], [83, 83, 83], [84, 84, 84], [8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1036</td>\n",
       "      <td>[[[241, 241, 241], [246, 246, 246], [243, 243,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1053</td>\n",
       "      <td>[[[241, 241, 241], [243, 243, 243], [243, 243,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>5264</td>\n",
       "      <td>[[[228, 228, 228], [227, 227, 227], [224, 224,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>5339</td>\n",
       "      <td>[[[70, 70, 70], [71, 71, 71], [67, 67, 67], [7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>5377</td>\n",
       "      <td>[[[243, 243, 243], [236, 236, 236], [243, 243,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>5382</td>\n",
       "      <td>[[[214, 214, 214], [222, 222, 222], [206, 206,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>5384</td>\n",
       "      <td>[[[88, 88, 88], [94, 94, 94], [91, 91, 91], [8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                                              image\n",
       "0    1000  [[[241, 241, 241], [242, 242, 242], [244, 244,...\n",
       "1    1027  [[[206, 206, 206], [211, 211, 211], [218, 218,...\n",
       "2    1029  [[[82, 82, 82], [83, 83, 83], [84, 84, 84], [8...\n",
       "3    1036  [[[241, 241, 241], [246, 246, 246], [243, 243,...\n",
       "4    1053  [[[241, 241, 241], [243, 243, 243], [243, 243,...\n",
       "..    ...                                                ...\n",
       "235  5264  [[[228, 228, 228], [227, 227, 227], [224, 224,...\n",
       "236  5339  [[[70, 70, 70], [71, 71, 71], [67, 67, 67], [7...\n",
       "237  5377  [[[243, 243, 243], [236, 236, 236], [243, 243,...\n",
       "238  5382  [[[214, 214, 214], [222, 222, 222], [206, 206,...\n",
       "239  5384  [[[88, 88, 88], [94, 94, 94], [91, 91, 91], [8...\n",
       "\n",
       "[240 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_df = load_images_from_folder('../dataset-images/dataset1')\n",
    "all_images_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals hierboven is te zien is de data succesvol geladen. Laten we voor de zekerheid kijken of er toch geen gebreken zijn. Hiervoor zullen we de \"describe()\" functie gebruiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3579</td>\n",
       "      <td>[[[222, 222, 222], [240, 240, 240], [238, 238,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                              image\n",
       "count    240                                                240\n",
       "unique   240                                                240\n",
       "top     3579  [[[222, 222, 222], [240, 240, 240], [238, 238,...\n",
       "freq       1                                                  1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor nu lijkt de data in orde dus kunnen we verder gaan.\n",
    "\n",
    "De data is nu verzameld.\n",
    "\n",
    "Om de data te kunnen gebruiken voor de machine learning algoritme zullen we het eerst moeten preprocessen en de features eruit halen.\n",
    "\n",
    "Hieronder zullen we een begin maken met het schrijven van de eerste versie van de preproces pipeline. Hiervoor zullen we de volgende stappen uitvoeren:\n",
    "\n",
    "1. De kleuren van de afbeelding omdraaien, zodat de cijfers wit zijn en de achtergrond zwart.\n",
    "2. De afbeelding omzetten naar een binair formaat (zwart/wit).\n",
    "3. Afbeelding knippen naar 1 cijfer per afbeelding.\n",
    "4. Afbeelding plaatsen in een grid en features eruit halen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De kleuren van de afbeelding omdraaien, zodat de cijfers wit zijn en de achtergrond zwart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image = all_images_df.iloc[0,1]\n",
    "image_name = all_images_df.iloc[0,0]\n",
    "\n",
    "image = image*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De afbeelding omzetten naar een binair formaat (zwart/wit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAAAuCAYAAAD+4SHmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAACSklEQVR4nO2bwW7EIAxEl2r//5fpqdKKAgtm7AEy71SlTWzM4NiEppzzS4hZftgOiDORcIQJCUeYkHCECQlHmJBwhIl375cpJXiv/tn+p5TQj9+Gv3FGjvHb1sqsLznn5g1d4aApB5ZzhgW2FzTm5EUtlJH9OGS8w15VzI3GCNs5Z9oYGXavqHFGVxvTvocPFrGifAgRjveKGE2/Hn6cmGUQPl+dcVJK/0QVOdE1QUcLzauuchUO873fA+XTiGCZnaOnD8dnnN7k1X6OtNu6tirc2v1ldi1ton1wE86IY5GrkfnKqtn3tBNR8x2dcWZWfe86ips3NEuOFk6NmcnzaI97fPrGqP+QzQJcOMyCeEQ0T8oKnkCFw+ygniyI1bFb5g0mnGjReLfUs4wWpbcIHCIcS/BvCeAqjCyNiP3S1/EdN/dEDOaMI9Fw2CXuR7bjq8FjFJNI+ztgEs7IfgVzV/g2ezsCzziMoJ7a0Z2MSTitD3lPWYk7fPFmY+6q2MFjH2RigfD9sQe5Tp74VTwWrOWZrsLpObQy+Tuka+Qxjdl7a7ajM/CRGacG68D4bj5EcY1wXq/vE9I6OReJpw8j40fZdxfODhPTux5lH+1DK66fNlo/jzznG6H/yYmk11mNTtCqqFs+zAjE+zy014IJeVXtUMyW7OATQris+6k1DuKbD3vj0Wof5bP1Oav2w4TTCjDyIJXH33qAtj87dvp5nN0oD4OX1yJso4vQXe2nG/YURDxX7eOIOCQcYULCESYkHGFCwhEmJBxh4hchRkJtFws/hQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 128x32 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gray = color.rgb2gray(image)\n",
    "thresh = filters.threshold_otsu(gray)\n",
    "binary = gray > thresh\n",
    "display(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afbeelding knippen naar 1 cijfer per afbeelding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC4AAAAuCAYAAABXuSs3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA20lEQVR4nO2Yyw7DIAwE2ar//8vkVCmqEoj8WGsVzzUcRhtjA5hzDkU+1QJWWpxNi7ORFf+uPgII75Xn9gtgt/Z2ATXx/5nhmSE08ehBJ1vjFPGMY4Vs4suu4iXzACebeJr4k7R3fXxFJ84mfHOyblShiTOvgWHi7LtriLhF2tNRxnDWeOULgTnx6mcN2XZoEt+lDcBdwzvCE88W/mESv5JjpHzG3FWYkle8a3M+ZfVXvO20E2eTLp61iTvxFRmplyYu8XZ4N1mt8rI1jupztRXZxFucTYuzkRU/AHA9PVknbkApAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 32x32 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC4AAAAuCAYAAABXuSs3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA/UlEQVR4nO2YwQ7EIAhEnc3+/y/T6yarlsIImjKnpiT1FQERiEg7UZ9sAKsKPFoFHq1jwb8zI4DUWikiGNmm4A8XGdqA4fpmhYTKikOOAq4BY8NTwLWhwIRf6nEAfz/Fgk8phwx4N/jM271nlsI8zg4ZF7jG25r3FtE9/gTO43UquAaa5XUa+IoEnMkMzqrH1u8c29YWeLRM4N74ZiRyaHfIVFg/zta7YtwbGmlt7Q6D0hSPM0SLce0ubHl1u4Pq2a27R68qI3h2XpgnWQDckJ5cSavj3gR3zQ5/F48ukSk3IEY5pU1rW+vvwKqajx1OQYve1WTtoAKPVoFH6wIak15ZbYYDZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 32x32 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC4AAAAuCAYAAABXuSs3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAABA0lEQVR4nO2Yyw6DMAwE2ar//8vuCYSqPGC92ETJ3EoJTCxjW4GZbSPyyRZgWeLRLPFohhX/tv4EQNfKvcwCYB+xmVl1cVOcfFn1t2cT/8jEoxuZJMevSis35xbPGhkerSqlnFZt1CVekwBwSCs/yDO0eEu6d00R9bAGpI68VPyptCghFe+lwHljZuZKmWFnlSV+LoG9+xSkR5zN83RxlrnEvZ1PkeeUeGSjqZEScQVzRfwNzCeunLGZtaHT4d37WoSnSkma+djl4q1oKsuo60AIQFHmjiBbWlOriqcfuMWvzuGldR5SIq7ovLJDz13mznmL631vGJgY5mv52SzxaJZ4ND8ZM1tia7pJBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 32x32 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC4AAAAuCAYAAABXuSs3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAABAUlEQVR4nO2YwQ7EIAhEy2b//5fZU5OuUSoMogbn1KapPkcElZj52lGf2QBWHfBoHfBobQv+lT4SkSpXvqVWItI0dzFz8wc3x3vqgWfNcAGfUcQgcGZWQ3sN0gyOAHjAD88q2gXZq6HgN/QIeBN4baqJ6A+whC3f0XBxd7wcgCQEftvKGQpemw2r67kdR7OGxfXcjmvlkdfzOL7KdUYex1dRHvBR21StpizOKQeJEY5b2jTFeG2jFH2Uy7M4Jb0515qZsFCROnuCtZ572nmTeAVnVQ8wKihU0AyD/A/HuLVzdNDhJyDNLYAktxi/YbwXYbO/VfbXWp0CFK0DHq0DHq0f8m1hXm3x4wYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 32x32 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "binary_splitted = [binary[:, :32], binary[:, 32:64], binary[:, 64:96], binary[:, 96:128]]\n",
    "\n",
    "for x in range(0, len(binary_splitted)):\n",
    "    display(binary_splitted[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afbeelding plaatsen in een grid en features eruit halen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  number    1     2     3    4     5     6     7     8     9    10    11  \\\n",
       "0      1  0.0   0.0  45.0  7.0   0.0  29.0  62.0   0.0   7.0  30.0  56.0   \n",
       "1      0  0.0  39.0  27.0  0.0   3.0  33.0  20.0   9.0  13.0  23.0  12.0   \n",
       "2      0  1.0  40.0  32.0  0.0   8.0  33.0  21.0   8.0   9.0  25.0   9.0   \n",
       "3      0  5.0  52.0  41.0  0.0  16.0  20.0  18.0  18.0  20.0  18.0  11.0   \n",
       "\n",
       "     12   13    14    15   16  \n",
       "0   0.0  0.0   0.0  42.0  5.0  \n",
       "1  16.0  3.0  41.0  41.0  4.0  \n",
       "2  17.0  0.0  43.0  41.0  8.0  \n",
       "3  23.0  2.0  44.0  43.0  7.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for x in range(0, len(binary_splitted)):\n",
    "    \n",
    "    \n",
    "    test = binary_splitted[x]\n",
    "    height = 8\n",
    "    width = 8\n",
    "\n",
    "    s_width = 0\n",
    "    s_heigth = 0\n",
    "\n",
    "    df.loc[x, 'number'] = image_name[x]\n",
    "    for i in range(1, 17):\n",
    "        h = s_heigth+height\n",
    "        w = s_width+width\n",
    "        feat = test[s_heigth:h, s_width:w]\n",
    "        white_pixels = feat[feat==1]\n",
    "        total_white_pixels = len(white_pixels)\n",
    "        df.loc[x, i] = total_white_pixels\n",
    "        if (i%4 == 0):\n",
    "            s_width = 0\n",
    "            s_heigth = s_heigth + height\n",
    "        else:\n",
    "            s_width = s_width + width\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze stappen leveren uiteindelijk de features op die hierboven te zien zijn. Voor deze functie is er gebruik gemaakt van een 4x4 grid. Hierdoor hebben we 16 features tot onze beschikking. Dit kan natuurlijk ook in een andere formaat. Dit zal geanalyseerd moeten worden.\n",
    "\n",
    "Nu het gelukt is om een functie te schrijven die de features uit een afbeelding kan halen door middel van een grid, zullen we dit gebruiken in een grotere formaat. Het idee is om nu een preprocess functie te schrijven die per afbeelding de bovengenoemde stoppen repeteert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "error_counts = 0\n",
    "\n",
    "def initialize_image(image, image_name):\n",
    "    zipcode = image\n",
    "    zipcode = zipcode *-1\n",
    "    gray = color.rgb2gray(zipcode)\n",
    "    thresh = filters.threshold_otsu(gray)\n",
    "    binary = gray > thresh\n",
    "    binary_splitted = [binary[:, :32], binary[:, 32:64], binary[:, 64:96], binary[:, 96:128]]\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for x in range(0, len(binary_splitted)):\n",
    "        \n",
    "        test = binary_splitted[x]\n",
    "        height = 8\n",
    "        width = 8\n",
    "\n",
    "        s_width = 0\n",
    "        s_heigth = 0\n",
    "\n",
    "        df.loc[x, 'number'] = image_name[x]\n",
    "\n",
    "        for i in range(1, 17):\n",
    "            h = s_heigth+height\n",
    "            w = s_width+width\n",
    "            feat = test[s_heigth:h, s_width:w]\n",
    "            white_pixels = feat[feat==1]\n",
    "            total_white_pixels = len(white_pixels)\n",
    "            df.loc[x, i] = total_white_pixels\n",
    "            if (i%4 == 0):\n",
    "                s_width = 0\n",
    "                s_heigth = s_heigth + height\n",
    "            else:\n",
    "                s_width = s_width + width\n",
    "\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit betekent dat we nog niet klaar zijn. We moeten er namelijk voor zorgen dat de data goed leesbaar is voor het algoritme. De data is al in een nummer formaat, dus het is al geschikt voor het algoritme. Alleen zijn er nog wel wat verschillen in groottes tussen de data. We willen dus eigenlijk de data gaan normaliseren zodat de algoritme hiermee beter om kan gaan. Hiervoor zullen we twee bekende functies gebruiken:\n",
    "\n",
    "- MinMaxScaler\n",
    "- StandarScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     1     2     3     4     5     6     7     8     9    10    11  \\\n",
       "0        1   0.0   0.0  45.0   7.0   0.0  29.0  62.0   0.0   7.0  30.0  56.0   \n",
       "1        0   0.0  39.0  27.0   0.0   3.0  33.0  20.0   9.0  13.0  23.0  12.0   \n",
       "2        0   1.0  40.0  32.0   0.0   8.0  33.0  21.0   8.0   9.0  25.0   9.0   \n",
       "3        0   5.0  52.0  41.0   0.0  16.0  20.0  18.0  18.0  20.0  18.0  11.0   \n",
       "4        1   0.0  48.0   0.0   0.0  19.0  58.0   3.0   0.0   0.0  28.0  13.0   \n",
       "..     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "955      2  11.0  57.0  30.0   3.0   7.0  12.0  42.0   2.0   1.0  29.0  21.0   \n",
       "956      5  10.0  59.0  50.0   9.0   9.0  44.0  13.0  12.0   9.0  14.0  37.0   \n",
       "957      3  17.0  47.0  41.0  13.0  10.0  28.0  40.0   9.0   9.0  15.0  47.0   \n",
       "958      8  13.0  42.0  31.0  11.0  18.0  46.0  49.0  17.0  17.0  54.0  45.0   \n",
       "959      4   8.0  19.0  40.0  17.0   7.0  45.0  32.0  34.0  26.0  50.0  60.0   \n",
       "\n",
       "       12    13    14    15    16  \n",
       "0     0.0   0.0   0.0  42.0   5.0  \n",
       "1    16.0   3.0  41.0  41.0   4.0  \n",
       "2    17.0   0.0  43.0  41.0   8.0  \n",
       "3    23.0   2.0  44.0  43.0   7.0  \n",
       "4     0.0   0.0  52.0  59.0  27.0  \n",
       "..    ...   ...   ...   ...   ...  \n",
       "955   3.0   8.0  63.0  50.0  20.0  \n",
       "956   6.0   9.0  49.0  40.0   8.0  \n",
       "957  24.0  12.0  39.0  44.0  12.0  \n",
       "958  21.0   7.0  49.0  46.0  16.0  \n",
       "959  22.0  11.0  12.0  52.0  10.0  \n",
       "\n",
       "[960 rows x 17 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalerA = StandardScaler()\n",
    "scalerB = MinMaxScaler()\n",
    "result = pd.DataFrame()\n",
    "for i in range(0, len(all_images_df.index)):\n",
    "    image_name = all_images_df.iloc[i,0]\n",
    "    image = all_images_df.iloc[i,1]\n",
    "    tmp_result = initialize_image(image, image_name)\n",
    "    result = pd.concat([result, tmp_result])\n",
    "    \n",
    "result.reset_index(inplace=True)\n",
    "result.drop(columns=['index'], inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Hierboven is te zien dat het eruit halen van de features is gelukt. Dit heeft ons uiteindelijk 960 datapunten opgeleverd. Laten we verder met een \"describe\" functie gaan bekijken of er gebreken zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>960</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.00000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.973958</td>\n",
       "      <td>40.127083</td>\n",
       "      <td>36.930208</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.388542</td>\n",
       "      <td>36.345833</td>\n",
       "      <td>34.962500</td>\n",
       "      <td>6.810417</td>\n",
       "      <td>6.153125</td>\n",
       "      <td>31.022917</td>\n",
       "      <td>37.850000</td>\n",
       "      <td>8.566667</td>\n",
       "      <td>3.96250</td>\n",
       "      <td>36.465625</td>\n",
       "      <td>40.151042</td>\n",
       "      <td>9.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.829561</td>\n",
       "      <td>13.274848</td>\n",
       "      <td>13.717176</td>\n",
       "      <td>7.709561</td>\n",
       "      <td>6.242416</td>\n",
       "      <td>15.306639</td>\n",
       "      <td>15.980392</td>\n",
       "      <td>7.340483</td>\n",
       "      <td>6.426977</td>\n",
       "      <td>17.706549</td>\n",
       "      <td>13.952564</td>\n",
       "      <td>7.077681</td>\n",
       "      <td>4.21906</td>\n",
       "      <td>13.516717</td>\n",
       "      <td>13.723210</td>\n",
       "      <td>9.561216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number           1           2           3           4           5  \\\n",
       "count     960  960.000000  960.000000  960.000000  960.000000  960.000000   \n",
       "unique     10         NaN         NaN         NaN         NaN         NaN   \n",
       "top         1         NaN         NaN         NaN         NaN         NaN   \n",
       "freq      138         NaN         NaN         NaN         NaN         NaN   \n",
       "mean      NaN    4.973958   40.127083   36.930208    5.900000    7.388542   \n",
       "std       NaN    4.829561   13.274848   13.717176    7.709561    6.242416   \n",
       "min       NaN    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%       NaN    1.000000   35.000000   29.000000    0.000000    2.000000   \n",
       "50%       NaN    4.000000   43.000000   39.000000    3.000000    6.000000   \n",
       "75%       NaN    8.000000   50.000000   47.000000    8.000000   12.000000   \n",
       "max       NaN   23.000000   62.000000   64.000000   54.000000   31.000000   \n",
       "\n",
       "                 6           7           8           9          10  \\\n",
       "count   960.000000  960.000000  960.000000  960.000000  960.000000   \n",
       "unique         NaN         NaN         NaN         NaN         NaN   \n",
       "top            NaN         NaN         NaN         NaN         NaN   \n",
       "freq           NaN         NaN         NaN         NaN         NaN   \n",
       "mean     36.345833   34.962500    6.810417    6.153125   31.022917   \n",
       "std      15.306639   15.980392    7.340483    6.426977   17.706549   \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      25.000000   24.000000    1.000000    1.000000   15.750000   \n",
       "50%      39.000000   38.000000    5.000000    4.000000   32.000000   \n",
       "75%      48.000000   47.000000   10.000000    9.000000   46.000000   \n",
       "max      64.000000   64.000000   37.000000   39.000000   64.000000   \n",
       "\n",
       "                11          12         13          14          15          16  \n",
       "count   960.000000  960.000000  960.00000  960.000000  960.000000  960.000000  \n",
       "unique         NaN         NaN        NaN         NaN         NaN         NaN  \n",
       "top            NaN         NaN        NaN         NaN         NaN         NaN  \n",
       "freq           NaN         NaN        NaN         NaN         NaN         NaN  \n",
       "mean     37.850000    8.566667    3.96250   36.465625   40.151042    9.015625  \n",
       "std      13.952564    7.077681    4.21906   13.516717   13.723210    9.561216  \n",
       "min       0.000000    0.000000    0.00000    0.000000    0.000000    0.000000  \n",
       "25%      29.000000    3.000000    0.00000   30.750000   35.000000    2.000000  \n",
       "50%      39.000000    7.000000    3.00000   38.000000   43.000000    6.000000  \n",
       "75%      48.000000   13.000000    6.00000   45.250000   49.000000   13.000000  \n",
       "max      64.000000   35.000000   28.00000   64.000000   64.000000   50.000000  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het lijkt erop dat er geen missende velden zijn. Alleen wordt de \"number\" kolom, ook wel de output kolom gezien als een NaN. We zullen de waardes in deze kolom moeten omzetten naar werkelijke nummers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.00000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.942708</td>\n",
       "      <td>4.973958</td>\n",
       "      <td>40.127083</td>\n",
       "      <td>36.930208</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.388542</td>\n",
       "      <td>36.345833</td>\n",
       "      <td>34.962500</td>\n",
       "      <td>6.810417</td>\n",
       "      <td>6.153125</td>\n",
       "      <td>31.022917</td>\n",
       "      <td>37.850000</td>\n",
       "      <td>8.566667</td>\n",
       "      <td>3.96250</td>\n",
       "      <td>36.465625</td>\n",
       "      <td>40.151042</td>\n",
       "      <td>9.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.741914</td>\n",
       "      <td>4.829561</td>\n",
       "      <td>13.274848</td>\n",
       "      <td>13.717176</td>\n",
       "      <td>7.709561</td>\n",
       "      <td>6.242416</td>\n",
       "      <td>15.306639</td>\n",
       "      <td>15.980392</td>\n",
       "      <td>7.340483</td>\n",
       "      <td>6.426977</td>\n",
       "      <td>17.706549</td>\n",
       "      <td>13.952564</td>\n",
       "      <td>7.077681</td>\n",
       "      <td>4.21906</td>\n",
       "      <td>13.516717</td>\n",
       "      <td>13.723210</td>\n",
       "      <td>9.561216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           number           1           2           3           4           5  \\\n",
       "count  960.000000  960.000000  960.000000  960.000000  960.000000  960.000000   \n",
       "mean     3.942708    4.973958   40.127083   36.930208    5.900000    7.388542   \n",
       "std      2.741914    4.829561   13.274848   13.717176    7.709561    6.242416   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      2.000000    1.000000   35.000000   29.000000    0.000000    2.000000   \n",
       "50%      4.000000    4.000000   43.000000   39.000000    3.000000    6.000000   \n",
       "75%      6.000000    8.000000   50.000000   47.000000    8.000000   12.000000   \n",
       "max      9.000000   23.000000   62.000000   64.000000   54.000000   31.000000   \n",
       "\n",
       "                6           7           8           9          10          11  \\\n",
       "count  960.000000  960.000000  960.000000  960.000000  960.000000  960.000000   \n",
       "mean    36.345833   34.962500    6.810417    6.153125   31.022917   37.850000   \n",
       "std     15.306639   15.980392    7.340483    6.426977   17.706549   13.952564   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     25.000000   24.000000    1.000000    1.000000   15.750000   29.000000   \n",
       "50%     39.000000   38.000000    5.000000    4.000000   32.000000   39.000000   \n",
       "75%     48.000000   47.000000   10.000000    9.000000   46.000000   48.000000   \n",
       "max     64.000000   64.000000   37.000000   39.000000   64.000000   64.000000   \n",
       "\n",
       "               12         13          14          15          16  \n",
       "count  960.000000  960.00000  960.000000  960.000000  960.000000  \n",
       "mean     8.566667    3.96250   36.465625   40.151042    9.015625  \n",
       "std      7.077681    4.21906   13.516717   13.723210    9.561216  \n",
       "min      0.000000    0.00000    0.000000    0.000000    0.000000  \n",
       "25%      3.000000    0.00000   30.750000   35.000000    2.000000  \n",
       "50%      7.000000    3.00000   38.000000   43.000000    6.000000  \n",
       "75%     13.000000    6.00000   45.250000   49.000000   13.000000  \n",
       "max     35.000000   28.00000   64.000000   64.000000   50.000000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"number\"] = pd.to_numeric(result[\"number\"])\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben de kolom omgezet naar nummerieke waardes. Nu kunnen we de data dus ook goed analyseren. Er lijkt binnen de \"number\" kolom ook geen problemen te zijn. De kleinste waarde is een 0 en de grootste waarde is een 9. Dit klopt inderdaad ook aangezien een postcode de nummer 10 niet kan bevatten. Daarnaast kunnen we met de eerste describe functie herleiden, dat de dataset alle nummers tussen de 0-9 bevat, omdat er 10 unieke waardes zijn geconstateerd.\n",
    "\n",
    "De vraag is of de labels goed verdeeld zijn over elkaar in aantallen. Hiermee bedoelen we dat de ene getal 200 data punten heeft en de ander maar 20. Als dit namelijk het geval is zou dit kunnen leiden tot underfitting/overfitting. Dit zou alleen maar nadelig werken voor onze algoritme. Hiervoor moeten we dan de labels balanceren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number\n",
       "0     87\n",
       "1    138\n",
       "2    120\n",
       "3    128\n",
       "4    123\n",
       "5     84\n",
       "6     74\n",
       "7     62\n",
       "8     63\n",
       "9     81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.groupby(by='number').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we naar boven kijken dan lijkt het erop dat de labels aardig gebalanceerd zijn. Dit zou dus geen problemen moeten leveren voor het algoritme.\n",
    "\n",
    "Dit betekent dat we door kunnen gaan met de volgende stappen.\n",
    "\n",
    "Allereerst zullen we nu meerdere functies defineren om code duplicatie te voorkomen, dit voorkomt namelijk problemen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "\n",
    "def preprocess(X_train, X_test):\n",
    "    print('-----Start preprocc----------')\n",
    "    global features\n",
    "    X_train[features] = scalerB.fit_transform(X_train[features].to_numpy())\n",
    "    X_test[features] = scalerB.transform(X_test[features].to_numpy())\n",
    "    print('---------Preprocess Done--------')\n",
    "    return X_train, X_test\n",
    "\n",
    "def splitTrainTest(result):\n",
    "    # Split data into 50% train and 50% test subsets\n",
    "    global features\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        result[features], result['number'], test_size=0.3, random_state=0)\n",
    "    \n",
    "    X_train, X_test = preprocess(X_train, X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainen / Testen / Evalueren\n",
    "\n",
    "Inmiddels hebben we de data verzameld. We hebben de data geanalyseerd en de benodigde features eruit gehaald. De preprocessors staan ook klaar. Dit betekent dat we door kunnen gaan met het uitkiezen van de bijpassende algoritme.\n",
    "\n",
    "Omdat er meerdere algoritmes bestaan willen we graag de algoritme kiezen met de hoogste accuracy. Hiervoor zijn de volgende regels belangrijk:\n",
    "\n",
    "- Verschillende parameters gebruiken per algoritme om de hoogst mogelijke accuraatheid te halen.\n",
    "- Algoritme controleren op overfitting en underfitting\n",
    "\n",
    "Voor het testen van de algoritmes met verschillende parameters zullen we gebruik maken van Grid search. Hiermee kunnen we een lijst meegeven van parameters. De functie zal dan deze lijst aflopen en de parameters die de hoogste accuraatheid halen tonen.\n",
    "\n",
    "Om de algoritme te controleren op overfitting en underfitting zullen we gebruik maken van Kfolding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoek optimale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def searchHyperParams_Knn(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'n_neighbors' : [3,5,11,14,19],\n",
    "        'weights' : ['uniform', 'distance'],\n",
    "        'metric' : ['euclidean', 'manhattan', 'chebyshev']\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        KNeighborsClassifier(),\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.8958333333333334\n",
      "best estimator:\n",
      "KNeighborsClassifier(metric='euclidean', weights='distance')\n",
      "best params:\n",
      "{'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_Knn(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volgens de resultaten is de best behaalde accuraatheid score: 0.896 afgerond. Hiervoor worden de volgende parameters gebruikt:\n",
    "- Metric -> euclidean\n",
    "- n_neighbors -> 5\n",
    "- weights -> distance\n",
    "\n",
    "We zullen deze parameters gebruiken om de algoritme te trainen en testen op een gesplitste dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hercontroleren door middel van een pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "def usingPipelines_Knn(result):\n",
    "    knnClassifier = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean')\n",
    "    knnPipe = Pipeline([('scaler', MinMaxScaler()), ('clf', knnClassifier)])\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('-------train model----------')\n",
    "    knnPipe.fit(X_train, y_train)\n",
    "    print('----------score---------')\n",
    "    score = knnPipe.score(X_test, y_test)\n",
    "\n",
    "    print('----------done---------')\n",
    "    print('the score is: {0}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-------train model----------\n",
      "----------score---------\n",
      "----------done---------\n",
      "the score is: 0.90625\n"
     ]
    }
   ],
   "source": [
    "usingPipelines_Knn(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessant. Volgens de pipeline halen we nog steeds een hoge score. Zelfs een hoger score die we door middel van de grid search hebben gekregen. Het is voor alsnog hadden om de algoritme te testen op overfitting en underfitting. Hiervoor zullen we dus kfolding gebruiken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controleren overfitting en underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def fit_score_knn(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean')\n",
    "    neigh.fit(X_train, y_train.to_numpy().reshape(train_samples))\n",
    "\n",
    "    score = neigh.score(X_test, y_test.to_numpy().reshape(test_samples))\n",
    "    return score\n",
    "\n",
    "    # Explanation KneighborsClassifier\n",
    "\n",
    "#we want to test the  model for overfitting and underfitting. for this i will use Kfold.\n",
    "def kfolding_knn(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = fit_score_knn(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 1], score: 0.90625\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 2], score: 0.91667\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 3], score: 0.92708\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 4], score: 0.91146\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 5], score: 0.91667\n"
     ]
    }
   ],
   "source": [
    "kfolding_knn(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De algoritme lijkt alsnog zeer hoge scores te halen die rond de 90% zitten. Dit lijkt erop dat de algoritme geen last heeft van overfitting of underfitting. Doormiddel van kfolding en gridsearch hebben we de optimale algoritme kunnen maken voor het classificeren van de dataset door middel van een KNN classifier.\n",
    "\n",
    "Het gemiddelde behaalde score van de algoritme is 0.915626\n",
    "\n",
    "Dezelfde stappen die we hebben uitgevoerd voor de knn classifier zullen we ook gebruiken voor de rest van de classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "0.8472222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "score = gnb.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoek optimale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def searchHyperParams_svc(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'C': [0.1,1, 10, 100],\n",
    "        'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': [1,0.1,0.01,0.001]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        SVC(),\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.9136904761904763\n",
      "best estimator:\n",
      "SVC(C=10, gamma=1)\n",
      "best params:\n",
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_svc(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimale parameters:\n",
    "\n",
    "- C -> 10\n",
    "- gamma -> 1\n",
    "- kernel -> rbf\n",
    "- accuraatheid -> 91.37%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hercontroleren door middel van een pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usingPipelines_svc(result):\n",
    "    classifier = SVC(C=10, gamma=1, kernel='rbf')\n",
    "    svcPipe = Pipeline([('scaler', MinMaxScaler()), ('clf', classifier)])\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('-------train model----------')\n",
    "    svcPipe.fit(X_train, y_train)\n",
    "    print('----------score---------')\n",
    "    score = svcPipe.score(X_test, y_test)\n",
    "\n",
    "    print('----------done---------')\n",
    "    print('the score is: {0}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-------train model----------\n",
      "----------score---------\n",
      "----------done---------\n",
      "the score is: 0.9201388888888888\n"
     ]
    }
   ],
   "source": [
    "usingPipelines_svc(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controleren overfitting en underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score_svc(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    classifier = SVC(C=10, gamma=1, kernel='rbf')\n",
    "    classifier.fit(X_train, y_train.to_numpy().reshape(train_samples))\n",
    "\n",
    "    score = classifier.score(X_test, y_test.to_numpy().reshape(test_samples))\n",
    "    return score\n",
    "\n",
    "def kfolding_svc(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = fit_score_svc(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 1], score: 0.92188\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 2], score: 0.92708\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 3], score: 0.94792\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 4], score: 0.92188\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 5], score: 0.95312\n"
     ]
    }
   ],
   "source": [
    "kfolding_svc(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De algoritme lijkt alsnog zeer hoge scores te halen die rond de 90% zitten. Dit lijkt erop dat de algoritme geen last heeft van overfitting of underfitting. Doormiddel van kfolding en gridsearch hebben we de optimale algoritme kunnen maken voor het classificeren van de dataset door middel van een SVC classifier.\n",
    "\n",
    "Het gemiddelde behaalde score van de algoritme is 0.934376"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree\n",
    "## Zoek optimale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def searchHyperParams_DT(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter' : ['best', 'random'],\n",
    "        'max_depth': [1,5,10,20,50,100,150,None],\n",
    "        'min_samples_split': np.arange(2,5),\n",
    "        'min_samples_leaf': np.arange(1,5),\n",
    "        'min_weight_fraction_leaf': np.arange(0,0.5)\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        DecisionTreeClassifier(),\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 384 candidates, totalling 1152 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.7157738095238094\n",
      "best estimator:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=2,\n",
      "                       min_samples_split=3)\n",
      "best params:\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_DT(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimale parameters:\n",
    "\n",
    "- Criterion -> gini\n",
    "- max-depth -> None\n",
    "- min_samples_leaf -> 1\n",
    "- min_samples_split -> 2\n",
    "- min_weight_fraction_leaf -> 0.0\n",
    "- splitter -> best\n",
    "- accuraatheid -> 72.17%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hercontroleren door middel van een pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usingPipelines_dt(result):\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=2,\n",
    "                       min_samples_split=3)\n",
    "    dtPipe = Pipeline([('scaler', MinMaxScaler()), ('clf', classifier)])\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('-------train model----------')\n",
    "    dtPipe.fit(X_train, y_train)\n",
    "    print('----------score---------')\n",
    "    score = dtPipe.score(X_test, y_test)\n",
    "\n",
    "    print('----------done---------')\n",
    "    print('the score is: {0}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-------train model----------\n",
      "----------score---------\n",
      "----------done---------\n",
      "the score is: 0.7048611111111112\n"
     ]
    }
   ],
   "source": [
    "usingPipelines_dt(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controleren overfitting en underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score_dt(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=2,\n",
    "                       min_samples_split=3)\n",
    "    classifier.fit(X_train, y_train.to_numpy().reshape(train_samples))\n",
    "\n",
    "    score = classifier.score(X_test, y_test.to_numpy().reshape(test_samples))\n",
    "    return score\n",
    "\n",
    "def kfolding_dt(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = fit_score_dt(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 1], score: 0.79688\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 2], score: 0.76042\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 3], score: 0.71875\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 4], score: 0.69792\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 5], score: 0.76562\n"
     ]
    }
   ],
   "source": [
    "kfolding_dt(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De algoritme lijkt alsnog ongeveer dezelfde resultaten te behalen. Dit lijkt erop dat de algoritme geen last heeft van overfitting of underfitting. Doormiddel van kfolding en gridsearch hebben we de optimale algoritme kunnen maken voor het classificeren van de dataset door middel van een Decision Tree classifier.\n",
    "\n",
    "Het gemiddelde behaalde score van de algoritme is 0.747918"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "## Zoek optimale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def searchHyperParams_RC(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'bootstrap': [True, False],\n",
    "         'max_depth': [10, 20, 30, 40, None],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_leaf': [1, 2, 4],\n",
    "         'min_samples_split': [2, 5, 10],\n",
    "         'n_estimators': [200, 400, 600, 800]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        RandomForestClassifier(),\n",
    "        grid_params,\n",
    "        verbose = 3,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-19de73090f82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearchHyperParams_RC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-83-c47092e52f28>\u001b[0m in \u001b[0;36msearchHyperParams_RC\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'---------grid search started---------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mgs_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--------Done--------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "searchHyperParams_RC(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimale parameters:\n",
    "\n",
    "- bootstrap -> False\n",
    "- max-depth -> 30\n",
    "- max_features -> sqrt\n",
    "- min_samples_leaf -> 1\n",
    "- min_samples_split -> 2\n",
    "- n_estimators -> 20\n",
    "- accuraatheid -> 90.18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hercontroleren door middel van een pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usingPipelines_rf(result):\n",
    "    classifier = RandomForestClassifier(n_estimators=800)\n",
    "    rfPipe = Pipeline([('scaler', MinMaxScaler()), ('clf', classifier)])\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('-------train model----------')\n",
    "    rfPipe.fit(X_train, y_train)\n",
    "    print('----------score---------')\n",
    "    score = rfPipe.score(X_test, y_test)\n",
    "\n",
    "    print('----------done---------')\n",
    "    print('the score is: {0}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-------train model----------\n",
      "----------score---------\n",
      "----------done---------\n",
      "the score is: 0.8958333333333334\n"
     ]
    }
   ],
   "source": [
    "usingPipelines_rf(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controleren overfitting en underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score_rf(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    classifier = RandomForestClassifier(n_estimators=800)\n",
    "    classifier.fit(X_train, y_train.to_numpy().reshape(train_samples))\n",
    "\n",
    "    score = classifier.score(X_test, y_test.to_numpy().reshape(test_samples))\n",
    "    return score\n",
    "\n",
    "def kfolding_rf(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = fit_score_rf(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 1], score: 0.90104\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 2], score: 0.89062\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 3], score: 0.92708\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 4], score: 0.89583\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 5], score: 0.87500\n"
     ]
    }
   ],
   "source": [
    "kfolding_rf(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De algoritme lijkt alsnog zeer hoge scores te halen die rond de 90% zitten. Dit lijkt erop dat de algoritme geen last heeft van overfitting of underfitting. Doormiddel van kfolding en gridsearch hebben we de optimale algoritme kunnen maken voor het classificeren van de dataset door middel van een Random Forest classifier.\n",
    "\n",
    "Het gemiddelde behaalde score van de algoritme is 0.897914\n",
    "\n",
    "Volgens de resultaten zijn dit de gemiddelde behaalde scores:\n",
    "\n",
    "- KNN -> 0.915626\n",
    "- SVC -> 0.934376\n",
    "- DT -> 0.747918\n",
    "- RF -> 0.897914\n",
    "\n",
    "SVC lijkt ook voor grid based classificatie de beste resultaten te leveren. Laten we de resultaten in een grafiek plaatsen om te kijken of de algoritme ook consistent is.\n",
    "\n",
    "## Weergave grafiek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Config: size of the figures\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "fix, axs = plt.subplots(2,2)\n",
    "\n",
    "knn_ax = [0.90625, 0.91667, 0.92708, 0.91146, 0.91667]\n",
    "svc_ax = [0.92188, 0.92708, 0.94792, 0.92188, 0.95312]\n",
    "dt_ax = [0.79688, 0.76042, 0.71875, 0.69792, 0.76562]\n",
    "rf_ax = [0.90104, 0.89062, 0.92708, 0.89583, 0.87500]\n",
    "\n",
    "x = np.arange(5)\n",
    "\n",
    "axs[0, 0].plot(x, knn_ax)\n",
    "axs[0, 0].set_title('Knn')\n",
    "axs[0, 0].set_ylim([0,1])\n",
    "axs[0, 1].plot(x, svc_ax, 'tab:orange')\n",
    "axs[0, 1].set_title('Svc')\n",
    "axs[0, 1].set_ylim([0,1])\n",
    "axs[1, 0].plot(x, dt_ax, 'tab:green')\n",
    "axs[1, 0].set_title('Decision Trees')\n",
    "axs[1, 0].set_ylim([0,1])\n",
    "axs[1, 1].plot(x, rf_ax, 'tab:red')\n",
    "axs[1, 1].set_title('Random Forest')\n",
    "axs[1, 1].set_ylim([0,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volgens de grafieken levert de SVC classifier ook een consistent resultaat. Dit lijkt de optimale algoritme die we kunnen gebruiken om de postcodes te classificeren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultaten\n",
    "\n",
    "Volgens de resultaten is .. de beste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de vorige hoofstuk hebben we geconcludeerd dat de SVC classifier de beste keuze is voor deze hoofdstuk. Nu is het tijd om de algoritme te gebruiken voor het classificeren van postcodes.\n",
    "\n",
    "Hiervoor gaan we de totale dataset aan 480 afbeeldingen gebruiken en deze splitsen in train en test data. De test data zullen we uiteindelijk gebruiken voor het berekenen van de accuraatheid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number     1     2     3    4     5     6     7     8     9    10    11  \\\n",
       "0         1   0.0   3.0  47.0  0.0   6.0  42.0  52.0   0.0   4.0  18.0  41.0   \n",
       "1         4   0.0  19.0  22.0  0.0   1.0  39.0  11.0  21.0  25.0  41.0  47.0   \n",
       "2         9   0.0  42.0  41.0  1.0   1.0  46.0  49.0  12.0   5.0   2.0  31.0   \n",
       "3         5   3.0  58.0  46.0  2.0  12.0  52.0  12.0   0.0   1.0  17.0  35.0   \n",
       "4         4   9.0  10.0  52.0  6.0  13.0  33.0  51.0   8.0  23.0  57.0  59.0   \n",
       "...     ...   ...   ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "1723      7   2.0  53.0  55.0  7.0   4.0  37.0  61.0  23.0   1.0  36.0  36.0   \n",
       "1724      6   8.0  38.0  18.0  2.0   8.0  44.0   4.0   6.0   8.0  56.0  36.0   \n",
       "1725      1   7.0   2.0  54.0  2.0  10.0  36.0  60.0   6.0   8.0  22.0  52.0   \n",
       "1726      7  10.0  44.0  58.0  5.0   4.0  30.0  58.0  14.0   4.0  44.0  40.0   \n",
       "1727      3   9.0  52.0  41.0  5.0  10.0  49.0  32.0   3.0   7.0  25.0  49.0   \n",
       "\n",
       "        12    13    14    15    16  \n",
       "0      0.0   0.0   4.0  49.0   5.0  \n",
       "1      9.0  13.0  29.0  33.0   0.0  \n",
       "2     12.0   8.0  46.0  40.0   1.0  \n",
       "3      0.0   0.0  49.0  25.0   0.0  \n",
       "4     14.0  10.0   7.0  58.0  10.0  \n",
       "...    ...   ...   ...   ...   ...  \n",
       "1723   4.0   3.0  48.0   8.0   2.0  \n",
       "1724  21.0   5.0  40.0  46.0  23.0  \n",
       "1725   7.0   4.0   6.0  52.0   9.0  \n",
       "1726   8.0  10.0  49.0   8.0   9.0  \n",
       "1727  14.0  12.0  48.0  50.0   8.0  \n",
       "\n",
       "[1728 rows x 17 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_df = load_images_from_folder('../dataset-images/all_images')\n",
    "train_images_df = all_images_df.sample(frac=0.9, random_state=25)\n",
    "test_images_df = all_images_df.drop(train_images_df.index)\n",
    "train_images_df.reset_index(inplace=True,drop=True)\n",
    "test_images_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(train_images_df.index)):\n",
    "    image_name = train_images_df.iloc[i,0]\n",
    "    image = train_images_df.iloc[i,1]\n",
    "    tmp_result = initialize_image(image, image_name)\n",
    "    result = pd.concat([result, tmp_result])\n",
    "\n",
    "\n",
    "result.reset_index(inplace=True)\n",
    "result.drop(columns=['index'], inplace=True)\n",
    "\n",
    "features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "\n",
    "all_zipcodes = []\n",
    "total_images = len(test_images_df.index)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>7</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number     1         2         3         4         5         6         7  \\\n",
       "0         1  0.00  0.047619  0.734375  0.000000  0.193548  0.656250  0.812500   \n",
       "1         4  0.00  0.301587  0.343750  0.000000  0.032258  0.609375  0.171875   \n",
       "2         9  0.00  0.666667  0.640625  0.018519  0.032258  0.718750  0.765625   \n",
       "3         5  0.12  0.920635  0.718750  0.037037  0.387097  0.812500  0.187500   \n",
       "4         4  0.36  0.158730  0.812500  0.111111  0.419355  0.515625  0.796875   \n",
       "...     ...   ...       ...       ...       ...       ...       ...       ...   \n",
       "1723      7  0.08  0.841270  0.859375  0.129630  0.129032  0.578125  0.953125   \n",
       "1724      6  0.32  0.603175  0.281250  0.037037  0.258065  0.687500  0.062500   \n",
       "1725      1  0.28  0.031746  0.843750  0.037037  0.322581  0.562500  0.937500   \n",
       "1726      7  0.40  0.698413  0.906250  0.092593  0.129032  0.468750  0.906250   \n",
       "1727      3  0.36  0.825397  0.640625  0.092593  0.322581  0.765625  0.500000   \n",
       "\n",
       "             8         9        10        11        12        13        14  \\\n",
       "0     0.000000  0.102564  0.281250  0.640625  0.000000  0.000000  0.062500   \n",
       "1     0.567568  0.641026  0.640625  0.734375  0.250000  0.464286  0.453125   \n",
       "2     0.324324  0.128205  0.031250  0.484375  0.333333  0.285714  0.718750   \n",
       "3     0.000000  0.025641  0.265625  0.546875  0.000000  0.000000  0.765625   \n",
       "4     0.216216  0.589744  0.890625  0.921875  0.388889  0.357143  0.109375   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1723  0.621622  0.025641  0.562500  0.562500  0.111111  0.107143  0.750000   \n",
       "1724  0.162162  0.205128  0.875000  0.562500  0.583333  0.178571  0.625000   \n",
       "1725  0.162162  0.205128  0.343750  0.812500  0.194444  0.142857  0.093750   \n",
       "1726  0.378378  0.102564  0.687500  0.625000  0.222222  0.357143  0.765625   \n",
       "1727  0.081081  0.179487  0.390625  0.765625  0.388889  0.428571  0.750000   \n",
       "\n",
       "            15    16  \n",
       "0     0.765625  0.10  \n",
       "1     0.515625  0.00  \n",
       "2     0.625000  0.02  \n",
       "3     0.390625  0.00  \n",
       "4     0.906250  0.20  \n",
       "...        ...   ...  \n",
       "1723  0.125000  0.04  \n",
       "1724  0.718750  0.46  \n",
       "1725  0.812500  0.18  \n",
       "1726  0.125000  0.18  \n",
       "1727  0.781250  0.16  \n",
       "\n",
       "[1728 rows x 17 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[features] = scaler.fit_transform(result[features].to_numpy())\n",
    "\n",
    "svc_clf = SVC(C=10, gamma=1)\n",
    "svc_clf.fit(result[features], result['number'])\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, total_images):\n",
    "    \n",
    "    image_name = test_images_df.iloc[i, 0]\n",
    "    image = test_images_df.iloc[i, 1]\n",
    "    tmp_result = initialize_image(image, image_name)\n",
    "    test_result = tmp_result\n",
    "    test_result.reset_index(inplace=True,drop=True)\n",
    "    test_result['number'] = test_result['number'].astype(int)\n",
    "    test_result[features] = scaler.transform(test_result[features].to_numpy())\n",
    "    \n",
    "    # classify\n",
    "    predicted = svc_clf.predict(test_result[features])\n",
    "    #print(predicted)\n",
    "    all_zipcodes.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  1 4 8 9\n",
      "original:  ['1489']\n",
      "predicted:  1 5 6 5\n",
      "original:  ['1865']\n",
      "predicted:  1 9 0 4\n",
      "original:  ['1904']\n",
      "predicted:  2 6 0 8\n",
      "original:  ['2608']\n",
      "predicted:  2 7 0 8\n",
      "original:  ['2708']\n",
      "predicted:  2 9 7 1\n",
      "original:  ['2971']\n",
      "predicted:  3 3 4 6\n",
      "original:  ['3046']\n",
      "predicted:  3 4 1 7\n",
      "original:  ['3417']\n",
      "predicted:  3 5 2 1\n",
      "original:  ['3521']\n",
      "predicted:  3 5 3 6\n",
      "original:  ['3536']\n",
      "predicted:  3 5 9 1\n",
      "original:  ['3591']\n",
      "predicted:  3 6 0 6\n",
      "original:  ['3606']\n",
      "predicted:  3 6 4 1\n",
      "original:  ['3648']\n",
      "predicted:  3 7 8 1\n",
      "original:  ['3711']\n",
      "predicted:  3 7 4 6\n",
      "original:  ['3746']\n",
      "predicted:  3 3 2 1\n",
      "original:  ['3921']\n",
      "predicted:  3 9 8 9\n",
      "original:  ['3988']\n",
      "predicted:  4 0 0 6\n",
      "original:  ['4006']\n",
      "predicted:  4 1 3 4\n",
      "original:  ['4134']\n",
      "predicted:  4 7 6 4\n",
      "original:  ['4764']\n",
      "predicted:  5 0 7 1\n",
      "original:  ['5071']\n",
      "predicted:  5 5 3 9\n",
      "original:  ['5539']\n",
      "predicted:  5 5 5 1\n",
      "original:  ['5551']\n",
      "predicted:  4 3 7 8\n",
      "original:  ['5578']\n",
      "predicted:  5 6 4 3\n",
      "original:  ['5643']\n",
      "predicted:  6 3 9 6\n",
      "original:  ['6396']\n",
      "predicted:  6 3 3 9\n",
      "original:  ['6399']\n",
      "predicted:  6 4 0 3\n",
      "original:  ['6403']\n",
      "predicted:  6 6 3 9\n",
      "original:  ['6639']\n",
      "predicted:  6 6 5 2\n",
      "original:  ['6652']\n",
      "predicted:  6 6 5 8\n",
      "original:  ['6658']\n",
      "predicted:  7 1 6 9\n",
      "original:  ['7169']\n",
      "predicted:  7 2 5 6\n",
      "original:  ['7256']\n",
      "predicted:  7 7 7 9\n",
      "original:  ['7779']\n",
      "predicted:  8 0 6 4\n",
      "original:  ['8060']\n",
      "predicted:  8 3 9 5\n",
      "original:  ['8395']\n",
      "predicted:  8 4 3 2\n",
      "original:  ['8432']\n",
      "predicted:  1 5 4 3\n",
      "original:  ['8543']\n",
      "predicted:  8 8 4 3\n",
      "original:  ['8893']\n",
      "predicted:  8 9 9 7\n",
      "original:  ['8997']\n",
      "predicted:  9 0 0 2\n",
      "original:  ['9002']\n",
      "predicted:  3 1 1 1\n",
      "original:  ['9111']\n",
      "predicted:  9 3 0 6\n",
      "original:  ['9306']\n",
      "predicted:  9 3 1 0\n",
      "original:  ['9310']\n",
      "predicted:  9 5 3 4\n",
      "original:  ['9534']\n",
      "predicted:  9 6 8 1\n",
      "original:  ['9611']\n",
      "predicted:  9 7 2 6\n",
      "original:  ['9726']\n",
      "predicted:  9 8 3 8\n",
      "original:  ['9838']\n",
      "accuracy is:  72.91666666666666\n"
     ]
    }
   ],
   "source": [
    "def concat(a, b, c, d):\n",
    "    return int(f\"{a}{b}{c}{d}\")\n",
    "\n",
    "positive = 0\n",
    "for i in range(0, len(all_zipcodes)):\n",
    "    print('predicted: ', all_zipcodes[i][0], all_zipcodes[i][1], all_zipcodes[i][2], all_zipcodes[i][3])\n",
    "    print('original: ',  test_images_df.loc[i,['name']].to_numpy())\n",
    "    concatted = concat(all_zipcodes[i][0], all_zipcodes[i][1], all_zipcodes[i][2], all_zipcodes[i][3])\n",
    "    if concatted == int(test_images_df.loc[i,['name']]):\n",
    "        positive = positive + 1\n",
    "    \n",
    "numberItems = len(all_zipcodes)\n",
    "\n",
    "accuracyy = positive / numberItems * 100\n",
    "\n",
    "print('accuracy is: ', accuracyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie\n",
    "\n",
    "De algoritme levert een accuraatheid op van 72.92%. Dit is al een stuk hoger dan de image based classificatie. Voor de zekerheid heb ik ook gebruikt gemaakt van de standardscalar. Dit levert een nog lagere score op. Het lijkt erop dat door middel van grid based classificatie de resultaten er beter eruit zien.\n",
    "\n",
    "Alsnog is dit niet het optimale resultaat dat we willen behalen. In de volgende notebook zullen we proberen deze 2 methodes te combineren met elkaar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
