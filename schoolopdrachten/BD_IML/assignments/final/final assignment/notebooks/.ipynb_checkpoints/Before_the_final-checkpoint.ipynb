{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Number : 408846\n",
    "## Student Name : Ibrahim Sahin\n",
    "\n",
    "# Image based en Grid based classificatie\n",
    "\n",
    "In de voorgaande notebooks hebben we gekeken naar de mogelijkheden van image based en grid based classificatie. In deze notebook zullen we de features gebruiken van beide notebooks om te kijken of dit betere resultaten oplevert.\n",
    "\n",
    "## Uitvoering\n",
    "\n",
    "Om dit probleem op te pakken zullen we de workflow hanteren die voornamelijk worden gebruikt binnen een Machine learning probleem (Data Science lifecycle). De workflow is te verdelen in de volgende stappen:\n",
    "\n",
    "1. Data verzamelen\n",
    "2. Data analyseren\n",
    "3. Preprocessen\n",
    "4. Feature engineering\n",
    "5. Trainen / Testen / Evalueren\n",
    "\n",
    "Allereerst beginnen we met het importeren van de libraries die we nodig zullen hebben in onze code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage\n",
    "\n",
    "from skimage import io, transform, color, filters, data, morphology, measure\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    images_name = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = io.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            images_name.append(filename[0:4])\n",
    "    \n",
    "    images_df = pd.DataFrame({\"name\": images_name,\n",
    "                             \"image\": images})\n",
    "\n",
    "    return images_df\n",
    "\n",
    "def display(np_image):\n",
    "    \"\"\"\n",
    "    This is a display function that we have added to show numpy images at full size\n",
    "    If you pass in an image with 3 channels, it will be displayed in RGB\n",
    "    If you passn in an image with 1 channel, it will be displayed in grayscale\n",
    "    \"\"\"\n",
    "    dpi = matplotlib.rcParams['figure.dpi']\n",
    "    if len(np_image.shape) == 3:\n",
    "        height, width, depth = np_image.shape\n",
    "    else:\n",
    "        height, width = np_image.shape\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Display the image in either RGB or grayscale (depending on the amount of dimensions)\n",
    "    if (len(np_image.shape) >= 3):\n",
    "        ax.imshow(np_image)\n",
    "    else:\n",
    "        ax.imshow(np_image, cmap='gray')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "all_images_df = load_images_from_folder('../dataset-images/all_images')\n",
    "all_images_df\n",
    "train_images_df = all_images_df.sample(frac=0.9, random_state=25)\n",
    "\n",
    "test_images_df = all_images_df.drop(train_images_df.index)\n",
    "\n",
    "train_images_df.reset_index(inplace=True,drop=True)\n",
    "test_images_df.reset_index(inplace=True,drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hierboven gedefineerde functies zijn geleverd door Saxion zelf. Die zullen gebruikt worden voor het inladen van de data en het tonen van de afbeeldingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_image_grids(image, image_name):\n",
    "    zipcode = image\n",
    "    zipcode = zipcode *-1\n",
    "    gray = color.rgb2gray(zipcode)\n",
    "    thresh = filters.threshold_otsu(gray)\n",
    "    binary = gray > thresh\n",
    "    binary_splitted = [binary[:, :32], binary[:, 32:64], binary[:, 64:96], binary[:, 96:128]]\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    lol = len(binary_splitted)\n",
    "    if (lol < 4):\n",
    "        print('splitted is smaller than 4')\n",
    "    for x in range(0, len(binary_splitted)):\n",
    "        \n",
    "        test = binary_splitted[x]\n",
    "        height = 8\n",
    "        width = 8\n",
    "\n",
    "        s_width = 0\n",
    "        s_heigth = 0\n",
    "\n",
    "        df.loc[x, 'zip_number'] = image_name[x]\n",
    "\n",
    "        for i in range(1, 17):\n",
    "            h = s_heigth+height\n",
    "            w = s_width+width\n",
    "            feat = test[s_heigth:h, s_width:w]\n",
    "            white_pixels = feat[feat==1]\n",
    "            total_white_pixels = len(white_pixels)\n",
    "            df.loc[x, i] = total_white_pixels\n",
    "            if (i%4 == 0):\n",
    "                s_width = 0\n",
    "                s_heigth = s_heigth + height\n",
    "            else:\n",
    "                s_width = s_width + width\n",
    "        \n",
    "    return df\n",
    "\n",
    "image_properties = ['label', 'area', 'centroid', \n",
    "                    'perimeter', 'eccentricity', 'euler_number',\n",
    "                    'filled_area','perimeter_crofton', 'local_centroid', \n",
    "                    'major_axis_length', 'minor_axis_length', 'orientation']\n",
    "\n",
    "def initialize_image_props(image, image_name):\n",
    "    zipcode = image\n",
    "    zipcode = zipcode *-1\n",
    "    gray = color.rgb2gray(zipcode)\n",
    "    thresh = filters.threshold_otsu(gray)\n",
    "    binary = gray > thresh\n",
    "    \n",
    "    # remove the white small spots/dots\n",
    "    binary = morphology.binary_opening(binary)\n",
    "    \n",
    "    # make the white zip numbers thicker\n",
    "    binary = morphology.binary_dilation(binary)\n",
    "    \n",
    "    # some numbers may have holes in it. That could seperate the number in 2 different labels. with closing the gap will be closed\n",
    "    binary = morphology.binary_closing(binary)\n",
    "    \n",
    "    # return number back to its original state before it was made thicker. make the numbers thinner\n",
    "    binary = morphology.binary_erosion(binary)\n",
    "    \n",
    "    label_image, total_labels = measure.label(binary, return_num=True)\n",
    "\n",
    "    global image_properties\n",
    "    props = measure.regionprops_table(label_image, properties=image_properties)\n",
    "    tmp_df = pd.DataFrame(props)\n",
    "    \n",
    "    # filter out labels that have too small areas. these labels are small dots that could not be filled with the opening function\n",
    "    tmp_df = tmp_df.query('area > 50').reset_index(drop=True)\n",
    "\n",
    "    zip_numbers = list(image_name)[:4]\n",
    "        \n",
    "    return tmp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>euler_number</th>\n",
       "      <th>filled_area</th>\n",
       "      <th>perimeter_crofton</th>\n",
       "      <th>local_centroid-0</th>\n",
       "      <th>local_centroid-1</th>\n",
       "      <th>major_axis_length</th>\n",
       "      <th>minor_axis_length</th>\n",
       "      <th>orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.840620</td>\n",
       "      <td>0.879793</td>\n",
       "      <td>1</td>\n",
       "      <td>272</td>\n",
       "      <td>87.855766</td>\n",
       "      <td>15.238971</td>\n",
       "      <td>10.816176</td>\n",
       "      <td>32.379127</td>\n",
       "      <td>15.391637</td>\n",
       "      <td>0.044635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>124.124892</td>\n",
       "      <td>0.676449</td>\n",
       "      <td>1</td>\n",
       "      <td>311</td>\n",
       "      <td>120.359293</td>\n",
       "      <td>17.598071</td>\n",
       "      <td>11.803859</td>\n",
       "      <td>30.923689</td>\n",
       "      <td>22.774959</td>\n",
       "      <td>-0.284669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>141.438600</td>\n",
       "      <td>0.818740</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>134.092201</td>\n",
       "      <td>15.252149</td>\n",
       "      <td>11.183381</td>\n",
       "      <td>36.800284</td>\n",
       "      <td>21.129437</td>\n",
       "      <td>-0.044963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>113.053824</td>\n",
       "      <td>0.904714</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>109.863263</td>\n",
       "      <td>13.984802</td>\n",
       "      <td>7.772036</td>\n",
       "      <td>37.710584</td>\n",
       "      <td>16.065428</td>\n",
       "      <td>-0.005646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.811183</td>\n",
       "      <td>0.795305</td>\n",
       "      <td>1</td>\n",
       "      <td>352</td>\n",
       "      <td>96.360393</td>\n",
       "      <td>16.701705</td>\n",
       "      <td>12.798295</td>\n",
       "      <td>30.494542</td>\n",
       "      <td>18.486091</td>\n",
       "      <td>-0.018643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.740115</td>\n",
       "      <td>0.836679</td>\n",
       "      <td>1</td>\n",
       "      <td>382</td>\n",
       "      <td>89.656600</td>\n",
       "      <td>12.654450</td>\n",
       "      <td>8.657068</td>\n",
       "      <td>32.454314</td>\n",
       "      <td>17.775027</td>\n",
       "      <td>-0.138335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>127.438600</td>\n",
       "      <td>0.826591</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>120.819369</td>\n",
       "      <td>18.587692</td>\n",
       "      <td>8.375385</td>\n",
       "      <td>34.897599</td>\n",
       "      <td>19.640498</td>\n",
       "      <td>0.304641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.740115</td>\n",
       "      <td>0.870053</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>89.656600</td>\n",
       "      <td>15.161404</td>\n",
       "      <td>11.564912</td>\n",
       "      <td>32.025504</td>\n",
       "      <td>15.787250</td>\n",
       "      <td>0.006075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.982756</td>\n",
       "      <td>0.874299</td>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>106.951708</td>\n",
       "      <td>13.219585</td>\n",
       "      <td>8.498516</td>\n",
       "      <td>35.514176</td>\n",
       "      <td>17.238121</td>\n",
       "      <td>-0.188826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.781746</td>\n",
       "      <td>0.888024</td>\n",
       "      <td>1</td>\n",
       "      <td>368</td>\n",
       "      <td>118.137852</td>\n",
       "      <td>16.138587</td>\n",
       "      <td>9.271739</td>\n",
       "      <td>38.976945</td>\n",
       "      <td>17.921454</td>\n",
       "      <td>0.071269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      zip_number     1     2     3    4     5     6     7     8     9  ...  \\\n",
       "0              1   0.0   3.0  47.0  0.0   6.0  42.0  52.0   0.0   4.0  ...   \n",
       "1              4   0.0  19.0  22.0  0.0   1.0  39.0  11.0  21.0  25.0  ...   \n",
       "2              9   0.0  42.0  41.0  1.0   1.0  46.0  49.0  12.0   5.0  ...   \n",
       "3              5   3.0  58.0  46.0  2.0  12.0  52.0  12.0   0.0   1.0  ...   \n",
       "4              4   9.0  10.0  52.0  6.0  13.0  33.0  51.0   8.0  23.0  ...   \n",
       "...          ...   ...   ...   ...  ...   ...   ...   ...   ...   ...  ...   \n",
       "1723           7   2.0  53.0  55.0  7.0   4.0  37.0  61.0  23.0   1.0  ...   \n",
       "1724           6   8.0  38.0  18.0  2.0   8.0  44.0   4.0   6.0   8.0  ...   \n",
       "1725           1   7.0   2.0  54.0  2.0  10.0  36.0  60.0   6.0   8.0  ...   \n",
       "1726           7  10.0  44.0  58.0  5.0   4.0  30.0  58.0  14.0   4.0  ...   \n",
       "1727           3   9.0  52.0  41.0  5.0  10.0  49.0  32.0   3.0   7.0  ...   \n",
       "\n",
       "       perimeter  eccentricity  euler_number  filled_area  perimeter_crofton  \\\n",
       "0      89.840620      0.879793             1          272          87.855766   \n",
       "1     124.124892      0.676449             1          311         120.359293   \n",
       "2     141.438600      0.818740             0          388         134.092201   \n",
       "3     113.053824      0.904714             1          329         109.863263   \n",
       "4      98.811183      0.795305             1          352          96.360393   \n",
       "...          ...           ...           ...          ...                ...   \n",
       "1723   91.740115      0.836679             1          382          89.656600   \n",
       "1724  127.438600      0.826591             0          363         120.819369   \n",
       "1725   91.740115      0.870053             1          285          89.656600   \n",
       "1726  109.982756      0.874299             1          337         106.951708   \n",
       "1727  121.781746      0.888024             1          368         118.137852   \n",
       "\n",
       "      local_centroid-0  local_centroid-1  major_axis_length  \\\n",
       "0            15.238971         10.816176          32.379127   \n",
       "1            17.598071         11.803859          30.923689   \n",
       "2            15.252149         11.183381          36.800284   \n",
       "3            13.984802          7.772036          37.710584   \n",
       "4            16.701705         12.798295          30.494542   \n",
       "...                ...               ...                ...   \n",
       "1723         12.654450          8.657068          32.454314   \n",
       "1724         18.587692          8.375385          34.897599   \n",
       "1725         15.161404         11.564912          32.025504   \n",
       "1726         13.219585          8.498516          35.514176   \n",
       "1727         16.138587          9.271739          38.976945   \n",
       "\n",
       "      minor_axis_length  orientation  \n",
       "0             15.391637     0.044635  \n",
       "1             22.774959    -0.284669  \n",
       "2             21.129437    -0.044963  \n",
       "3             16.065428    -0.005646  \n",
       "4             18.486091    -0.018643  \n",
       "...                 ...          ...  \n",
       "1723          17.775027    -0.138335  \n",
       "1724          19.640498     0.304641  \n",
       "1725          15.787250     0.006075  \n",
       "1726          17.238121    -0.188826  \n",
       "1727          17.921454     0.071269  \n",
       "\n",
       "[1728 rows x 30 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(train_images_df.index)):\n",
    "    image_name = train_images_df.iloc[i,0]\n",
    "    image = train_images_df.iloc[i,1]\n",
    "    tmp_result_grid = initialize_image_grids(image, image_name)\n",
    "    tmp_result_props = initialize_image_props(image, image_name)\n",
    "    tmp_result = pd.concat([tmp_result_grid,tmp_result_props], axis=1)\n",
    "    result = pd.concat([result, tmp_result])\n",
    "\n",
    "\n",
    "result.reset_index(inplace=True, drop=True)\n",
    "result.drop(columns=['label'], inplace=True)\n",
    "result[\"zip_number\"] = pd.to_numeric(result[\"zip_number\"])\n",
    "result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>euler_number</th>\n",
       "      <th>filled_area</th>\n",
       "      <th>perimeter_crofton</th>\n",
       "      <th>local_centroid-0</th>\n",
       "      <th>local_centroid-1</th>\n",
       "      <th>major_axis_length</th>\n",
       "      <th>minor_axis_length</th>\n",
       "      <th>orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.506366</td>\n",
       "      <td>5.077546</td>\n",
       "      <td>40.752315</td>\n",
       "      <td>37.320023</td>\n",
       "      <td>6.612847</td>\n",
       "      <td>7.591435</td>\n",
       "      <td>36.108796</td>\n",
       "      <td>34.551505</td>\n",
       "      <td>7.057870</td>\n",
       "      <td>6.132523</td>\n",
       "      <td>...</td>\n",
       "      <td>117.812376</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>0.641204</td>\n",
       "      <td>355.395833</td>\n",
       "      <td>113.627233</td>\n",
       "      <td>15.441678</td>\n",
       "      <td>9.626942</td>\n",
       "      <td>36.412613</td>\n",
       "      <td>18.282600</td>\n",
       "      <td>0.053658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.870081</td>\n",
       "      <td>4.714772</td>\n",
       "      <td>12.402672</td>\n",
       "      <td>14.015213</td>\n",
       "      <td>8.223288</td>\n",
       "      <td>6.085073</td>\n",
       "      <td>14.940328</td>\n",
       "      <td>16.311733</td>\n",
       "      <td>7.133933</td>\n",
       "      <td>6.114837</td>\n",
       "      <td>...</td>\n",
       "      <td>16.962037</td>\n",
       "      <td>0.055155</td>\n",
       "      <td>0.558944</td>\n",
       "      <td>62.740932</td>\n",
       "      <td>15.371770</td>\n",
       "      <td>1.776676</td>\n",
       "      <td>1.402906</td>\n",
       "      <td>3.359063</td>\n",
       "      <td>2.400625</td>\n",
       "      <td>0.176289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>81.254834</td>\n",
       "      <td>0.622461</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>79.715930</td>\n",
       "      <td>10.373585</td>\n",
       "      <td>4.478070</td>\n",
       "      <td>26.983168</td>\n",
       "      <td>8.955324</td>\n",
       "      <td>-0.614621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>106.325902</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>103.389508</td>\n",
       "      <td>14.324786</td>\n",
       "      <td>8.715563</td>\n",
       "      <td>34.333093</td>\n",
       "      <td>16.803967</td>\n",
       "      <td>-0.055271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>117.195959</td>\n",
       "      <td>0.868373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>113.330178</td>\n",
       "      <td>15.392865</td>\n",
       "      <td>9.575076</td>\n",
       "      <td>36.508761</td>\n",
       "      <td>18.214380</td>\n",
       "      <td>0.066309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.556872</td>\n",
       "      <td>0.895468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>385.250000</td>\n",
       "      <td>124.476854</td>\n",
       "      <td>16.464615</td>\n",
       "      <td>10.496913</td>\n",
       "      <td>38.854624</td>\n",
       "      <td>19.721163</td>\n",
       "      <td>0.175082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>167.480231</td>\n",
       "      <td>0.966171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>156.099698</td>\n",
       "      <td>20.266667</td>\n",
       "      <td>14.304734</td>\n",
       "      <td>43.564530</td>\n",
       "      <td>26.083379</td>\n",
       "      <td>0.494077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        zip_number            1            2            3            4  \\\n",
       "count  1728.000000  1728.000000  1728.000000  1728.000000  1728.000000   \n",
       "mean      4.506366     5.077546    40.752315    37.320023     6.612847   \n",
       "std       2.870081     4.714772    12.402672    14.015213     8.223288   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     1.000000    35.000000    29.000000     1.000000   \n",
       "50%       4.000000     4.000000    43.000000    39.000000     4.000000   \n",
       "75%       7.000000     8.000000    50.000000    48.000000     9.000000   \n",
       "max       9.000000    25.000000    63.000000    64.000000    54.000000   \n",
       "\n",
       "                 5            6            7            8            9  ...  \\\n",
       "count  1728.000000  1728.000000  1728.000000  1728.000000  1728.000000  ...   \n",
       "mean      7.591435    36.108796    34.551505     7.057870     6.132523  ...   \n",
       "std       6.085073    14.940328    16.311733     7.133933     6.114837  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       3.000000    25.000000    24.000000     1.000000     1.000000  ...   \n",
       "50%       6.000000    39.000000    37.000000     5.000000     5.000000  ...   \n",
       "75%      12.000000    48.000000    47.000000    11.000000     9.000000  ...   \n",
       "max      31.000000    64.000000    64.000000    37.000000    39.000000  ...   \n",
       "\n",
       "         perimeter  eccentricity  euler_number  filled_area  \\\n",
       "count  1728.000000   1728.000000   1728.000000  1728.000000   \n",
       "mean    117.812376      0.855734      0.641204   355.395833   \n",
       "std      16.962037      0.055155      0.558944    62.740932   \n",
       "min      81.254834      0.622461     -1.000000   203.000000   \n",
       "25%     106.325902      0.823269      0.000000   311.000000   \n",
       "50%     117.195959      0.868373      1.000000   345.000000   \n",
       "75%     129.556872      0.895468      1.000000   385.250000   \n",
       "max     167.480231      0.966171      1.000000   579.000000   \n",
       "\n",
       "       perimeter_crofton  local_centroid-0  local_centroid-1  \\\n",
       "count        1728.000000       1728.000000       1728.000000   \n",
       "mean          113.627233         15.441678          9.626942   \n",
       "std            15.371770          1.776676          1.402906   \n",
       "min            79.715930         10.373585          4.478070   \n",
       "25%           103.389508         14.324786          8.715563   \n",
       "50%           113.330178         15.392865          9.575076   \n",
       "75%           124.476854         16.464615         10.496913   \n",
       "max           156.099698         20.266667         14.304734   \n",
       "\n",
       "       major_axis_length  minor_axis_length  orientation  \n",
       "count        1728.000000        1728.000000  1728.000000  \n",
       "mean           36.412613          18.282600     0.053658  \n",
       "std             3.359063           2.400625     0.176289  \n",
       "min            26.983168           8.955324    -0.614621  \n",
       "25%            34.333093          16.803967    -0.055271  \n",
       "50%            36.508761          18.214380     0.066309  \n",
       "75%            38.854624          19.721163     0.175082  \n",
       "max            43.564530          26.083379     0.494077  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle features zijn numerieke waardes. Hiervoor hoeven we dus geen aanpassingen in te brengen. De numerieke waardes verschillen wel in groottes. Dit zal genormaliseerd moeten worden in een latere fase.\n",
    "\n",
    "Verder lijkt het erop dat er geen missende waardes zijn.\n",
    "\n",
    "We zullen nog even moeten controleren of de labels gebalanceerd zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip_number\n",
       "0    162\n",
       "1    178\n",
       "2    185\n",
       "3    172\n",
       "4    170\n",
       "5    168\n",
       "6    168\n",
       "7    184\n",
       "8    162\n",
       "9    179\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.groupby(by='zip_number').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we naar boven kijken dan lijkt het erop dat de labels aardig gebalanceerd zijn. Dit zou dus geen problemen moeten leveren voor het algoritme. Dit betekent dat we door kunnen gaan met de volgende stappen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,\n",
    "            'major_axis_length', 'minor_axis_length', 'euler_number', \n",
    "            'centroid-0', 'eccentricity', 'local_centroid-0', 'perimeter', \n",
    "            'perimeter_crofton', 'filled_area', 'orientation']\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "minMaxScaler = MinMaxScaler()\n",
    "\n",
    "def preprocess(X_train, X_test):\n",
    "    print('-----Start preprocc----------')\n",
    "    global features\n",
    "    X_train[features] = minMaxScaler.fit_transform(X_train[features].to_numpy())\n",
    "    X_test[features] = minMaxScaler.transform(X_test[features].to_numpy())\n",
    "    print('---------Preprocess Done--------')\n",
    "    return X_train, X_test\n",
    "\n",
    "def splitTrainTest(result):\n",
    "    # Split data into 50% train and 50% test subsets\n",
    "    global features\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        result[features], result['zip_number'], test_size=0.25, random_state=0)\n",
    "    \n",
    "    X_train, X_test = preprocess(X_train, X_test)\n",
    "    print('-----------dataset splitted------------')\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-----------dataset splitted------------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = splitTrainTest(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchHyperParams_knn(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'n_neighbors' : [3,5,11,14,19],\n",
    "        'weights' : ['uniform', 'distance'],\n",
    "        'metric' : ['euclidean', 'manhattan', 'chebyshev']\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        KNeighborsClassifier(),\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)\n",
    "    \n",
    "def gaussian_nb_fit_score(result):\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "\n",
    "    score = gnb.score(X_test, y_test)\n",
    "    print(score)\n",
    "    \n",
    "def searchHyperParams_svc(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'C': [0.1,1, 10, 100],\n",
    "        'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': [1,0.1,0.01,0.001]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        SVC(),\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)\n",
    "    \n",
    "def searchHyperParams_DT(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter' : ['best', 'random'],\n",
    "        'max_depth': [1,5,10,20,50,100,150,None],\n",
    "        'min_samples_split': np.arange(2,5),\n",
    "        'min_samples_leaf': np.arange(1,5),\n",
    "        'min_weight_fraction_leaf': np.arange(0,0.5)\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        DecisionTreeClassifier(),\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)\n",
    "\n",
    "def searchHyperParams_RC(result):\n",
    "    print('--------start searching params--------')\n",
    "    X_train, X_test, y_train, y_test = splitTrainTest(result)\n",
    "    print('--------splitted train test----------')\n",
    "    grid_params = {\n",
    "        'bootstrap': [True, False],\n",
    "         'max_depth': [10, 20, 30, 40, None],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_leaf': [1, 2, 4],\n",
    "         'min_samples_split': [2, 5, 10],\n",
    "         'n_estimators': [200, 400, 600, 800]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        RandomForestClassifier(),\n",
    "        grid_params,\n",
    "        verbose = 3,\n",
    "        cv = 3,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    print('---------grid search started---------')\n",
    "    gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "    print('--------Done--------')\n",
    "    print('best score:')\n",
    "    print(gs_results.best_score_)\n",
    "    print('best estimator:')\n",
    "    print(gs_results.best_estimator_)\n",
    "    print('best params:')\n",
    "    print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-----------dataset splitted------------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.9421296296296297\n",
      "best estimator:\n",
      "KNeighborsClassifier(metric='manhattan', weights='distance')\n",
      "best params:\n",
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_knn(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-----------dataset splitted------------\n",
      "0.8356481481481481\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_fit_score(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-----------dataset splitted------------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.960648148148148\n",
      "best estimator:\n",
      "SVC(C=10, gamma=1)\n",
      "best params:\n",
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_svc(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-----------dataset splitted------------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 384 candidates, totalling 1152 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.8287037037037037\n",
      "best estimator:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=20, min_samples_split=3)\n",
      "best params:\n",
      "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_DT(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------start searching params--------\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "-----------dataset splitted------------\n",
      "--------splitted train test----------\n",
      "---------grid search started---------\n",
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "--------Done--------\n",
      "best score:\n",
      "0.91820987654321\n",
      "best estimator:\n",
      "RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=400)\n",
      "best params:\n",
      "{'bootstrap': False, 'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "searchHyperParams_RC(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_fit_score(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    neigh = KNeighborsClassifier(metric='manhattan', weights='distance')\n",
    "    neigh.fit(X_train, y_train.to_numpy().reshape(train_samples))\n",
    "\n",
    "    score = neigh.score(X_test, y_test.to_numpy().reshape(test_samples))\n",
    "    return score\n",
    "\n",
    "def kfolding_knn(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    global features\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['zip_number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = knn_fit_score(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1\n",
    "\n",
    "def svc_fit_score(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    neigh = SVC(C=10, gamma=1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "def kfolding_svc(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    global features\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['zip_number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = svc_fit_score(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1\n",
    "        \n",
    "def DT_fit_score(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    neigh = DecisionTreeClassifier(criterion='entropy', max_depth=20, min_samples_split=3)\n",
    "    neigh.fit(X_train, y_train)\n",
    "\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "def kfolding_DT(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    global features\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['zip_number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = DT_fit_score(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1\n",
    "        \n",
    "def RF_fit_score(X_train, X_test, y_train, y_test):\n",
    "    train_samples = len(X_train)\n",
    "    test_samples = len (X_test)\n",
    "    neigh = RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=400)\n",
    "    neigh.fit(X_train, y_train)\n",
    "\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "def kfolding_RF(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    global features\n",
    "    X_training = dataset[features]\n",
    "    y_training = dataset['zip_number']\n",
    "    k = 1\n",
    "    for train_index, test_index in kf.split(X_training, y_training):\n",
    "        \n",
    "        X_train, X_test = X_training.loc[train_index,:], X_training.loc[test_index,:]\n",
    "        y_train, y_test = y_training.loc[train_index], y_training.loc[test_index]\n",
    "        X_train, X_test = preprocess(X_train, X_test)\n",
    "        \n",
    "        score = RF_fit_score(X_train, X_test, y_train, y_test)\n",
    "        print(\"[fold {0}], score: {1:.5f}\".\n",
    "          format(k, score))\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 1], score: 0.95376\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 2], score: 0.94220\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 3], score: 0.94509\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 4], score: 0.94783\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 5], score: 0.94783\n"
     ]
    }
   ],
   "source": [
    "kfolding_knn(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit de resultaten kunnen we concluderen dat de algoritme als nog goed presteert onder de kfolding methode. Dit betekent dat de model geen last heeft van zowel overfitting als underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 1], score: 0.96821\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 2], score: 0.96821\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 3], score: 0.95665\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 4], score: 0.96232\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 5], score: 0.96812\n"
     ]
    }
   ],
   "source": [
    "kfolding_svc(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit de resultaten kunnen we concluderen dat de algoritme als nog goed presteert onder de kfolding methode. Dit betekent dat de model geen last heeft van zowel overfitting als underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 1], score: 0.82081\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 2], score: 0.82948\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 3], score: 0.83237\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 4], score: 0.83768\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 5], score: 0.81449\n"
     ]
    }
   ],
   "source": [
    "kfolding_DT(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit de resultaten kunnen we concluderen dat de algoritme als nog goed presteert onder de kfolding methode. Dit betekent dat de model geen last heeft van zowel overfitting als underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 1], score: 0.93353\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 2], score: 0.94798\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 3], score: 0.90173\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 4], score: 0.91594\n",
      "-----Start preprocc----------\n",
      "---------Preprocess Done--------\n",
      "[fold 5], score: 0.95072\n"
     ]
    }
   ],
   "source": [
    "kfolding_RF(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit de resultaten kunnen we concluderen dat de algoritme als nog goed presteert onder de kfolding methode. Dit betekent dat de model geen last heeft van zowel overfitting als underfitting.\n",
    "\n",
    "Om een classifier methode te kiezen zullen we de gemiddelde score berekenen (fold 1 t/m 5) van de kfolding methode. Dit doen we dus voor ieder algoritme.\n",
    "\n",
    "Dit levert de volgende resultaten op:\n",
    "\n",
    "- KNN -> 0.947342\n",
    "- SVC -> 0.964702\n",
    "- DT -> 0.826966\n",
    "- RN -> 0.92998\n",
    "\n",
    "allereerst kunnen we concluderen dat de combinatie van features voor betere resultaten zorgt. verder is het duidelijk geworden dat de SVC algoritme gemiddeld hoger scoort dan de overige classifiers. Voor de zekerheid is het handig om de resultaten te tonen in een grafiek om te controleren of de classifiers consistente resultaten leveren.\n",
    "\n",
    "## Grafiek weergave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Config: size of the figures\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "fix, axs = plt.subplots(2,2)\n",
    "\n",
    "knn_ax = [0.95376, 0.94220, 0.94509, 0.94783, 0.94783]\n",
    "svc_ax = [0.96821, 0.96821, 0.95665, 0.96232, 0.96812]\n",
    "dt_ax = [0.82081, 0.82948, 0.83237, 0.83768, 0.81449]\n",
    "rf_ax = [0.93353, 0.94798, 0.90173, 0.91594, 0.95072]\n",
    "\n",
    "x = np.arange(5)\n",
    "\n",
    "axs[0, 0].plot(x, knn_ax)\n",
    "axs[0, 0].set_title('Knn')\n",
    "axs[0, 0].set_ylim([0,1])\n",
    "axs[0, 1].plot(x, svc_ax, 'tab:orange')\n",
    "axs[0, 1].set_title('Svc')\n",
    "axs[0, 1].set_ylim([0,1])\n",
    "axs[1, 0].plot(x, dt_ax, 'tab:green')\n",
    "axs[1, 0].set_title('Decision Trees')\n",
    "axs[1, 0].set_ylim([0,1])\n",
    "axs[1, 1].plot(x, rf_ax, 'tab:red')\n",
    "axs[1, 1].set_title('Random Forest')\n",
    "axs[1, 1].set_ylim([0,1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit de grafieken kunnen we concluderen dat alle algoritmes consistent presteren. Ons interesse gaat voornamelijk naar de SVC classifier, vanwege de hoge resultaten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultaten\n",
    "\n",
    "In de vorige hoofdstuk hebben we geconcludeerd dat de SVC classifier de beste keuze is voor  nummer herkenning. Daarnaast lijkt een combinatie van features tot betere resultaten te leiden. Nu is het tijd om de algoritme te gebruiken voor het classificeren van postcodes.\n",
    "\n",
    "Hiervoor gaan we de totale dataset aan 480 afbeeldingen gebruiken en deze splitsen in train en test data. De test data zullen we  uiteindelijk gebruiken voor het berekenen van de accuraatheid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------score from test------------------- \n",
      "0.9595375722543352\n"
     ]
    }
   ],
   "source": [
    "all_zipcodes = []\n",
    "total_images = len(test_images_df.index)\n",
    "\n",
    "#standardScaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        result[features], result['zip_number'], test_size=0.2, random_state=0)\n",
    "\n",
    "X_train[features] = scaler.fit_transform(X_train[features].to_numpy())\n",
    "X_test[features] = scaler.transform(X_test[features].to_numpy())\n",
    "#train model\n",
    "svc_clf = SVC(C=10, gamma=1)\n",
    "svc_clf.fit(X_train, y_train)\n",
    "\n",
    "score = svc_clf.score(X_test, y_test)\n",
    "print('---------score from test------------------- ')\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, total_images):\n",
    "    \n",
    "    image_name = test_images_df.iloc[i, 0]\n",
    "    image = test_images_df.iloc[i, 1]\n",
    "    tmp_result_grid = initialize_image_grids(image, image_name)\n",
    "    tmp_result_props = initialize_image_props(image, image_name)\n",
    "    test_result = pd.concat([tmp_result_grid,tmp_result_props], axis=1)\n",
    "    test_result.reset_index(inplace=True,drop=True)\n",
    "    test_result['zip_number'] = test_result['zip_number'].astype(int)\n",
    "    test_result[features] = scaler.transform(test_result[features].to_numpy())\n",
    "    \n",
    "    # classify\n",
    "    predicted = svc_clf.predict(test_result[features])\n",
    "    #print(predicted)\n",
    "    all_zipcodes.append(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(a, b, c, d):\n",
    "    return int(f\"{a}{b}{c}{d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  1 4 8 9\n",
      "original:  ['1489']\n",
      "predicted:  1 8 6 5\n",
      "original:  ['1865']\n",
      "predicted:  1 9 0 4\n",
      "original:  ['1904']\n",
      "predicted:  2 6 0 8\n",
      "original:  ['2608']\n",
      "predicted:  2 7 0 8\n",
      "original:  ['2708']\n",
      "predicted:  2 9 7 1\n",
      "original:  ['2971']\n",
      "predicted:  3 3 4 6\n",
      "original:  ['3046']\n",
      "predicted:  3 4 1 7\n",
      "original:  ['3417']\n",
      "predicted:  5 5 2 1\n",
      "original:  ['3521']\n",
      "predicted:  3 5 3 6\n",
      "original:  ['3536']\n",
      "predicted:  3 5 9 1\n",
      "original:  ['3591']\n",
      "predicted:  3 6 0 6\n",
      "original:  ['3606']\n",
      "predicted:  3 6 4 1\n",
      "original:  ['3648']\n",
      "predicted:  3 7 1 1\n",
      "original:  ['3711']\n",
      "predicted:  3 7 4 6\n",
      "original:  ['3746']\n",
      "predicted:  3 9 2 1\n",
      "original:  ['3921']\n",
      "predicted:  3 9 8 9\n",
      "original:  ['3988']\n",
      "predicted:  4 0 0 6\n",
      "original:  ['4006']\n",
      "predicted:  4 1 3 4\n",
      "original:  ['4134']\n",
      "predicted:  4 7 6 9\n",
      "original:  ['4764']\n",
      "predicted:  5 0 7 1\n",
      "original:  ['5071']\n",
      "predicted:  5 5 3 9\n",
      "original:  ['5539']\n",
      "predicted:  5 5 5 1\n",
      "original:  ['5551']\n",
      "predicted:  5 5 7 8\n",
      "original:  ['5578']\n",
      "predicted:  5 6 4 3\n",
      "original:  ['5643']\n",
      "predicted:  6 3 9 6\n",
      "original:  ['6396']\n",
      "predicted:  6 3 3 9\n",
      "original:  ['6399']\n",
      "predicted:  6 4 0 3\n",
      "original:  ['6403']\n",
      "predicted:  6 6 3 9\n",
      "original:  ['6639']\n",
      "predicted:  6 6 5 2\n",
      "original:  ['6652']\n",
      "predicted:  6 6 5 8\n",
      "original:  ['6658']\n",
      "predicted:  7 1 6 9\n",
      "original:  ['7169']\n",
      "predicted:  7 2 5 6\n",
      "original:  ['7256']\n",
      "predicted:  7 7 7 9\n",
      "original:  ['7779']\n",
      "predicted:  8 0 6 4\n",
      "original:  ['8060']\n",
      "predicted:  8 3 9 5\n",
      "original:  ['8395']\n",
      "predicted:  8 4 3 2\n",
      "original:  ['8432']\n",
      "predicted:  8 5 4 3\n",
      "original:  ['8543']\n",
      "predicted:  8 8 9 3\n",
      "original:  ['8893']\n",
      "predicted:  8 9 9 7\n",
      "original:  ['8997']\n",
      "predicted:  9 0 0 2\n",
      "original:  ['9002']\n",
      "predicted:  3 1 1 1\n",
      "original:  ['9111']\n",
      "predicted:  9 3 0 6\n",
      "original:  ['9306']\n",
      "predicted:  9 3 1 0\n",
      "original:  ['9310']\n",
      "predicted:  9 5 3 4\n",
      "original:  ['9534']\n",
      "predicted:  9 6 1 1\n",
      "original:  ['9611']\n",
      "predicted:  9 7 2 6\n",
      "original:  ['9726']\n",
      "predicted:  9 8 3 8\n",
      "original:  ['9838']\n",
      "accuracy is:  83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "positive = 0\n",
    "for i in range(0, len(all_zipcodes)):\n",
    "    print('predicted: ', all_zipcodes[i][0], all_zipcodes[i][1], all_zipcodes[i][2], all_zipcodes[i][3])\n",
    "    print('original: ',  test_images_df.loc[i,['name']].to_numpy())\n",
    "    concatted = concat(all_zipcodes[i][0], all_zipcodes[i][1], all_zipcodes[i][2], all_zipcodes[i][3])\n",
    "    if concatted == int(test_images_df.loc[i,['name']]):\n",
    "        positive = positive + 1\n",
    "    \n",
    "numberItems = len(all_zipcodes)\n",
    "\n",
    "accuracyy = positive / numberItems * 100\n",
    "\n",
    "print('accuracy is: ', accuracyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie\n",
    "\n",
    "De algoritme levert een accuraatheid op van 83.3%. Dit is een hoger resultaat dan de vorige notebook. Voor de zekerheid heb ik ook gebruikt gemaakt van de standardscalar. Dit levert een nog lagere score op. Het lijkt erop dat een combinatie van image based en grid based classificatie leidt tot betere resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../classifiers/best_classifier.pkl']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(scaler, '../classifiers/best_preprocessor.pkl')\n",
    "joblib.dump(svc_clf, '../classifiers/best_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
