{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab session week 4: Analysis and cleaning\n",
    "\n",
    "In this lab session you will learn how to work with analysing, cleaning and preprocessing data. You will use the kNN classifier in the end.\n",
    "\n",
    "This weeks lab session consists of 5 small exercises:\n",
    "1. Analysing your data\n",
    "2. Imputation of missing values\n",
    "3. Dealing with outliers\n",
    "3. Preprocessing\n",
    "4. Classification with kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: analysing data with Pandas\n",
    "During this exercise we will use the dataset `housedata.csv`. Please watch the following video to understand the describe function of Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\display.py:717: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MaTAhxRsshE\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MaTAhxRsshE\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will use a dataset that has been created using this dataset from Kaggle (https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). It might be useful to look up the column information for each of the columns in your own dataset before you proceed.\n",
    "\n",
    "Now it is time to analyse our own dataset `housedata.csv`. Please do the following exercises:\n",
    "1. Load your data into a dataframe\n",
    "2. Have a look at the statistics using the describe function (hint: use include = 'all') and answer the following questions\n",
    "    - Does your dataset have missing values?\n",
    "    - Are their outliers?\n",
    "    - How is the distribution of your data (hint: use plots)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1378</td>\n",
       "      <td>1362.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ex</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>741</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10516.828082</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.095448</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1934.567808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9981.264932</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.386296</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>300.142482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-491.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7553.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9478.500000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11601.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2457.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LotArea  LotFrontage BldgType  OverallQual  OverallCond  \\\n",
       "count     1460.000000  1201.000000     1378  1362.000000  1460.000000   \n",
       "unique            NaN          NaN        5          NaN          NaN   \n",
       "top               NaN          NaN     1Fam          NaN          NaN   \n",
       "freq              NaN          NaN     1153          NaN          NaN   \n",
       "mean     10516.828082    70.049958      NaN     6.095448     5.575342   \n",
       "std       9981.264932    24.284752      NaN     1.386296     1.112799   \n",
       "min       1300.000000    21.000000      NaN     1.000000     1.000000   \n",
       "25%       7553.500000    59.000000      NaN     5.000000     5.000000   \n",
       "50%       9478.500000    69.000000      NaN     6.000000     5.000000   \n",
       "75%      11601.500000    80.000000      NaN     7.000000     6.000000   \n",
       "max     215245.000000   313.000000      NaN    10.000000     9.000000   \n",
       "\n",
       "          YearBuilt HeatingQC   Label  \n",
       "count   1460.000000      1460    1460  \n",
       "unique          NaN         5       3  \n",
       "top             NaN        Ex  normal  \n",
       "freq            NaN       741     593  \n",
       "mean    1934.567808       NaN     NaN  \n",
       "std      300.142482       NaN     NaN  \n",
       "min     -491.000000       NaN     NaN  \n",
       "25%     1952.000000       NaN     NaN  \n",
       "50%     1972.000000       NaN     NaN  \n",
       "75%     2000.000000       NaN     NaN  \n",
       "max     2457.000000       NaN     NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "houses = pd.read_csv('housedata.csv')\n",
    "houses.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers:**\n",
    "- Does the data set have missing values? Which columns?\n",
    "    - ... -> Yes, there is a difference in values in the \"Count\" row. If we take a look at the table, i would say the LotFrontage, BldgType and OverallQual columns have missing values because of the lower counts.\n",
    "- Does the data set have outliers? Which columns?\n",
    "    - ... -> yes there are surely outliers. if we look at the Yearbuilt column, you would expect that the yearbuilt would be in between 1900-2021 (now). But if we take a look at the min and max row of the Yearbuilt column we see significantly different values that exceeds or expectations. 2457 is in the future and -491 would be 491 b.c. i think? We could easily say there are outliers in this column.\n",
    "- How is the distribution of your data?\n",
    "    - ... -> there seems some not numerical data types in our data. it would be better to convert these types to numerical types for a ML algorithm. Bldgtype HealtingQc and Label are the NaN datatypes. Besides that we have a significant difference in numeric range. the LotArea is in between 1.300 and 215.245. while some other colums are in between 1 and 10. Data normalisation/standardization would be in handy for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Imputation\n",
    "We will now fix the problem of missing values by using imputation. Please watch the following video to understand how imputation works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\isahi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\display.py:717: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/D6saJ9R65L4\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/D6saJ9R65L4\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to do imputation on our own dataset.\n",
    "\n",
    "1. Impute missing values (mean, median or mode) depending on the earlier found statistics\n",
    "2. Use the Scikit-learn framework for imputation (http://scikit-learn.org/stable/modules/impute.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for numerical data using the imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Your code here\n",
    "houses.isnull()\n",
    "houses.isnull().sum()\n",
    "houses.isnull().sum()/len(houses)\n",
    "#houses.drop('LotFrontage', inplace=True, axis=1)\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "houses['OverallQual'] = imp.fit_transform(houses['OverallQual'].values.reshape(-1,1))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotArea        0\n",
       "BldgType       0\n",
       "OverallQual    0\n",
       "OverallCond    0\n",
       "YearBuilt      0\n",
       "HeatingQC      0\n",
       "Label          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values for categorical values using pandas operations\n",
    "houses.isnull().sum()\n",
    "\n",
    "houses['BldgType'].value_counts()\n",
    "houses['BldgType'].fillna('1Fam', inplace=True)\n",
    "houses.isnull().sum()\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Dealing with outliers\n",
    "Since your dataset contains some outliers, we should fix this problem before proceeding to the next step. Read the following two (short) articles:\n",
    "1. https://www.theanalysisfactor.com/outliers-to-drop-or-not-to-drop/\n",
    "2. https://www.rapidinsightinc.com/handle-outliers/\n",
    "\n",
    "Use the described techniques, find the outliers in your dataset and deal with them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1428.000000</td>\n",
       "      <td>1428</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>1428</td>\n",
       "      <td>1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ex</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>722</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10510.981092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.084734</td>\n",
       "      <td>5.574930</td>\n",
       "      <td>1971.236695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10028.036885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.339065</td>\n",
       "      <td>1.117793</td>\n",
       "      <td>30.214811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7538.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9468.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1972.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11601.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LotArea BldgType  OverallQual  OverallCond    YearBuilt  \\\n",
       "count     1428.000000     1428  1428.000000  1428.000000  1428.000000   \n",
       "unique            NaN        5          NaN          NaN          NaN   \n",
       "top               NaN     1Fam          NaN          NaN          NaN   \n",
       "freq              NaN     1213          NaN          NaN          NaN   \n",
       "mean     10510.981092      NaN     6.084734     5.574930  1971.236695   \n",
       "std      10028.036885      NaN     1.339065     1.117793    30.214811   \n",
       "min       1300.000000      NaN     1.000000     1.000000  1872.000000   \n",
       "25%       7538.750000      NaN     5.000000     5.000000  1954.000000   \n",
       "50%       9468.500000      NaN     6.000000     5.000000  1972.500000   \n",
       "75%      11601.500000      NaN     7.000000     6.000000  2000.000000   \n",
       "max     215245.000000      NaN    10.000000     9.000000  2010.000000   \n",
       "\n",
       "       HeatingQC   Label  \n",
       "count       1428    1428  \n",
       "unique         5       3  \n",
       "top           Ex  normal  \n",
       "freq         722     581  \n",
       "mean         NaN     NaN  \n",
       "std          NaN     NaN  \n",
       "min          NaN     NaN  \n",
       "25%          NaN     NaN  \n",
       "50%          NaN     NaN  \n",
       "75%          NaN     NaN  \n",
       "max          NaN     NaN  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "houses.describe(include=\"all\")\n",
    "houses.query('YearBuilt < 1800')\n",
    "houses = houses[(houses.YearBuilt < 2021) & (houses.YearBuilt > 1800)]\n",
    "houses.describe(include=\"all\")\n",
    "\n",
    "#houses.query('LotArea > 80000')\n",
    "#houses['LotArea'].plot.hist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Preprocessing\n",
    "In order to use the data we have to preprocess the data. We have to perform several steps to make the data ready for classification.\n",
    "\n",
    "1. Apply one-hot-encoding on categorical features (use Scikit-learn or getDummies in Pandas (see: http://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example))\n",
    "2. Apply min-max-scaling or standardization (use Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>Label</th>\n",
       "      <th>BldgType_1Fam</th>\n",
       "      <th>BldgType_2fmCon</th>\n",
       "      <th>BldgType_Duplex</th>\n",
       "      <th>BldgType_Twnhs</th>\n",
       "      <th>BldgType_TwnhsE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>Ex</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>Ex</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>Ex</td>\n",
       "      <td>expensive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>Gd</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>Ex</td>\n",
       "      <td>expensive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>7917</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>Ex</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>13175</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>TA</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>9042</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>Ex</td>\n",
       "      <td>expensive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>9717</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>Gd</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>9937</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>Gd</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1428 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual  OverallCond  YearBuilt HeatingQC      Label  \\\n",
       "0        8450          7.0            5       2003        Ex     normal   \n",
       "1        9600          6.0            8       1976        Ex     normal   \n",
       "2       11250          7.0            5       2001        Ex  expensive   \n",
       "3        9550          7.0            5       1915        Gd     normal   \n",
       "4       14260          8.0            5       2000        Ex  expensive   \n",
       "...       ...          ...          ...        ...       ...        ...   \n",
       "1455     7917          6.0            5       1999        Ex     normal   \n",
       "1456    13175          6.0            6       1978        TA     normal   \n",
       "1457     9042          7.0            9       1941        Ex  expensive   \n",
       "1458     9717          5.0            6       1950        Gd     normal   \n",
       "1459     9937          5.0            6       1965        Gd     normal   \n",
       "\n",
       "      BldgType_1Fam  BldgType_2fmCon  BldgType_Duplex  BldgType_Twnhs  \\\n",
       "0                 1                0                0               0   \n",
       "1                 1                0                0               0   \n",
       "2                 1                0                0               0   \n",
       "3                 1                0                0               0   \n",
       "4                 1                0                0               0   \n",
       "...             ...              ...              ...             ...   \n",
       "1455              1                0                0               0   \n",
       "1456              1                0                0               0   \n",
       "1457              1                0                0               0   \n",
       "1458              1                0                0               0   \n",
       "1459              1                0                0               0   \n",
       "\n",
       "      BldgType_TwnhsE  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "1455                0  \n",
       "1456                0  \n",
       "1457                0  \n",
       "1458                0  \n",
       "1459                0  \n",
       "\n",
       "[1428 rows x 11 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1: Apply one hot encoding (using getdummies and concat?)\n",
    "\n",
    "# Your code here\n",
    "test = pd.concat([houses, pd.get_dummies(houses['BldgType'], prefix='BldgType')], axis=1)\n",
    "test.drop(['BldgType'], axis=1, inplace=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2: Apply min-max scaling or standardization\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Classification\n",
    "1. Split the dataset in two parts (75%/25%) for training and testing.\n",
    "2. Use the kNN algorithm from Scikit-learn and train a classifier\n",
    "3. Validate using your testset\n",
    "4. Play around with several hyperparameters to optimize your classification results\n",
    "\n",
    "**Warning: this dataset will probably not give you great classification results (around 70% score)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
